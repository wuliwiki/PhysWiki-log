% 海森矩阵
% keys 线性代数|多元微积分|矩阵|海森矩阵|海瑟矩阵|海塞矩阵|黑塞矩阵|Hessian|泰勒展开|矢量|梯度矢量|雅可比矩阵
% license Xiao
% type Tutor

\begin{issues}
\issueDraft
\end{issues}

\pentry{偏导数（简明微积分）\upref{ParDer}}

\footnote{参考 Wikipedia \href{https://en.wikipedia.org/wiki/Hessian_matrix}{相关页面}。}一个二阶可导的多元函数 $f(\bvec x)$ 的\textbf{海森矩阵（Hessian matrix）}\footnote{也译作\textbf{海瑟矩阵}，\textbf{海塞矩阵}，\textbf{黑塞矩阵}等。}， $\mat H$ 的定义为
\begin{equation}
H_{ij} = \pdv{f}{x_i}{x_j}~.
\end{equation}
$f(\bvec x)$ 的泰勒展开\upref{NDtalr}的前两项可以用梯度矢量和海森矩阵表示为
\begin{equation}
f(\bvec x) = f(\bvec x_0) + (\bvec x - \bvec x_0) \grad f(\bvec x_0) + \frac12(\bvec x - \bvec x_0) \mat H (\bvec x - \bvec x_0) + \order{(x-x_0)^3}~.
\end{equation}
海森矩阵可以看做梯度矢量 $\grad f$ 的雅可比矩阵， 即
\begin{equation}
H_{ij} = \pdv{x_j} \qty(\pdv{f}{x_i})~,
\end{equation}
所以有
\begin{equation}
\dd{(\grad f)} = \mat H \dd{\bvec x}~.
\end{equation}

如果 $f(\bvec x)$ 是一个二阶函数， 海森矩将不随 $\bvec x$ 变化。 所以有
\begin{equation}
\grad f(\bvec x) - \grad f(\bvec x_0) = \mat H (\bvec x - \bvec x_0)~,
\end{equation}
则函数的极值点为（令 $\grad f = 0$）
\begin{equation}
\bvec x = \bvec x_0 - \mat H^{-1} \grad f(\bvec x_0)~.
\end{equation}
这就是牛顿法寻找函数极小值的主要思路（链接未完成）。
