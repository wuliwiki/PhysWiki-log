% 交叉熵
% 交叉熵 信息论

\begin{issues}
\issueDraft
\end{issues}

\textbf{交叉熵}（Cross entropy）是信息论中一种衡量两个数据分布之间差异的度量。
在离散情形下，随机变量$x$有两个概率分布$P$和$Q$，$P$和$Q$的交叉熵定义如下：
\begin{equation}
H(P,Q)=-\sum_iP(x)lnQ(x)~.
\end{equation}

在连续情形下，随机变量$x$有两个概率密度$p$和$q$，$p$和$q$的交叉熵定义如下：
\begin{equation}
H(P,Q)=- \int_{-\infty}^{+\infty}p(x)lnq(x)dx~.
\end{equation}

交叉熵和相对熵\upref{KLD}有一定联系，满足关系：$H(P,Q)=H(P)+KL(P||Q)$。