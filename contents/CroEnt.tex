% 交叉熵
% keys 交叉熵|信息论
% license Xiao
% type Tutor


\pentry{随机变量、概率密度函数\upref{RandF}，反常积分（简明微积分）\upref{impro}}{nod_fa40}

\textbf{交叉熵}（Cross entropy）是信息论中一种衡量两个数据分布之间差异的度量。
在离散情形下，随机变量$x$有两个概率分布$P$和$Q$，$P$和$Q$的交叉熵定义如下：
\begin{equation}
H(P,Q)=-\sum_iP(x)lnQ(x)~.
\end{equation}

在连续情形下，随机变量$x$有两个概率密度$p$和$q$，$p$和$q$的交叉熵定义如下：
\begin{equation}
H(P,Q)=- \int_{-\infty}^{+\infty}p(x)lnq(x)dx~.
\end{equation}

交叉熵和\textbf{相对熵}\upref{KLD}有一定联系，满足关系：$H(P,Q)=H(P)+KL(P||Q)$。
