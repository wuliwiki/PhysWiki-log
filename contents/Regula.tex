% 正则化
% 正则化

\begin{issues}
\issueMissDepend
\issueNeedCite
\end{issues}

\textbf{正则化}（Regularization）是机器学习中用于减少泛化误差（测试误差），从而缓解过度拟合的设计策略。当使用正则化策略减少泛化误差时，可能会增大训练误差。

\textbf{参数范数惩罚}是最常用的正则化策略之一。传统机器学习方法就有很多使用，而在当今的深度学习中也应用广泛。参数范数惩罚的主要思想是给目标函数$J$添加一个参数范数惩罚项$\Omega(\theta)$，限制模型的学习能力，从而减少过度拟合的发生。设$J'$为正则化后的目标函数，则有：
\begin{equation}
J'(\bvec \theta;\bvec X,y)=J(\theta;\bvec X,y)+\alpha\Omega(\bvec \theta)
\end{equation}
其中，$\alpha\in[0,\infty)$是权衡范数惩罚项$\Omega$和标准目标函数$J(\bvec X;\bvec \theta)$相对贡献的超参数。将$\alpha$设为$0$表示没有正则化。


\subsection{$L^2$参数正则化}

$L^2$参数正则化指的是用参数的$2$范数作为惩罚项，即把公式$(1)$中的$\Omega(\theta)$写成参数的$2$范数形式。数学表示是：$\Omega(\theta)=\frac{1}{2}||\bvec w||_2^2$.
在优化代价函数时，会使得$\Omega(\bvec \theta)$有极小化的趋势，因此，该正则化策略会使得权值趋向于原点。

采用了$L_2$正则化策略的代价函数表示为：
\begin{equation}
J'(\bvec \theta;\bvec X,y)=J(\bvec \theta;\bvec X,y)+\alpha\frac{1}{2}||\bvec w||_2^2~
\end{equation}

有的文献称$L^2$正则化为\textbf{岭回归}。


\subsection{$L^1$参数正则化}

$L_1$参数正则化也是一种常用的参数范数惩罚策略.顾名思义,就是采用参数的$1$范数作为惩罚项,即$\Omega(\theta)=||\bvec w||_1=\sum_i|\bvec w_i|$.

采用了$L_1$正则化策略的代价函数表示为：
\begin{equation}
J'(\bvec \theta;\bvec X,y)=J(\bvec \theta;\bvec X,y)+\alpha||\bvec w||_1~
\end{equation}


\subsection{数据增强}

如果一个训练数据集拥有足够多的训练数据，那么可以较好地反应数据生成分布，由此训练出来的模型就具有良好的泛化能力。但实际应用中，往往缺少关键的数据。此时，就可以采用数据增强方法来训练模型。

\textbf{数据增强}（Data augmentation）是对原始训练数据中的样本做一定规则的变换，从而生成新的训练数据样本。此方法也是一种常用的正则化方法，可以明显地增强模型的泛化能力，而且使用起来较为方便。

一个典型的应用场景，就是图像分类任务。我们可以通过对原始训练数据中的图像做平移、旋转或缩放等仿射变换操作，以补充训练数据。例如，一个识别图像是猫或狗的对象识别问题。无论猫或狗在图像中是什么位置或什么角度，又或是什么大小，都不会改变它们的性质。因此，为了增强模型对各种情况下的分类准确性，可以采用上述数据增强的办法。

向数据中添加噪音也是数据增强的一种办法。在分类任务中，显然，我们希望在数据中有少量噪音的情况下，模型也能够给出正确结果。如果只采用原始数据来训练模型，可能使得模型对噪音的鲁棒性不足。为了，提高鲁棒性，我们可以在训练时，向数据中添加一定的噪音。


\subsection{提前终止}

在模型训练时，经常会出现的一种情况是，随着训练轮数的增加，训练误差不断减少，测试误差一开始也减少，但到一定时间之后，又会增加。此时，模型已经出现过度拟合。

其实，我们只要在测试误差最小的时候，停止训练，并返回模型即可。此策略就被称为\textbf{提前终止}（Early stopping）。