% MPI 笔记（C 语言）
% license Xiao
% type Note

\begin{issues}
\issueDraft
\end{issues}

本文参考\href{https://www.codingame.com/playgrounds/349/introduction-to-mpi/introduction-to-distributed-computing}{一个教程}， \href{https://people.sc.fsu.edu/~jburkardt/cpp_src/hello_mpi/hello_mpi.html}{入门例程}， \href{https://mpitutorial.com/tutorials/running-an-mpi-cluster-within-a-lan/}{如何配置集群}。

\subsection{安装 MPICH}
\begin{itemize}
\item mpich 虚拟机亲测成功， 然而在组里的服务器上不成功（ubuntu 系统不同， apt 中的 mpich 版本也不同， 不想自己编译了）
\item 安装 \verb|sudo apt install libmpich-dev|， 自动选择的版本是 \verb|3.3a2|。 安装完如果找不到 \verb|mpiexec|， 就退出 shell 再重新打开。
\item 要再每台机器把 s0 到 s3 的 ip 放到 \verb|/etc/localhost| 里面！ 确保可以 ping， 然后用 \verb|mpiexec -np 4 -host s0,s1,s2,s3 ./quad_mpi|， 不能用 \verb|localhost| 注意 \verb|./| 不能少。
\end{itemize}

\subsection{安装 OpenMPI}
\begin{itemize}
\item 检查 OpenMPI 版本用 \verb|mpiexec --version|， 目前是 4.1.x， \verb|mpicxx --version| 只会给出 g++ 的版本号。
\item \verb|sudo apt install openmpi-bin libopenmpi-dev| 然而 apt 的版本是非常老的， \verb|2.x.x|， 目前的版本是 \verb|4.1.4|。 笔者用 \verb|2.x.x| 在多台机器上从来没成功过。 其实 \verb|4.1.4| 也没有成功\footnote{\verb`WARNING: Open MPI accepted a TCP connection from what appears to be a another Open MPI process but cannot find a corresponding process entry for that peer.`}\footnote{\verb`WARNING: Open MPI failed to TCP connect to a peer MPI process.  This should not happen. ... connect() to 10.0.2.4:1024 failed`}。
\item 要安装比 apt 更新的版本， 复制 \verb|https://www.open-mpi.org/software/ompi/v4.1/| 里面的压缩包链接， 用 \verb|wget| 下载， 然后解压如 \verb|tar -xzvf openmpi-4.1.4.tar.gz| （要几分钟）。 进入解压文件夹， \verb|./configure|， \verb|make all -j20|， \verb|sudo make install| 即可。 如果 \verb|mpicxx --version| 说找不到 so 文件， 就用 \verb|sudo ldconfig| 即可。
\item \verb|sudo make uninstall| 卸载
\end{itemize}

\subsection{安装 Intel MPI}
\begin{itemize}
\item 【更新】现在 Intel 已经包括在 \enref{Intel OneAPI}{OneAPI} 中了。 编译器， MKL， MPI 等（Parallel Studio 中的一切）， 商用和非商用都已经免费。 \textbf{组里的服务器亲测成功}， \verb|mpiexec -np 2 --host server1,server2 ./可执行文件|
\item intel MPI 和 MKL 一样是免费的， google 一下， 下载安装包即可， 运行 \verb`sudo ./install.sh` 安装， 过程和 MKL 差不多
\item 如果已经安装了 MKL， 可能会提示目录已经存在（不确定 MKL 是否已经包含 MPI）
\item 安装好以后同样需要在 \verb`~/.bashrc` 中添加路径， 即在文件最后加入命令 \verb`source /opt/intel/compilers_and_libraries_2020.1.217/linux/mpi/intel64/bin/mpivars.sh`
\item 重启一下 shell， 运行 \verb`mpicxx --help`， 如果进入帮助页面就说明成功了
\item \verb`mpicxx` 或者 \verb`mpigxx` 都是 g++ 的一个 wraper， 和 g++ 一样使用即可。如果编译和链接分开也都要用。
\item 所有的机器都需要使用同一个版本的 MPI。
\end{itemize}


\subsection{基本语法}
\begin{itemize}
\item \verb|# include <mpi.h>|
\item 编译完以后， 如果直接运行程序只会有一个 process， 需要用例如 \verb|mpiexec -np 4 ./main.x| 指定进程数量。 \verb|mpirun| 也基本一样， 但并不在 MPI 标准中。 运行这个命令后，所有进程就都开始了。
\item 如果程序有参数以及 stdin 的文件， 用 \verb`mpiexec -np 4 ./main.x [参数1] [参数2] < 输入文件` 即可。 每一个进程都会获得完全一样的参数和独立的标准输入（不存在抢读输入文件的情况）。
\item \verb|MPI_Init(&argc, &argv);| 开始 MPI， \verb|MPI_Finalize();| 结束。 初始化会占用一些时间，可以留到程序中真的需要用到 MPI 的时候才使用，在这之前每个进程可以各自执行自己的事情（但是无法获取节点编号，所以一般在 init 前的计算都是完全相同的）。
\item \verb|MPI_Comm_size(MPI_Comm comm, &size);| 获取指定 communicator 的进程数
\item \verb|MPI_Comm_rank(MPI_Comm comm, &rank);|获取当前进程的 id， 称为 rank。
\item \verb|int MPI_Send(const void *buf, int count, MPI_Datatype datatype, int dest, int tag, MPI_Comm comm)| 其中 \verb|dest| 是进程 \verb|id|， \verb|tag| 是一个编号用于区分不同的消息（只需要区分来源和目标相同的多条消息）， \verb|comm| 一般是 \verb|MPI_COMM_WORLD| （所有进程）。
\item \verb`MPI_Send` 执行完以后，修改 \verb`buf` 是安全的。
\item 常用的 \verb|MPI_Datatype| 有 \verb|MPI_CHAR|， \verb|MPI_UNSIGNED_CHAR|， \verb|MPI_INT|， \verb|MPI_UNSIGNED|， \verb|MPI_LONG|， \verb|MPI_LONG_LONG|， \verb|MPI_FLOAT|， \verb|MPI_DOUBLE|， \verb|MPI_LONG_DOUBLE|， \verb|MPI_COMPLEX|， \verb|MPI_REAL16|， \verb|MPI_COMPLEX32|。
\item \verb|count| 是 \verb|buf| 中有几个数据， 即数组的长度。
\item \verb|int MPI_Recv(void *buf, int count, MPI_Datatype datatype, int source, int tag, MPI_Comm comm, MPI_Status *status)|， 接收信息。 \verb|status| 可以用于获取更多信息， 其他参数同理。 注意如果没有收到信息就会一直等待。
\item 事实上，\verb`MPI_Send` 和 \verb`MPI_Send` 之前还是必须要 \verb`MPI_Bcast` 让所有的节点都知道接收者是谁。 如果信息量不大，还不如把信息和接收者一起直接广播。例如每个节点有一个数，要找到最大的数所在的节点并通知它，就直接用下面的 \verb`MPI_Allreduce` 和 \verb`MPI_MAXLOC` 即可。 这样编程起来也会简单的多。
\item \verb|int MPI_Bcast(void *buffer, int count, MPI_Datatype datatype, int root,  MPI_Comm comm)| 从所有进程调用， 把所有进程中的 buffer 同步为 \verb`root` 的。 这相当于分别对每个进程用 \verb|MPI_Send()| 和 \verb|MPI_Recv()|。 注意如果 root 节点是运行时才确定的，那所有节点都要事先知道 root 是谁（要不然怎么确定自己要不要发送呢？）。
\item \verb|double MPI_Wtime()| 返回当前进程的时间（从任意起点开始， 单位秒）。
\item \verb|int MPI_Reduce(const void* send_buffer, void* receive_buffer, int count, MPI_Datatype datatype, MPI_Op operation, int root, MPI_Comm communicator);| 把每个进程中的某个变量（或数组）相加或相乘等， 赋值给 id 为 \verb|root| 的某个变量（或数组，即每个元素分别相加）。 其中 \verb|operation| 可以是 \verb|MPI_MAX, MPI_MIN, MPI_SUM, MPI_PROD|
\item \verb|int MPI_Allreduce(void *sendbuf, void *recvbuf, int count, MPI_Datatype datatype, MPI_Op op, MPI_Comm comm);| 和 \verb|MPI_Reduce| 一样， 但结果会返回到所有进程。
\item \verb|int MPI_Barrier(MPI_Comm comm)| 可以同步所有的进程到某个点。
\item \verb|Scatter()| （未完成）
\item \verb|Gather()| （未完成）
\item 如果每个节点有一个数字，而我们希望每个节点都可以获得一个一样的数组，装有每个节点的数字，那么用 \verb`MPI_Allgather(&my_number, 1, MPI_DOUBLE, all_numbers, 1, MPI_DOUBLE, MPI_COMM_WORLD);` 其中 \verb`my_number` 是双精度数字， \verb`all_numbers` 是双精度数组的指针。
\end{itemize}

\subsection{配置集群}
\begin{itemize}
\item 配置 \verb`~/.ssh/config` 或者 host 文件（给每个 ip 一个名称）， 设置免密码 ssh\upref{SSH}。
\item 设置一个共享网络文件夹\upref{NFS}（应该方法不限）， 把 mpicxx 编译的可执行文件放到里面
\item \verb|mpirun -np 5 -host localhost,worker1,worker2,... ./可执行文件|。 其中 \verb`localhost` 是本机，\verb`worker1,worker2` 是 ssh config 中的其他机器的名称。 如果不指定 \verb`-host`， 所有进程将在本机运行。
\item 注意进程和线程是两回事。 \verb`-np` 指定的是进程。
\item 注意虽然 \verb`mpirun` 依赖 \verb`ssh` 在其他主机运行进程等，但在真正的通讯中一般使用 MPI 自己的通讯协议（基于 \verb`TCP/IP` 或 InfiniBand 等）
\item 也可以用文件指定机器，以及每个机器运行几个进程（\verb`slots`）： \verb`mpiexec -np 12 -machinefile machines.txt ./main.x`
\begin{lstlisting}[language=none,caption=machines.txt]
localhost slots=2
machine1 slots=4
machine2 slots=4
machine3 slots=2
\end{lstlisting}
其中也可以不包含 \verb`localhost`，那么所有进程将远程运行。
\end{itemize}
