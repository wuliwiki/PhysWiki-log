% 线性无关判别法
% keys 线性无关|判别法
% license Xiao
% type Tutor

\begin{issues}
\issueOther{缺例题}
\end{issues}

\pentry{对偶空间\nref{nod_DualSp}}{nod_b56e}

在向量空间中，找出线性无关\upref{linDpe}的向量往往是一个基本的任务，这可以从基底张成向量空间看出（\autoref{def_VecSpn_1}~\upref{VecSpn}）。再有了对偶空间 \upref{DualSp}$V^*$ 的知识后，可以便洁的给出向量空间 $V$ 中向量线性无关性的各种判别法。

\begin{lemma}{}\label{lem_LinInD_1}
若 $\bvec a_1,\cdots,\bvec a_m$ 是 $V$ 中线性相关的向量，而 $f_1,\cdots,f_m$ 是 $V$ 上任意的线性函数\autoref{def_DualSp_3}~\upref{DualSp}，那么
\begin{equation}
\det(f_i(\bvec a_j))=0\qquad (1\leq i,j\leq m)~.
\end{equation}
($i$ 是行指标，$j$ 是列指标)\footnote{矩阵的指标往往遵从“左行右列，上行下列”的原则，因为人们习惯“从上到下，从左到右”。在一维情形，“上”和“左”，“下”和“右”并无区别，只是表明某种方向性。}
\end{lemma}
\textbf{证明：}由于 $\bvec a_1,\cdots,\bvec a_m$ 线性相关，必有一个向量是其余向量的线性组合，不失一般性，设这个向量就是 $\bvec a_m$，则
\begin{equation}
\bvec a_m=\sum_{i\neq m}\alpha_i\bvec a_i~
\end{equation}
在行列式 $\det(f_i(\bvec a_j))$ 中，从最后一列减去第一列乘 $\alpha_1$，$\cdots$，第 $m-1$ 列乘 $\alpha_{m-1}$ ，于是最后一列变为
\begin{equation}
\begin{aligned}
&f_i(\bvec a_m)-\sum_{j\neq m}\alpha_j f_i(\bvec a_j)=f_i(\bvec a_m-\sum_{j\neq m}\alpha_{j}\bvec a_j)\\
&=f_i(\bvec 0)=0 \qquad (i=1,\cdots ,m)~,
\end{aligned}
\end{equation}
所以行列式为0.

\textbf{证毕！}

\begin{lemma}{}\label{lem_LinInD_2}
如果 $(f_1,\cdots,f_n)$ 是向量空间 $V$ 的 对偶空间$V^*$ 的一个基底，那么，向量 $\bvec a_1,\cdots,\bvec a_n\in V$ 线性无关的充要条件为
\begin{equation}\label{eq_LinInD_1}
\det(f_i(\bvec a_j))\neq 0~.
\end{equation}
\end{lemma}
\textbf{证明：} \begin{enumerate}
\item \textbf{充分性：}由\autoref{lem_LinInD_1} 直接得证！
\item \textbf{必要性：}向量 $\bvec a_1,\cdots,\bvec a_n\in V$ 线性无关，意味着 $V=\langle\bvec a_1,\cdots,\bvec a_n\rangle$ （\autoref{def_VecSpn_1}~\upref{VecSpn} ）.用 $(\bvec e_1,\cdots,\bvec e_n)$ 代表 $V$ 的对偶于 $(f_1,\cdots,f_n)$ 的基底（\autoref{sub_DualSp_1}~\upref{DualSp} ），而用 $\alpha_{1j},\cdots,\alpha_{nj}$ 代表向量 $\bvec a_j$ 在这个基底下的坐标。那么
\begin{equation}
\begin{pmatrix}
\alpha_{11}&\cdots&\alpha_{1n}\\
\vdots&\vdots&\vdots\\
\alpha_{n1}&\cdots&\alpha_{nn}
\end{pmatrix}~
\end{equation}
就是由基底 $(\bvec e_1,\cdots,\bvec e_n)$ 到基底 $(\bvec a_1,\bvec a_n)$ 的过渡矩阵\upref{TransM}。由\autoref{ex_TransM_1}~\upref{TransM}，它是可逆的，从而 $\det(\alpha_{ij}))\neq0$ 。但 $\alpha_{ij}=f_i(\bvec a_j)$ ，故而\autoref{eq_LinInD_1} 成立。

\textbf{证毕！} 
\end{enumerate}
\begin{theorem}{}
设 $(f_1,\cdots,f_n)$ 是对偶于 $V$ 的空间 $V^*$ 的一个基底。那么，向量组 $\bvec a_1,\cdots,\bvec a_k\in V$ 的秩等于所有形如
\begin{equation}\label{eq_LinInD_2}
\det(f_i(\bvec a_j))\qquad (1\leq i=i_1~,\cdots~ ,i_m\leq n;\;1\leq j=j_1~,\cdots~,j_m\leq k)~
\end{equation}
的非零行列式的最大阶数。
\end{theorem}
\textbf{证明：}用 $r$ 代表向量组 $\bvec a_1,\cdots,\bvec a_k$ 的秩。任意 $m>r$ ，$\bvec a_{j1},\cdots,\bvec a_{jm}$ 必线性相关。据\autoref{lem_LinInD_1} ，阶数 $m>r$ 的形如\autoref{eq_LinInD_2} 的行列式必为0。

现在只需证明，存在一个形如\autoref{eq_LinInD_2} 的非零行列式，其秩为 $r$。用 $\overline{f_1},\cdots,\overline{f_n}$ 代表线性函数 $f_1,\cdots,f_n$ 在子空间 $U=\langle\bvec a_1,\cdots,\bvec a_k\rangle$ 上的限制。
现要证明
\begin{equation}\label{eq_LinInD_3}
\langle\overline{f_1},\cdots,\overline{f_n}\rangle=U^*~.
\end{equation}

事实上，显然 $\langle\overline{f_1},\cdots,\overline{f_n}\rangle \in U^*$。齐次，设 $\tilde f$ 是 $U^*$ 的任一向量，$(\bvec e_1,\cdots,\bvec e_r)$ 的基底，而 $(\bvec e_1,\cdots,\bvec e_r;\bvec e_{r+1},\cdots,\bvec e_n)$ 是它在 $V$ 中的扩展基底。

对这样的线性函数 $f\in V^*$，其中 
\begin{equation}
f(\bvec e_i)=\tilde f(\bvec e_i) \quad(i=1~,\cdots ~,r)~,\quad f(\bvec e_i)=0
\quad (i=r+1,\cdots,n)~,
\end{equation}
因为 $V^*=\langle f_1,\cdots,f_n\rangle$，故 $f$ 可写成
\begin{equation}
f=\sum \beta_if_i~.
\end{equation}
把 $f$ 限制在 $U$ 上，显然 $\overline f=f|_U=\tilde f$，于是
\begin{equation}
\tilde f=\overline f=\sum \beta_i \overline f_i~,
\end{equation}
即 $\tilde f\in\langle\overline{f_1},\cdots,\overline{f_n}\rangle$ ，故 $U^*\subset\langle\overline{f_1},\cdots,\overline{f_n}\rangle$，于是证得\autoref{eq_LinInD_3} 。

最后，在 $\bvec a_1,\cdots,\bvec a_k$ 中选择 $r$ 个线性无关的向量（设为 $\bvec a_{j1},\cdots,\bvec a_{jr} $），在 $\overline f_1,\cdots ,\overline f_n$ 中选择 $r$ 个线性无关的向量（设为 $\overline f_{i1},\cdots,\overline f_{ir}$），它们分别构成 $U,U^*$ 的基底，由\autoref{lem_LinInD_2} 
\begin{equation}
\det(\overline f_i(\bvec a_j))\neq0 \qquad (i=i_1,\cdots ,i_r;\; j=j_1,\cdots,j_r)~.
\end{equation}
剩下只需注意 $\overline f_i(\bvec a_j)=f_i(\bvec a_j)$。

\textbf{证毕！}
