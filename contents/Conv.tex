% 卷积
% keys 卷积
% license Xiao
% type Tutor


\pentry{定积分\upref{DInt}，反常积分（简明微积分）\upref{impro}}

\textbf{卷积}（Convolution）是两个实变函数之间的运算，可以生成第三个函数。
设有两个函数$f(x)$和$g(x)$，$x \in R$，卷积后的结果函数为$s(t)$, $t \in R$。卷积运算通过定积分定义如下：
\begin{equation}
s(t) = (f*g)(t) = \int_{ - \infty }^{ + \infty } {f(x)g(t - x)dx}~.
\end{equation}
其中，星号*表示卷积运算。

从直观上说，卷积，顾名思义，就是相当于把一个函数水平\textbf{翻转}（flip）——即“卷”——之后，与另一个函数求积。

上述是卷积的连续情况下的定义。在实际应用中，所测量到的物理量可能是离散的。可以将上式中的积分换成求和即可。卷积在离散情形下的定义如下：
\begin{equation}
s(t) = (f*g)(t) = \sum_{ x = - \infty }^{ + \infty } {f(x)g(t - x)}~.
\end{equation}

在卷积神经网络中，通常称卷积的第一个参数，即式($2$)中的$x$为\textbf{输入}，第二个参数，即式($2$)中的函数$g$为\textbf{卷积核}（kernel）。

卷积运算是卷积神经网络的基本操作。整个卷积网络是由大量卷积操作搭建而成。由于数据在计算机中均是离散形式，因此卷积神经网络中的卷积运算均是离散形式的操作。卷积网络的特点是指考虑相邻神经元之间的联系，而早先的全连接网络则是要考虑同一层的每两个神经元之间的关系。

\textbf{卷积神经网络}\upref{ConvNe}最擅长处理的是图像任务。图像数据在计算机中的通常表示为矩阵，是二维形式的数据。对于二维离散数据的卷积操作，定义如下：
\begin{equation}
S(i,j) = (I*K)(i,j) = \sum_{m}\sum_{n}I(m,n)*K(i-m,j-n)~.
\end{equation}

值得注意的是，真正的卷积神经网络中的卷积其实并非符合上述定义的真正的卷积，而是所谓\textbf{互相关函数}（cross-correlation）。也就是说，实际网络中的卷积并没有翻转卷积核的操作[1]。


\textbf{参考文献:}
\begin{enumerate}
\item I. Goodfellow, Y. Bengio, and A. Courville, Deep learning. MIT press, 2016.
\end{enumerate}
