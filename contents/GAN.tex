% 生成对抗网络
% keys 生成|对抗|无监督|深度学习
% license Xiao
% type Tutor

\pentry{随机变量、概率密度函数\upref{RandF}，神经网络\upref{NN}}

\textbf{生成对抗网络}（Generative Adversarial Network, GAN）是基于神经网络结构的生成模型，是深度学习中的一种主流方法。该模型在各种问题场景，比如数据生成、艺术造作、图像修复、图像风格转换、语音合成、文本图像互相转换等中均有十分广泛的应用。

生成对抗网络模型主要包含两个网络结构：一是捕获数据分布的生成模型，也称为生成器（通常用$G$表示），二是估计来自训练数据（而不是$G$）样本的概率的判别模型，也称为判别器（通常用$D$表示）。生成器$G$的训练步骤是要最大化判别器$D$做出错误判断的概率。这个框架对应于最小最大化两人博弈。在生成器$G$和判别器$D$的任意函数的解空间中，存在一个独一无二的解，生成器还原训练数据分布，判别器处处等于$1/2$。

\begin{figure}[ht]
\centering
\includegraphics[width=14.25cm]{./figures/049dc13888134911.png}
\caption{生成对抗网络示意图} \label{fig_GAN_2}
\end{figure}

生成器在数据$x$上的分布记为$p_g$，输入生成器的随机变量，即噪音，记为$z$，其分布为$p(z)$.生成器本质上是一个从潜在空间（latent space），即输入的随机噪音，到数据空间（data space）的映射，是由多层神经网络表示的带有参数$\theta_g$的可微分函数，记为$G(z;\theta_g)$，参数$\theta_g$的值是模型训练时确定的，也就是学习出来的。
生成器和判别器玩的是双人最小最大游戏，其价值函数为：
\begin{equation}
\mathop{\min}\limits_G \mathop {\max }\limits_D V(D,G)=E_{x\sim p_{data}(x)}[logD(x)]+E_{z\sim p_z(z)}[log(1-D(G(z)))]~.s
\end{equation}
其中，$G$是生成器，$D$是判别器，$V$是价值函数，$z$表示随机噪音，$E$表示数学期望。

% Copied From MathType
% \begin{equation}
% \[\mathop {\min }\limits_G \mathop {\max }\limits_D V(D,G) = {E_{x\~{p_{data}}(x)}}[\log (D(x)] + {E_{z\~{p_z}(z)}}[\log (1 - D(G(z)))]\]
% \end{equation}

判别器的训练目标是尽可能分辨出数据是来自真实数据集，还是由生成器伪造的。通常会将真实数据的标签设置为$1$，生成器产生的数据的标签设置为$0$.生成器训练的目标是尽可能迷惑判别器，以使其无法准确辨别数据是真实的，还是生成器产生的。从数学上来说，生成对抗网络最终的目标是最小化模型输出数据的分布与真实数据分布之间的$JS$散度\upref{JSD}。

训练生成对抗网络时，会将生成器和判别器连接成一个网络。判别器参数保持不变，更新生成器参数；生成器参数保持不变，更新判别器参数。生成器和判别器连续不断地交替更新，直至训练结束。
\begin{figure}[ht]
\centering
\includegraphics[width=14.25cm]{./figures/d10422a86ae62784.png}
\caption{网络演化过程} \label{fig_GAN_1}
\end{figure}

随着人们研究的深入，生成对抗网络又出现多种变体。主要有：条件生成对抗网络\upref{cGAN}（Conditional Generative Adversarial Nets, cGAN）和循环生成对抗网络（Cycle Generative Adversarial Network, CycleGAN）。




\textbf{参考文献：}
\begin{enumerate}
\item I. Goodfellow et al., “Generative adversarial nets,” in Advances in neural information processing systems, 2014, pp. 2672–2680.
\end{enumerate}
