% JS 散度
% Jensen-Shannon Divergence

\textbf{JS散度}（Jensen-Shannon Divergence，缩写JSD）是基于 KL 散度（相对熵）\upref{KLD}的一种统计学度量，能够衡量两个概率分布之间的差异程度。

设概率空间上有两个概率分布$P$和$Q$，$M=\frac{1}{2}(P+Q)$，为$P$和$Q$的平均，则，$P$和$Q$的$JS$散度定义为
\begin{equation}
JSD(P||Q)=\frac{1}{2}D_{KL}(P||M)+\frac{1}{2}D_{KL}(Q||M)~,
\end{equation}
其中，$D_{KL}$表示$KL$散度。



参考文献
\begin{enumerate}
\item B. Fuglede and F. Topsoe, “Jensen-Shannon divergence and Hilbert space embedding,” in International Symposium onInformation Theory, 2004. ISIT 2004. Proceedings., 2004, p. 31–.
\end{enumerate}
