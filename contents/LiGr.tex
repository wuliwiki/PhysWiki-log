% 线性回归
% keys 线性回归

\textbf{线性回归}（Linear regression）是一种利用线性函数对自变量（特征）和因变量之间的关系进行建模的方法。线性回归是机器学习中一种广泛使用的基本回归算法。含有有多个特征的线性回归称为多元线性回归。

假设有$n$个特征（自变量）$x_1$,$x_2$,...,$x_n$，一个输出变量$y$，线性回归的一般形式表示如下：
\begin{equation}
y=f(\bvec x)=w_1x_1+w_2x_2+...+w_nx_n+b~.
\end{equation}
其中，系数$w_1$,$w_2$,...,$w_n$为特征的权重，$b$为偏置。上式也可以写成向量的形式：
\begin{equation}
y=f(\bvec x)=\bvec w^T\bvec x+b~.
\end{equation}
其中，$\bvec x = [x_1,x_2,...,x_n]$,$\bvec w = [w_1,w_2,...,w_n]$.

一个一元线性回归的示意图如下：
\begin{figure}[ht]
\centering
\includegraphics[width=14.25cm]{./figures/9fc43706c178cfe4.png}
\caption{示意图} \label{fig_LiGr_1}
\end{figure}
图中，蓝色表示数据点，红色直线表示最终求得的线性回归结果。

线性回归适合处理的是数值型数据。但也可以处理标签型数据，此时，须要先对标签数据做连续化预处理。

例如，性别，有两个可能的取值：男、女。为了将性别作为特征送给线性回归使用，可以设男=0，女=1.又如，苹果大小，这个特征，本来有三个标签取值：大、中和小。我们可以令小=1、中=2、大=3，然后再作为特征以便回归使用。

值得注意的是，不是所有标签型数据的特征都可以按照上述方法连续化。考察前面两个例子，其特征的取值是有偏序关系的，因而可以直接按照序关系取数值做连续化。然而，一个没有序关系的特征，就不能直接按照上述方法处理。举个例子，颜色，可能取得的值为：红、绿和蓝。那么，我们就不好直接令红=1，绿=2，蓝=3.因为它们之间没有既定的顺序，如果我们直接赋值$1$、$2$、$3$，就会人为引入一个顺序关系，从而可能会带来问题。此时，可以采用的解决办法是，采用一个三维向量来表示三个特征的取值。设$x$、$y$、$z$分别表示是否为红、绿、蓝。若是，则为1，否则为0.，那么，红、绿、蓝三种颜色可以分别表示为$[1,0,0]$、$[0,1,0]$和$[0,0,1]$。这样做的好处是，避免人为引入一个顺序关系。