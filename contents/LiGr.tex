% 线性回归
% 线性回归

\textbf{线性回归}（Linear regression）是一种利用线性函数对自变量（特征）和因变量之间的关系进行建模的方法。线性回归是机器学习中一种广泛使用的基本回归算法。含有有多个特征的线性回归称为多元线性回归。

假设有$n$个特征（自变量）$x_1$,$x_2$,...,$x_n$，一个输出变量$y$，线性回归的一般形式表示如下：
\begin{equation}
y=f(\bvec x)=w_1x_1+w_2x_2+...+w_nx_n+b
\end{equation}
其中，系数$w_1$,$w_2$,...,$w_n$为特征的权重，$b$为偏置。上式也可以写成向量的形式：
\begin{equation}
y=f(\bvec x)=\bvec w^T\bvec x+b
\end{equation}
其中，$\bvec x = [x_1,x_2,...,x_n]$,$\bvec w = [w_1,w_2,...,w_n]$.

一个一元线性回归的示意图如下：
\begin{figure}[ht]
\centering
\includegraphics[width=14.25cm]{./figures/LiGr_1.png}
\caption{示意图} \label{LiGr_fig1}
\end{figure}
图中，蓝色表示数据点，红色直线表示最终求得的线性回归结果。