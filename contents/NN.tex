% 神经网络
% keys 神经网络 人工神经网络
% license Xiao
% type Tutor

\textbf{神经网络}（Neural network, NN），准确地说，是\textbf{人工神经网络}（Artificial neural network, ANN），在机器学习领域中是指“由具有适应性的简单单元组成的广泛并行互联的网络，其组织能够模拟生物神经系统对真实世界物体所做出的交互反应”[1]。

神经网络是机器学习中广泛使用的一种基本方法。该方法具有较好的曲线拟合能力，能够从数据中学习离散型、连续型或者向量型函数。

\subsection{动机}

神经网络最初是受到生物神经系统结构的启发，而提出的机器学习模型。生物的神经系统，比如人脑，从结构上讲，是由大量的基本单位——神经元通过各种复杂的互相连接而构成。从功能的角度，神经系统中的每个神经元都可以接收别的神经元传来的信号，然后做出处理，将处理后的结果，通过信号发送给其它与之连接的神经元。大量神经元能够同时协调工作，从而使得整个神经系统具有对各种环境刺激做出反应的能力，即\textbf{智能}（Intelligence）。

由此，人们受到启发，如果能够模拟生物神经系统的结构，并赋予其类似的信息传送和处理机制，则可以定义一个能够具有一定智能的数学模型。值得注意的是，虽然人工神经网络最初的想法是受到生物学的启发，但是在其后续实际研究过程中，站在计算机科学家的角度上来说，并不追求在每一个细节上都模拟生物神经系统。例如，人工神经元输出单一不变的值，然而生物神经元输出的是复杂的时序脉冲[2]。

\subsection{基本结构}

\subsubsection{1.神经元}

生物神经系统的基本单位是神经元，能够接收、处理和发送信号。人们将生物神经元抽象出一个简单模型，即\textbf{人工神经元}（Artificial neuraon），在机器学习领域内，通常就称\textbf{神经元}（Neuron）。在该模型中，神经元接收到其它多个神经元传来的输入信号，这些输入信号通过带有权重的连接进行传递，神经元接收到的总输入值将与神经元的阈值进行比较，然后通过\textbf{激活函数}\upref{ActFun}处理以产生神经元的输出[3]。
\begin{figure}[ht]
\centering
\includegraphics[width=10cm]{./figures/4181cdc1351396c0.png}
\caption{神经元示意图} \label{fig_NN_1}
\end{figure}
神经元的基本结构如图1所示。其中，$x_1, x_2, ..., x_i, ..., x_n$表示神经元的输入，$w_1, w_2, ..., w_i, ..., w_n$表示每个输入所对应的权重，$g$为激活函数，$w_0$为偏移量，$y$为神经元的输出值。输出和输入的关系是
\begin{equation}
y=g(w_1x_1+w_2x_2+...+w_ix_i+...+w_nx_n+w_0).~
\end{equation}
也可以写成向量形式：
\begin{equation}
y=g(\bvec w \bvec x).~
\end{equation}
其中，$\bvec w=(w_0, w_1, w_2, ..., w_i, ..., w_n)$，$\bvec x=(x_0, x_1, x_2, ..., x_i, ..., x_n)$，$x_0=1$.


\subsubsection{2.感知机}
\textbf{感知机}（Perceptron）是有两层神经元构成的最简单的神经网络。其结构中主要包含输入层和输出层。输入层能够接收外界传送来的输入信号，并传递给输出层。输出层就是一个神经元，功能是接收来自输入层传递来的信号，然后做出处理，并输出结果。
\begin{figure}[ht]
\centering
\includegraphics[width=5cm]{./figures/5aea3a7e0b71ef24.png}
\caption{简单的感知机示意图} \label{fig_NN_2}
\end{figure}
图2表示的是一个简单的感知机。其中有两层，分别为输入层和输出层。输入层有两个输入神经元，分别接收输入信号$x_1$和$x_2$。输出层有一个输出神经元，产生输出结果$y$。

感知机能够表示所有的原子布尔函数：与（AND）、或（OR）、与非（NAND）、或非（NOR）[2]。



\subsubsection{参考文献}
\begin{enumerate}
\item T. Kohonen, “An introduction to neural computing,” Neural Networks, vol. 1, no. 1, pp. 3–16, 1988.
\item T. M. Mitchell, Machine learning. 1997.
\item 周志华. 机器学习[M]. 北京：清华大学出版社. 2016: 97
\end{enumerate}