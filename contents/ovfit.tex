% 过度拟合
% 过度拟合  过拟合

\textbf{过度拟合}（或称\textbf{过拟合、过配}，英文：overfitting）是指机器学习算模型在训练集上的误差和测试集上的误差之间差异过大。
造成过度拟合的原因可能有多种。最常见的就是模型容量过高，模型过于复杂，换句话说是模型假设所包含的参数数量过多。如此一来，算法会将训练集中所包含的没有普遍性的一些特征也学习进来，结果降低了模型的泛化能力。

\begin{figure}[ht]
\centering
\includegraphics[width=10cm]{./figures/5954d8c20533e993.png}
\caption{过度拟合。左图：欠拟合；中图：恰当拟合；右图：过度拟合 [1]} \label{fig_ovfit_1}
\end{figure}

机器学习从功能表现上与人类的学习类似。
打个可能不太恰当的比方，一个饱经沧桑，经历过各种复杂人际关系的人在遇到一个心思纯粹的人时，容易将对方想得很复杂，反而难以理解对方。这其实是因为他自己的经历所决定的。

过度拟合无法完全避免。在实际应用中，可以采用一些方法来尽可能减少过度拟合，例如，降低模型的复杂度，提前停止（Early stopping
），\textbf{交叉验证}\upref{CroVal}（Cross-validation），或者\textbf{正则化}\upref{Regula}（Regularization）等方法。

提高模型泛化能力背后的哲学思想正是所谓的“奥卡姆剃刀”原理。此原理的意思是，在能够解释所观察到的现象的各种不同理论中，我们尽可能去选择那个最简单的理论。



\textbf{参考文献：}
\begin{enumerate}
\item I. Goodfellow, Y. Bengio, A. Courville, and Y. Bengio, Deep learning, vol. 1, no. 2. MIT press Cambridge, 2016.
\item 周志华. 机器学习[M]. 清华大学出版社， 2016
\item https://en.wikipedia.org/wiki/Overfitting
\end{enumerate}