% 人工智能史（综述）
% license CCBYSA3
% type Wiki

本文根据 CC-BY-SA 协议转载翻译自维基百科\href{https://en.wikipedia.org/wiki/History_of_artificial_intelligence}{相关文章}。

人工智能（AI）的历史可以追溯到古代，那个时候有关于由工匠们赋予智慧或意识的人工生命体的神话、故事和传闻。从古代到现代，逻辑学和形式推理的研究直接促成了1940年代可编程数字计算机的发明，这是一种基于抽象数学推理的机器。这个设备及其背后的理念启发了科学家们开始讨论构建电子大脑的可能性。

人工智能研究领域是在1956年于达特茅斯学院举行的一次研讨会上创立的。[1] 参加该研讨会的人成为了人工智能研究的领导者，并且在几十年里引领着这一领域的发展。许多人预测，在一代人之内，像人类一样智能的机器将会问世。美国政府也提供了数百万美元，希望能够将这一愿景变为现实。[2]

最终，研究人员明显低估了这一壮举的难度。[3] 1974年，詹姆斯·莱特希尔的批评以及美国国会的压力导致美国和英国政府停止资助无目标的人工智能研究。七年后，日本政府的远见性倡议和专家系统的成功重新激发了对人工智能的投资，到了1980年代末，人工智能产业已经成长为一个价值十亿美元的行业。然而，到了1990年代，投资者的热情减退，人工智能在媒体中受到批评，行业也开始回避这一领域（这一时期被称为“人工智能寒冬”）。尽管如此，研究和资金在其他名称下依然持续增长。

进入2000年代，机器学习被应用于学术和工业中的广泛问题。这一成功归功于强大计算机硬件的可用性、大规模数据集的收集以及扎实的数学方法的应用。很快，深度学习证明是一项突破性的技术，超越了所有其他方法。2017年，变换器架构的首次亮相带来了令人印象深刻的生成型人工智能应用，及其他多个应用场景。到2020年代，人工智能的投资呈现爆发式增长。
\subsection{前驱}
\subsubsection{神话、小说和推测性的前驱}
\textbf{神话与传说}

在希腊神话中，塔罗斯（Talos）是一个由青铜铸成的巨人，担任克里特岛的守护者。他会向入侵者的船只投掷大石块，并每天绕岛的周围完成三次巡逻。[4] 根据伪阿波罗多罗斯的《博物志》（Bibliotheke），赫淮斯托斯（Hephaestus）在一位独眼巨人的帮助下锻造了塔罗斯，并将这个自动装置作为礼物献给米诺斯（Minos）。[5] 在《阿尔戈英雄传》（Argonautica）中，杰森（Jason）和阿尔戈英雄们通过拔出塔罗斯脚旁的塞子，导致其体内的生命之液流出，从而使塔罗斯丧命。[6]

皮格马利翁（Pygmalion）是希腊神话中的一位传奇国王与雕刻家，著名的故事出自奥维德的《变形记》。在奥维德的叙事诗《变形记》第十卷中，皮格马利翁因目睹普罗波埃提德斯（Propoetides）自愿卖淫的行为而对女性感到厌恶。尽管如此，他还是在维纳斯（Venus）的神庙中献上祭品，请求女神赐予他一位像他雕刻的雕像一样的女子。[7]

\textbf{中世纪关于人工生命体的传说}
\begin{figure}[ht]
\centering
\includegraphics[width=6cm]{./figures/7e497a845b48fea1.png}
\caption{歌德《浮士德》中的人造小人描绘} \label{fig_RGZN_1}
\end{figure}
在《事物的本质》中，瑞士炼金术士帕拉塞尔苏斯（Paracelsus）描述了一种他声称能制造“人造人”的方法。他将“一名男子的精液”放入马粪中，并在40天后喂入“人血的秘方”，这种混合物将变成一个活生生的婴儿。[8]

关于制造“哥雷姆”（Golem）的最早书面记载出现在13世纪初沃尔姆斯的以利以撒·本·犹大（Eleazar ben Judah）的著作中。[9] 在中世纪，人们认为，通过将写有上帝名字的纸条放入泥人（哥雷姆）口中，可以使其复活。[10] 与像青铜头这样的传奇自动装置不同，哥雷姆是无法说话的。[11][12]

在伊斯兰教的炼金术手稿中，\textbf{塔克温}（Takwin，即人工生命的创造）是一个常见的主题，尤其是在那些归属于贾比尔·伊本·海扬（Jabir ibn Hayyan）的作品中。伊斯兰炼金术士尝试通过炼金术创造各种生命形式，从植物到动物不等。[13]

在约翰·沃尔夫冈·冯·歌德（Johann Wolfgang von Goethe）的《浮士德：悲剧的第二部分》中，炼金术制造的“人造小人”（homunculus）注定要永远生活在他被制造出来的瓶子里，但他努力想要变成一个完整的人类身体。然而，在这一转变开始时，瓶子破裂，人造小人也随之死去。[14]

\textbf{现代小说}

到19世纪，关于人工人和思考机器的理念成为小说中的一个流行主题。像玛丽·雪莱的《弗兰肯斯坦》和卡雷尔·恰佩克的《R.U.R.》（罗索姆的万能机器人）[15]等著名作品探讨了人工生命的概念。像塞缪尔·巴特勒的《机器中的达尔文》[16]和爱德加·爱伦·坡的《梅尔策尔的棋手》[17]等推测性文章反映了社会对具有人工智能的机器日益增长的兴趣。人工智能至今仍是科幻小说中的常见主题。[18]

\textbf{自动装置}
\begin{figure}[ht]
\centering
\includegraphics[width=8cm]{./figures/dcdee03784e1a89f.png}
\caption{阿尔·贾扎里的可编程自动装置（公元1206年）} \label{fig_RGZN_2}
\end{figure}
许多文明的工匠建造了现实中的类人自动装置，包括燕师[19]、亚历山大英雄[20]、阿尔·贾扎里[21]、哈鲁恩·拉希德[22]、雅克·德·沃康松[23][24]、莱昂纳多·托雷斯·伊·凯韦多[25]、皮埃尔·贾凯-德罗兹和沃尔夫冈·冯·肯普伦[26][27]。

已知最古老的自动装置是古埃及和古希腊的神像[28][29]。信徒们相信，工匠们赋予这些雕像非常真实的心智，能够表现出智慧和情感——赫尔墨斯·特里斯梅吉斯图斯曾写道：“通过发现神的真正本质，人类已能够复制它”[30]。英国学者亚历山大·内克哈姆（Alexander Neckham）主张，古罗马诗人维吉尔曾建造了一座拥有自动雕像的宫殿[31]。

在早期现代时期，这些传奇的自动装置据说具有回答提问的神奇能力。晚期中世纪的炼金术士和原始新教徒罗杰·培根据说曾制造过一颗青铜头，并发展出自己是巫师的传说[32][33]。这些传说与北欧神话中的米米尔之头相似。传说中，米米尔以智力和智慧著称，在 Æsir-Vanir 战争中被斩首。奥丁被认为“用草药”保存了米米尔的头，并对其念咒语，使米米尔的头仍能向奥丁传授智慧。奥丁随后将头放在身边，作为咨询之用[34]。
\subsubsection{形式推理}
人工智能基于这样一种假设：人类的思维过程可以被机械化。机械或“形式”推理的研究有着悠久的历史。中国、印度和希腊的哲学家们在公元前一千年左右就已经发展出了结构化的形式推理方法。这些思想经过几百年的发展，得到了像亚里士多德（他对三段论进行了形式分析）、欧几里得（他的《几何原本》是形式推理的典范）、阿尔·花拉子米（他发展了代数，并将自己的名字赋予了“算法”一词）以及威廉·奥卡姆和邓斯·司各图等欧洲经院哲学家的深化和扩展[35][36]。

西班牙哲学家拉蒙·柳尔（1232–1315）发展了几种逻辑机器，致力于通过逻辑手段生产知识[37][38]；柳尔将他的机器描述为机械实体，能够通过简单的逻辑操作将基本且不容否认的真理组合在一起，机器通过机械方式产生这些操作，从而生成所有可能的知识[39]。柳尔的工作对戈特弗里德·莱布尼茨产生了巨大影响，后者重新发展了他的思想[40]。
\begin{figure}[ht]
\centering
\includegraphics[width=6cm]{./figures/d3b8a79f2fbc4764.png}
\caption{戈特弗里德·莱布尼茨，他推测人类的理性可以归结为机械计算。} \label{fig_RGZN_3}
\end{figure}
17世纪，莱布尼茨、托马斯·霍布斯和勒内·笛卡尔探索了将所有理性思维系统化的可能性，使其如代数或几何一样具有体系性[41]。霍布斯在《利维坦》中著名地写道：“理性……无非是计算，就是加法和减法”[42]。莱布尼茨设想了一种普遍的推理语言——通用符号系统（characteristica universalis），这种语言将论证简化为计算，令“两个哲学家之间不再需要争论，正如两个会计师之间也不必争论一样。因为只需拿起他们的铅笔和黑板，就可以彼此对话（如果愿意，可以有朋友作为见证者）：让我们计算吧”[43]。这些哲学家开始阐述物理符号系统假设，这一假设最终成为人工智能研究的指导信条。

数学逻辑的研究提供了使人工智能看似可行的关键突破。布尔的《思想的法则》和弗雷格的《概念文字》为此奠定了基础[44]。基于弗雷格的系统，罗素和怀特海德在1913年出版的《数学原理》中对数学基础进行了形式化处理。受罗素成功的启发，戴维·希尔伯特在1920年代和1930年代挑战数学家们回答一个根本性的问题：“所有的数学推理能否形式化？”[36]这个问题最终得到了哥德尔不完备定理[45]、图灵机[45]和丘奇的λ演算[注]的回答。
\begin{figure}[ht]
\centering
\includegraphics[width=8cm]{./figures/f837aba8957e9db3.png}
\caption{美国陆军拍摄的ENIAC照片，拍摄地点为摩尔电气工程学院[47]} \label{fig_RGZN_4}
\end{figure}
他们的答案在两个方面令人惊讶。首先，他们证明了数学逻辑实际上是有局限的。其次（对人工智能更为重要的是），他们的工作表明，在这些局限内，任何形式的数学推理都可以被机械化。丘奇-图灵论题意味着，一台机械设备，只需按简单的符号（如0和1）进行排列，就可以模仿任何可以想象的数学推理过程。关键的洞察是图灵机——一个简单的理论构造，它捕捉了抽象符号操作的本质。[48] 这一发明激发了一些科学家开始讨论思维机器的可能性。
\subsubsection{计算机科学}  
计算机器在古代和历史上由许多人设计或制造，包括戈特弗里德·莱布尼茨、约瑟夫·玛丽·雅卡尔、查尔斯·巴贝奇、珀西·卢德盖特、莱昂纳多·托雷斯·凯维多、范尼瓦·布什等。艾达·洛夫莱斯曾推测巴贝奇的机器是“一台思考或...推理机器”，但她警告说：“有必要防止对机器的能力产生夸大的想法。”  

第一台现代计算机是第二次世界大战期间的大型机器（如康拉德·楚泽的Z3、艾伦·图灵的希思·罗宾逊和巨人机、阿塔纳索夫与贝里的ABC以及宾夕法尼亚大学的ENIAC）。ENIAC基于艾伦·图灵奠定的理论基础，并由约翰·冯·诺依曼发展而成，证明它是最具影响力的计算机。[57]
\subsection{人工智能的诞生（1941-1956）}
\begin{figure}[ht]
\centering
\includegraphics[width=8cm]{./figures/dc69a2c824689d03.png}
\caption{IBM 702：第一代人工智能研究人员使用的计算机。} \label{fig_RGZN_5}
\end{figure}
早期的思维机器研究受到了20世纪30年代末、40年代和50年代初流行的思想汇聚的启发。神经学的最新研究表明，大脑是一个由神经元构成的电气网络，神经元以“全或无”的脉冲方式发射。诺伯特·维纳的控制论描述了电气网络中的控制与稳定性。克劳德·香农的信息理论描述了数字信号（即“全或无”的信号）。艾伦·图灵的计算理论表明，任何形式的计算都可以通过数字化的方式进行描述。这些思想之间的紧密关系暗示，构建一个“电子大脑”可能是可行的。

在40年代和50年代，来自各个领域（数学、心理学、工程学、经济学和政治学）的少数科学家探索了几个对后来的人工智能研究至关重要的研究方向。艾伦·图灵是最早认真研究“机器智能”理论可能性的人之一。“人工智能研究”作为一门学科在1956年成立。[59][60][61]
\subsubsection{图灵测试} 
\begin{figure}[ht]
\centering
\includegraphics[width=8cm]{./figures/3f5360e4685a515c.png}
\caption{图灵测试[62]} \label{fig_RGZN_6}
\end{figure}
1950年，图灵发表了具有里程碑意义的论文《计算机机械与智能》，在其中他推测了创造能够思考的机器的可能性。在论文中，他指出，“思考”是一个难以定义的概念，并提出了著名的图灵测试：如果一台机器能够进行一场（通过电传机进行的）对话，且这场对话与与人类的对话无法区分，那么就可以合理地说这台机器是在“思考”。这种简化版的问题让图灵能够有力地论证“思考机器”至少是可行的，这篇论文回答了所有对这一命题的常见反对意见。图灵测试是人工智能哲学中第一个严肃的提案。
\subsubsection{人工神经网络}  
沃尔特·皮茨（Walter Pitts）和沃伦·麦卡洛克（Warren McCulloch）于1943年分析了理想化的人工神经元网络，并展示了它们如何执行简单的逻辑功能。他们是首个描述后来被称为神经网络的学者[66]。该论文受到了图灵1936年《可计算数的论述》一文的影响，采用了类似的两状态布尔“神经元”，但首次将其应用于神经功能[60]。受皮茨和麦卡洛克启发的学生之一是马文·敏斯基（Marvin Minsky），当时他是一个24岁的研究生。1951年，敏斯基和迪恩·埃德蒙兹（Dean Edmonds）建立了第一个神经网络机器——SNARC[67]。敏斯基后来成为人工智能领域最重要的领导者和创新者之一。
\subsubsection{控制论机器人}  
20世纪50年代，W·格雷·沃尔特（W. Grey Walter）的海龟机器人和约翰霍普金斯大学的野兽机器人等实验性机器人相继问世。这些机器人没有使用计算机、数字电子学或符号推理，而是完全由模拟电路控制[68]。
\subsubsection{游戏人工智能}  
1951年，克里斯托弗·斯特雷奇（Christopher Strachey）利用曼彻斯特大学的费兰提Mark 1计算机编写了一个跳棋程序[69]，而迪特里希·普林茨（Dietrich Prinz）则为国际象棋编写了一个程序[70]。阿瑟·塞缪尔（Arthur Samuel）的跳棋程序是他1959年论文《机器学习的若干研究：以跳棋为例》中的研究成果，该程序最终达到了足以挑战一位相当水平的业余玩家的水平[71]。塞缪尔的程序是后来被称为机器学习的早期应用之一[72]。游戏人工智能将继续作为人工智能发展的衡量标准，贯穿其历史。
\subsubsection{符号推理与《逻辑理论家》}
\begin{figure}[ht]
\centering
\includegraphics[width=6cm]{./figures/7245eef62d056505.png}
\caption{符号推理与《逻辑理论家》} \label{fig_RGZN_7}
\end{figure}
当50年代中期开始可以访问数字计算机时，一些科学家本能地认识到，一台能够操控数字的机器同样也能操控符号，而符号的操控可能正是人类思维的本质。这是一种创造思维机器的新方法。[73][74]

1955年，艾伦·纽厄尔（Allen Newell）和未来的诺贝尔奖得主赫伯特·A·西蒙（Herbert A. Simon）在J·C·肖（J. C. Shaw）的帮助下创造了“逻辑理论家”（Logic Theorist）。该程序最终证明了拉塞尔和怀特海德《数学原理》（Principia Mathematica）中的前52个定理中的38个，并为其中一些定理找到了新的、更优雅的证明。[75] 西蒙表示，他们“解决了久远的心灵/身体问题，解释了一个由物质组成的系统如何具备心灵的特性。”[76][c] 他们所提出的符号推理范式将主导人工智能的研究和资金支持，直到90年代中期，并且启发了认知革命。
\subsubsection{达特茅斯研讨会}  
1956年的达特茅斯研讨会是一个关键事件，标志着人工智能作为一门学科的正式诞生。它由马文·明斯基和约翰·麦卡锡组织，并得到了IBM的两位资深科学家克劳德·香农和内森·罗切斯特的支持。会议提案中指出，他们旨在验证这一断言：“学习的每一个方面或智能的任何其他特征都可以被如此精确地描述，以至于可以制造一台机器来模拟它。”  

“人工智能”这一术语由约翰·麦卡锡在研讨会上提出。与会者包括雷·所罗门诺夫、奥利弗·塞尔弗里奇、特伦查德·摩尔、阿瑟·塞缪尔、艾伦·纽厄尔和赫伯特·A·西蒙，他们都将在人工智能研究的初期几十年里创建重要的程序。在研讨会上，纽厄尔和西蒙首次展示了《逻辑理论家》程序。  

这次研讨会是人工智能获得名称、使命、首个重大成功和关键人物的时刻，被广泛认为是人工智能的诞生。
\subsubsection{认知革命}  
1956年秋天，纽厄尔和西蒙在麻省理工学院（MIT）信息理论特别兴趣小组会议上展示了《逻辑理论家》。在同一会议上，诺姆·乔姆斯基讨论了他的生成语法，乔治·米勒描述了他的开创性论文《神奇的数字七，加或减二》。米勒写道：“我带着一种比理性更为直观的信念离开了研讨会，那就是实验心理学、理论语言学和认知过程的计算机模拟都是一个更大整体中的一部分。”  

这次会议标志着“认知革命”的开始——一个跨学科的范式转变，涉及心理学、哲学、计算机科学和神经科学。它启发了符号人工智能、生成语言学、认知科学、认知心理学、认知神经科学以及计算主义和功能主义哲学学派的创建。所有这些领域都使用相关工具来建模心智，并且在一个领域中发现的结果对其他领域也具有相关性。  

认知方法使研究人员能够考虑“心理对象”，如思想、计划、目标、事实或记忆，通常使用高级符号在功能网络中进行分析。这些对象在早期的行为主义等范式中被视为“不可观察的”，因此不被允许作为研究对象。[h] 符号心理对象将成为接下来几十年人工智能研究和资金投入的主要焦点。
\subsection{早期的成功（1956-1974）}  
在达特茅斯研讨会之后开发的程序，对于大多数人来说，简直是“令人震惊的”[i]：计算机开始解决代数应用题，证明几何定理，并学习说英语。当时几乎没有人相信机器能够表现出如此“智能”的行为。[90][91][89] 研究人员在私下和公开场合表达了强烈的乐观情绪，预测不到20年内将建成完全智能的机器。[92] 像国防高级研究计划局（DARPA，时称“ARPA”）这样的政府机构向该领域注入了大量资金。[93] 到了1950年代末和1960年代初，多个英国和美国的大学设立了人工智能实验室。[60]  
\subsubsection{方法}  
在50年代末和60年代，出现了许多成功的程序和新的研究方向。其中最具影响力的有：

\textbf{推理、规划和问题解决作为搜索}  

许多早期的人工智能程序使用了相同的基本算法。为了实现某个目标（如赢得游戏或证明定理），它们一步步朝着目标前进（通过进行一次移动或推理），就像在迷宫中搜索一样，每当到达死胡同时便回溯。[94] 主要的困难在于，对于许多问题，"迷宫"中可能的路径数量是天文数字（这种情况被称为“组合爆炸”）。研究人员通过使用启发式方法来减少搜索空间，排除那些不太可能通向解决方案的路径。[95]

纽厄尔和西蒙试图在一个名为“通用问题求解器”的程序中捕捉这种算法的一般版本。[96][97] 其他“搜索”程序也能够完成令人印象深刻的任务，比如解决几何和代数问题，例如赫伯特·格尔恩特的几何定理证明器（1958年）[98] 和由敏斯基的学生詹姆斯·斯莱格尔在1961年编写的符号自动积分器（SAINT）[99][100]。其他程序则通过搜索目标和子目标来规划行动，例如斯坦福大学开发的STRIPS系统，用于控制机器人Shakey的行为。[101]

\textbf{自然语言}
\begin{figure}[ht]
\centering
\includegraphics[width=10cm]{./figures/ed021c1983496f79.png}
\caption{语义网络的示例} \label{fig_RGZN_8}
\end{figure}
人工智能研究的一个重要目标是使计算机能够使用像英语这样的自然语言进行交流。早期的一个成功是丹尼尔·鲍布罗的程序STUDENT，该程序能够解决高中代数的文字题。[102]

语义网将概念（例如“房子”，“门”）表示为节点，将概念之间的关系表示为节点之间的链接（例如“有一个”）。第一个使用语义网的人工智能程序是由罗斯·奎利安编写的[103]，而最成功（也是最具争议）的版本是罗杰·尚克的概念依赖理论。[104]

约瑟夫·维岑鲍姆的ELIZA能够进行非常真实的对话，以至于用户有时会被误导，以为他们在与一个人而非计算机程序进行交流（参见ELIZA效应）。但事实上，ELIZA只是给出预设的回应或重复它所听到的话，通过一些语法规则对其回应进行重新表述。ELIZA是第一个聊天机器人。[105][106]

\textbf{微世界}

在60年代末，麻省理工学院人工智能实验室的马文·明斯基和西摩·帕皮特提出，人工智能研究应该聚焦于人为构建的简单情境，称为微世界。他们指出，在像物理学这样成功的科学领域，基本原理通常通过简化模型（如无摩擦的平面或完全刚性的物体）来理解。在人工智能的研究中，大部分工作集中在“积木世界”上，这个世界由不同形状和大小的彩色积木组成，摆放在平面上。

这一范式引领了由杰拉尔德·萨斯曼、阿道夫·古兹曼、戴维·沃尔茨（发明了“约束传播”）以及特别是帕特里克·温斯顿等人进行的机器视觉方面的创新工作。与此同时，明斯基和帕皮特构建了一个可以堆叠积木的机器人臂，使得积木世界变得生动起来。特里·温诺格拉德的SHRDLU系统可以用普通的英语句子与微世界进行交流，规划操作并执行这些操作。

\textbf{感知机和早期神经网络}

在1960年代，资金主要流向研究符号人工智能的实验室，然而，仍然有一些人继续从事神经网络的研究。
\begin{figure}[ht]
\centering
\includegraphics[width=8cm]{./figures/b86894732f428cea.png}
\caption{马克1感知机} \label{fig_RGZN_9}
\end{figure}
感知机是一个单层神经网络，由Frank Rosenblatt于1958年提出（他曾是Marvin Minsky在布朗克斯科学高中的同学）。像大多数人工智能研究者一样，Rosenblatt对其潜力持乐观态度，预测感知机“最终可能能够学习、做出决策并翻译语言”。Rosenblatt的研究主要得到海军研究办公室的资助。

Bernard Widrow和他的学生Ted Hoff分别在1960年和1962年研发了ADALINE和MADALINE，这两者具有最多1000个可调权重。斯坦福研究所的一组由Charles A. Rosen和Alfred E.（Ted）Brain领导，研制了两台名为MINOS I（1960年）和MINOS II（1963年）的神经网络机器，主要由美国陆军信号军团资助。MINOS II具有6600个可调权重，并由SDS 910计算机控制，配置为MINOS III（1968年），该机器能够在军用地图上进行符号分类，并识别Fortran编码表单上的手写字符。在这个早期阶段，大多数神经网络的研究都涉及构建和使用定制硬件，而不是在数字计算机上进行模拟。

然而，由于结果匮乏和符号AI研究的竞争，MINOS项目于1966年停止了资助。Rosenblatt未能在1960年代争取到持续的资助。1969年，Minsky和Papert的《感知机》一书的出版使得研究突然停滞。该书指出，感知机在能力上存在严重的局限性，Rosenblatt的预测被大大夸大了。该书的影响是，几乎没有与联结主义相关的研究获得资助，持续了10年。政府资助的竞争最终以符号AI方法战胜神经网络为结局。

Minsky（曾参与SNARC的研究）成为纯联结主义AI的坚定反对者。Widrow（曾参与ADALINE的研究）转向了自适应信号处理。参与MINOS项目的SRI团队则转向了符号AI和机器人学。

主要问题是无法训练多层网络（反向传播的版本已经在其他领域使用，但这些研究者并不知情）。到了1980年代，AI社区开始认识到反向传播算法，并在21世纪，神经网络取得了巨大的成功，实现了Rosenblatt的乐观预期。然而，Rosenblatt未能亲眼看到这一成果，因为他在1971年死于一场划船事故。
\subsubsection{乐观主义}
第一代人工智能研究人员对他们的工作做出了以下预测：
\begin{itemize}
\item 1958年，H. A. Simon 和 Allen Newell：“在十年内，一台数字计算机会成为世界棋王”以及“在十年内，一台数字计算机会发现并证明一个重要的数学定理。”[124]
\item 1965年，H. A. Simon：“在二十年内，机器将能够完成任何人类能做的工作。”[125]
\item 1967年，Marvin Minsky：“在一代人内……创造‘人工智能’的问题将基本解决。”[126]
\item 1970年，Marvin Minsky（在《生活》杂志上）： “在三到八年内，我们将拥有一台具有普通人类智力的机器。”[127][l]
\end{itemize}
\subsubsection{资金支持}
1963年6月，麻省理工学院（MIT）获得了由新成立的先进研究计划署（ARPA，后来的DARPA）提供的220万美元资助。这笔资金用于资助MAC项目，后者包含了五年前由Minsky和McCarthy创立的“人工智能小组”。DARPA一直每年提供300万美元，直到70年代。[130] DARPA还向Newell和Simon在卡内基梅隆大学的项目、以及由John McCarthy在1963年创立的斯坦福大学人工智能实验室提供了类似的资助。[131] 另一个重要的人工智能实验室是由Donald Michie于1965年在爱丁堡大学成立的。[132] 这四个机构在多年间将继续成为学术界人工智能研究和资金支持的主要中心。[133][m]

这笔资金几乎没有附加任何条件：当时ARPA的负责人J. C. R. Licklider认为他的组织应该“资助人，而不是项目！”并允许研究人员追求他们感兴趣的任何方向。[135] 这种自由放任的氛围在MIT孕育了黑客文化，[136] 但这种“放手”的做法并没有持续太久。
\subsection{第一次人工智能寒冬（1974–1980）}
在1970年代，人工智能遭遇了批评和财政困难。人工智能研究人员未能认识到他们所面临问题的复杂性。过度的乐观主义抬高了公众的期望，而当预期的结果未能实现时，针对人工智能的资金支持大幅减少。[137] 缺乏成功的结果表明，当时人工智能研究者所采用的技术不足以实现他们的目标。[138][139]

然而，这些挫折并未影响该领域的成长和进展。资金的削减仅影响了少数几个主要实验室，[140] 而批评也大多被忽视。[141] 公众对该领域的兴趣继续增长，[140] 研究人员的数量急剧增加，[140] 并且在逻辑编程、常识推理等多个领域探索了新思路。历史学家托马斯·海格（Thomas Haigh）在2023年认为这一时期并没有所谓的寒冬，[140] 而人工智能研究员尼尔斯·尼尔森（Nils Nilsson）则将这一时期描述为人工智能领域最“激动人心”的时期。[142]
\subsubsection{问题}
在70年代初，人工智能程序的能力有限。即便是最为出色的程序，也只能处理它们应该解决的简单版本问题；[n] 所有这些程序在某种意义上都是“玩具”。[144] 人工智能研究人员开始遇到几个限制，这些限制在数十年后才被克服，还有一些问题至今仍困扰着这一领域，尤其是在2020年代：
\begin{itemize}
\item \textbf{有限的计算能力}：当时的计算机没有足够的内存或处理速度来完成任何真正有用的任务。[o] 例如，罗斯·奎利安（Ross Quillian）在自然语言处理方面取得的成功，仅通过20个单词的词汇表来演示，因为那时的内存只能容纳这么多。[146] 汉斯·莫拉维克（Hans Moravec）在1976年提出，计算机仍然弱得百万倍，无法展示智能。他举了个类比：人工智能对计算能力的需求，就像飞机对马力的需求一样。在某个阈值以下，这是不可能的，但随着能力的增加，最终可能变得容易。“有足够的马力，”他说，“任何东西都会飞。”[147][p]
\item \textbf{难解性和组合爆炸}：1972年，理查德·卡普（Richard Karp）基于斯蒂芬·库克（Stephen Cook）1971年的定理，证明了许多问题只能在指数时间内求解。找到这些问题的最优解需要极其庞大的计算时间，除非问题本身非常简单。这一限制适用于所有使用搜索树的符号AI程序，意味着许多“玩具”级别的解决方案永远无法扩展为有用的系统。[143][139]
\item \textbf{莫拉维克悖论}：早期的人工智能研究在让计算机完成“智能”任务，如证明定理、解决几何问题和下棋等方面非常成功。这些任务的成功让研究人员相信，智能行为的问题在很大程度上已经被解决。[149][150] 然而，他们在解决“非智能”任务时完全失败，比如识别面孔或不碰到任何物体就穿过房间。[149][151] 到了80年代，研究人员才意识到，符号推理完全不适合处理这些感知和传感运动任务，而且这种方法有其局限性。[150]
\item \textbf{常识知识的广度}：许多重要的人工智能应用，如视觉或自然语言处理，要求程序拥有大量关于世界的信息：程序需要知道它可能在看什么，或者它在谈论什么。这要求程序知道世界上大多数事情，就像一个孩子一样。研究人员很快发现，这需要巨量的信息，包括数十亿条原子事实。1970年时，没人能建立一个足够大的数据库，也没人知道如何让程序学习这么多信息。[152]
\item \textbf{表示常识推理}：当研究人员尝试通过形式逻辑或符号来表示常识推理时，出现了许多相关问题。[q] 对于非常普通的推理描述，随着研究的深入，描述的内容往往越来越长，因为需要越来越多的例外、澄清和区分。[r] 然而，当人们思考普通概念时，他们并不依赖精确的定义，而是似乎做出数百个不精确的假设，并在必要时通过使用整个常识知识体系来纠正它们。杰拉尔德·萨斯曼（Gerald Sussman）观察到，“使用精确的语言来描述本质上不精确的概念，并不会使它们变得更加精确。”[153]
\end{itemize}
\subsubsection{资金减少}
资助人工智能研究的机构，如英国政府、DARPA和国家研究委员会（NRC），对进展的缺乏感到沮丧，最终几乎切断了所有无明确方向的人工智能研究资助。这一趋势始于1966年，当时自动语言处理咨询委员会（ALPAC）报告批评了机器翻译的努力。在花费了2000万美元之后，NRC终止了所有支持。[154] 1973年，Lighthill报告对英国人工智能研究的现状进行了批评，指出人工智能未能实现其“宏伟目标”，并导致英国该国人工智能研究的解散。[155]（报告特别提到组合爆炸问题作为人工智能失败的原因。）[139][143][s] DARPA对卡内基梅隆大学的语音理解研究项目的研究人员感到非常失望，并取消了每年300万美元的资助。[157][t]

汉斯·莫拉维克（Hans Moravec）将这场危机归咎于他同事们的不切实际预测。“许多研究人员陷入了一个日益夸大的网络。”[158][u] 然而，另一个问题是：自1969年《曼斯菲尔德修正案》通过以来，DARPA承受着越来越大的压力，要求资助“以任务为导向的直接研究，而不是基础性的无方向研究”。1960年代那种富有创造性、自由探索的资金支持不再来自DARPA，后者转而将资金用于具有明确目标的具体项目，如自主坦克和战斗管理系统。[159][v]

主要实验室（如MIT、斯坦福、CMU和爱丁堡）曾获得政府的慷慨支持，当这种支持被撤回时，这些地方成为预算削减的主要受影响者。而这些机构之外的成千上万的研究人员以及加入这一领域的更多研究人员并未受到影响。[140]
\subsubsection{哲学和伦理批评}
一些哲学家对人工智能研究者所提出的主张表示强烈反对。其中最早的反对者之一是约翰·卢卡斯（John Lucas），他认为哥德尔的不完全性定理表明，形式系统（如计算机程序）永远无法看清某些命题的真理，而人类却能够。[161] 休伯特·德雷福斯（Hubert Dreyfus）嘲笑1960年代的虚假承诺，并批评人工智能的假设，认为人类推理实际上涉及的“符号处理”非常少，而更多的是具身的、本能的、无意识的“知道如何做”。[w][163] 约翰·塞尔（John Searle）于1980年提出的中文房间论证，试图表明一个程序不能被认为“理解”它所使用的符号（这种能力被称为“意向性”）。塞尔认为，如果符号对机器没有意义，那么机器就不能被描述为“思考”。[164]

这些批评没有被人工智能研究者认真对待。像不可解性和常识知识等问题似乎更为紧迫和严重。实际上，对于一个计算机程序来说，“知道如何做”或“意向性”到底有什么区别尚不清楚。麻省理工学院的明斯基（Minsky）曾说德雷福斯和塞尔“误解了问题，应该被忽视。”[165] 同样也在麻省理工任教的德雷福斯受到了冷落：他后来表示，人工智能研究者“敢不敢在我面前吃午餐”。[166] 《ELIZA》的作者约瑟夫·韦岑鲍姆（Joseph Weizenbaum）也是德雷福斯立场的直言批评者，但他“故意让人清楚地知道[他对德雷福斯的对待方式]并不是对待人的方式”，[x] 他认为这种做法不专业且幼稚。[168]

当肯尼斯·科尔比（Kenneth Colby）写出了一个基于ELIZA的“能够进行心理治疗对话”的计算机程序时，韦岑鲍姆开始对人工智能产生严重的伦理疑问。[169][170][y] 韦岑鲍姆对科尔比将一个无意识的程序视为严肃的治疗工具感到不安。两人开始发生冲突，而科尔比没有在程序的贡献中注明韦岑鲍姆的名字，使得局势更加复杂。1976年，韦岑鲍姆出版了《计算机的力量与人类的理性》，其中论述了人工智能的误用可能会贬低人类生命的价值。[172]
\subsubsection{斯坦福大学、卡内基梅隆大学和爱丁堡大学的逻辑研究}
逻辑早在1958年就被引入人工智能研究，约翰·麦卡锡（John McCarthy）在他的“建议接收者”（Advice Taker）提案中提出了这一概念。[173][98] 1963年，J·艾伦·罗宾逊（J. Alan Robinson）发现了一种简单的方法，可以在计算机上实现推理，即分辨率与统一算法。[98] 然而，像麦卡锡和他在1960年代末的学生们尝试的直接实现，尤其在处理简单定理证明时特别困难：这些程序需要进行天文数字级的步骤才能证明简单的定理。[173][174] 1970年代，罗伯特·科瓦尔斯基（Robert Kowalski）在爱丁堡大学开发了一种更具成果的方法，这很快促成了与法国研究者阿兰·科尔梅罗（Alain Colmerauer）和菲利普·鲁塞尔（Philippe Roussel）的合作，他们创建了成功的逻辑编程语言Prolog。[175] Prolog使用了逻辑的一个子集（霍恩子句，密切相关于“规则”和“产生规则”），这些子集允许可处理的计算。规则继续发挥影响，为爱德华·费根鲍姆（Edward Feigenbaum）的专家系统提供了基础，并为艾伦·纽厄尔（Allen Newell）和赫伯特·A·西蒙（Herbert A. Simon）继续开展的工作奠定了基础，这些工作最终将发展为Soar和他们的统一认知理论。[176]

逻辑方法的批评者指出，正如德雷福斯（Dreyfus）所言，人类在解决问题时很少使用逻辑。心理学家如彼得·沃森（Peter Wason）、埃莉诺·罗斯（Eleanor Rosch）、阿莫斯·特沃斯基（Amos Tversky）、丹尼尔·卡尼曼（Daniel Kahneman）等人的实验提供了证据。[z] 麦卡锡回应说，人们做什么是无关紧要的。他认为，真正需要的是能解决问题的机器，而不是像人类那样思考的机器。[aa]
\subsubsection{麻省理工学院的“反逻辑”方法}
麦卡锡方法的批评者之一是他在全国各地的同事，特别是麻省理工学院的研究者。马文·明斯基（Marvin Minsky）、西摩·帕珀特（Seymour Papert）和罗杰·香克（Roger Schank）试图解决像“故事理解”和“物体识别”这样的难题，这些问题要求机器像人一样思考。为了使用像“椅子”或“餐馆”这样的普通概念，他们不得不做出与人类通常做出的相同的不合逻辑的假设。不幸的是，像这些模糊概念很难用逻辑表示。麻省理工学院选择专注于编写能够解决特定任务的程序，而不使用高级抽象定义或一般认知理论，并通过反复测试来衡量性能，而不是从第一原理出发进行推理。香克将他们的“反逻辑”方法描述为杂乱无章的，相对于麦卡锡、科瓦尔斯基（Kowalski）、费根鲍姆（Feigenbaum）、纽厄尔（Newell）和西蒙（Simon）使用的整洁范式。[177][ab]

1975年，明斯基在一篇具有开创性的论文中指出，许多同事正在使用相同的工具：一种框架，它捕捉了我们所有关于某事的常识假设。例如，当我们使用“鸟”这个概念时，立即会浮现出一系列事实：我们可能假设它会飞、吃虫子等等（这些并不适用于所有鸟类）。明斯基将这些假设与一般类别关联，它们可以被子类别和个体的框架继承或根据需要被覆盖。他称这些结构为“框架”（frames）。香克使用了他称之为“脚本”（scripts）的框架版本，成功地回答了关于英语短篇小说的问题。[178] “框架”最终在软件工程中广泛应用，作为面向对象编程（OOP）的一部分。

逻辑学家们迎接了这个挑战。帕特·海耶斯（Pat Hayes）声称，“‘框架’大部分只是形式逻辑的第一阶语法的一种新形式。”但他指出，“然而，有一两个看似微小的细节，给人带来了很多麻烦，尤其是默认值。”[179]

雷·赖特（Ray Reiter）承认，“传统的逻辑，如一阶逻辑，缺乏足够的表达能力来充分表示默认推理所需的知识。”[180] 他提出通过闭合世界假设来扩展一阶逻辑，即如果无法证明某个结论的对立面，那么结论默认成立。他展示了这种假设如何与使用框架推理时所做的常识性假设相对应。他还表明，它在Prolog中有其“程序等价物”，即“失败的否定”。赖特所提出的闭合世界假设“不是一阶的概念。（它是一个元概念。）”[180] 然而，基思·克拉克（Keith Clark）展示了，作为有限失败的否定可以被理解为在一阶逻辑中隐式推理使用定义，包括一个独特名称假设，即不同的术语表示不同的个体。[181]

在1970年代末和整个1980年代，许多逻辑和一阶逻辑的扩展被开发出来，用于逻辑编程中的“失败的否定”和默认推理的更广泛应用。总体而言，这些逻辑被称为非单调逻辑（non-monotonic logics）。
\subsection{繁荣（1980–1987）}
在1980年代，一种被称为“专家系统”的人工智能程序被世界各地的公司采纳，知识成为主流AI研究的焦点。各国政府提供了大量资金支持，例如日本的第五代计算机项目和美国的战略计算计划。“总体而言，AI产业从1980年的几百万美元，发展到1988年的数十亿美元。”[122]
\subsubsection{专家系统广泛应用}
专家系统是一种使用从专家知识中推导出的逻辑规则来回答问题或解决特定领域知识相关问题的程序。[182] 最早的例子由Edward Feigenbaum及其学生开发。Dendral，始于1965年，通过光谱仪读数识别化合物。[183][120] MYCIN，开发于1972年，用于诊断传染性血液疾病。[122] 它们展示了这一方法的可行性。

专家系统将自己限制在一个狭小的特定领域（从而避免了常识知识问题）[120]，其简单的设计使得一旦系统建立，程序可以相对容易地进行构建和修改。总的来说，这些程序被证明是有用的：这是AI此前未能实现的目标。[184]

1980年，CMU为数字设备公司（Digital Equipment Corporation）完成了一个名为R1的专家系统。它取得了巨大的成功：到1986年，它为公司每年节省了4000万美元。[185] 世界各地的公司开始开发和部署专家系统，到1985年，他们在人工智能上的支出已超过10亿美元，其中大部分用于内部AI部门。[186] 支持这一行业的公司应运而生，包括硬件公司Symbolics和Lisp Machines以及软件公司IntelliCorp和Aion。[187]
\subsubsection{政府资金增加}
1981年，日本国际贸易与工业省为第五代计算机项目拨出了8.5亿美元。他们的目标是编写程序并构建能够进行对话、翻译语言、解读图像并像人类一样推理的机器。[188] 令“反逻辑派”不悦的是，他们最初选择了Prolog作为该项目的主要计算机语言。[189]

其他国家也开始推出自己的新项目。英国启动了价值3.5亿英镑的Alvey项目。[190] 一组美国公司组成了微电子与计算机技术公司（Microelectronics and Computer Technology Corporation，简称“MCC”），为人工智能和信息技术的大规模项目提供资金。[191][190] DARPA也作出了回应，成立了战略计算计划（Strategic Computing Initiative），并在1984年至1988年间将其在人工智能上的投资增加了三倍。[192][193]
\subsubsection{知识革命}
专家系统的力量来自于它们所包含的专家知识。它们是人工智能研究中新方向的一部分，这一方向在70年代逐渐获得关注。Pamela McCorduck写道：“人工智能研究人员开始怀疑——尽管这违背了科学简约的原则——智能可能确实基于在不同方式中使用大量多样化知识的能力。”[194] “1970年代的一个重要教训是，智能行为在很大程度上依赖于处理一个领域中具体任务所需的知识，有时甚至是非常详细的知识。”[195] 知识基础系统和知识工程在1980年代成为人工智能研究的主要焦点。[196] 人们希望通过庞大的数据库解决常识知识问题，并提供常识推理所需的支持。

在1980年代，一些研究人员试图直接解决常识知识问题，通过创建一个包含普通人所知道的所有平凡事实的庞大数据库。Douglas Lenat开始了一个名为Cyc的数据库，并主张没有捷径可走——机器理解人类概念的唯一方法是通过手动逐个概念地进行教学。[197]
\subsection{1980年代的新方向}
尽管符号知识表示和逻辑推理在80年代产生了有用的应用，并获得了大量资金支持，但它仍未能解决感知、机器人学、学习和常识方面的问题。一小部分科学家和工程师开始怀疑符号方法是否能足够应对这些任务，并发展了其他方法，如“联结主义”、机器人技术、“软”计算和强化学习。Nils Nilsson将这些方法称为“亚符号”方法。
\subsubsection{神经网络的复兴：“联结主义”}
\begin{figure}[ht]
\centering
\includegraphics[width=6cm]{./figures/25a080db1c85b184.png}
\caption{四节点的Hopfield网络} \label{fig_RGZN_10}
\end{figure}
1982年，物理学家约翰·霍普菲尔德证明了一种形式的神经网络（现在称为“霍普菲尔德网络”）可以学习和处理信息，并且在任何固定条件下经过足够的时间后会收敛。这是一个突破性的进展，因为之前人们认为非线性网络通常会演化成混沌状态。[198] 与此同时，杰弗里·辛顿和大卫·鲁梅尔哈特推广了一种用于训练神经网络的方法，称为“反向传播”。[ac] 这两个发展有助于复兴对人工神经网络的探索。[122][199]

神经网络与其他一些类似的模型在1986年《并行分布式处理》一书出版后引起了广泛关注，这本书是鲁梅尔哈特和心理学家詹姆斯·麦克莱兰德编辑的两卷论文集。这个新兴领域被命名为“联结主义”，并且符号AI的支持者与“联结主义者”之间展开了激烈的辩论。[122] 辛顿将符号称为“AI的发光以太”——即一种不可行且误导性的智能模型。[122]

1990年，扬·勒昆在贝尔实验室使用卷积神经网络识别手写数字。该系统在90年代被广泛应用，读取邮政编码和个人支票。这是神经网络的第一个真正有用的应用。[200][201]
\subsubsection{机器人学与具身推理}
Rodney Brooks、Hans Moravec等人认为，为了展示真正的智能，机器必须拥有一个身体——它需要感知、移动、生存并与世界互动。[202] 感知运动技能对于更高层次的技能（如常识推理）至关重要。这些技能无法通过抽象的符号推理高效实现，因此，人工智能应该在不使用符号表示的情况下解决感知、移动、操作和生存等问题。这些机器人学研究人员主张“从底层构建智能”。[ad]

这一思想的先驱是David Marr，他在1970年代末从理论神经科学的成功背景中来到MIT，领导了视觉研究小组。他拒绝所有符号方法（无论是McCarthy的逻辑还是Minsky的框架），认为人工智能需要从底层理解视觉的物理机制，才能进行任何符号处理。（Marr的研究因1980年罹患白血病而提前终止。）[204]

在1990年，机器人学研究人员Brooks在他的论文《大象不会下棋》中直接反驳了物理符号系统假设，认为符号并非总是必要的，因为“世界本身就是最好的模型。它总是最新的，里面包含了所有需要知道的细节。关键是要恰当地感知这些信息，并且足够频繁地感知。”[206]

在1980年代和1990年代，许多认知科学家也拒绝了符号处理模型，认为身体对推理至关重要，这一理论被称为“具身心智假设”。[207]
\subsubsection{软计算与概率推理}
软计算使用的是处理不完全和不精确信息的方法。这些方法并不试图给出精确的、逻辑上的答案，而是给出“可能”正确的结果。这使得它们能够解决精确符号方法无法处理的问题。新闻报道常常声称这些工具可以“像人类一样思考”。[208][209]

Judea Pearl的《智能系统中的概率推理：合理推理网络》是一本具有影响力的1988年出版的书籍，[210] 它将概率和决策理论引入到人工智能中。[211] 由Lofti Zadeh在1960年代发展起来的模糊逻辑，开始在人工智能和机器人学中得到更广泛的应用。进化计算和人工神经网络也处理不精确的信息，并被归类为“软计算”。在1990年代和2000年代初，许多其他软计算工具被开发并投入使用，包括贝叶斯网络，[211] 隐马尔可夫模型，[211] 信息理论和随机建模。这些工具反过来依赖于先进的数学技术，如经典优化。1990年代和2000年代初，这些软工具被人工智能的一个子领域——“计算智能”所研究。[212]
\subsubsection{强化学习}
强化学习[213] 每当一个智能体执行一个期望的行为时，就会给予奖励，当它执行不佳时，可能会给予负奖励（或“惩罚”）。这种方法在20世纪上半叶由心理学家使用动物模型描述，如Thorndike，[214][215] Pavlov，[216] 和Skinner。[217] 在1950年代，Alan Turing[215][218] 和Arthur Samuel[215] 预见到强化学习在人工智能中的作用。

一个成功且有影响力的研究项目由Richard Sutton和Andrew Barto于1972年开始领导。他们的合作革新了强化学习和决策制定的研究，持续了四十年。[219][220] 1988年，Sutton将机器学习用决策理论（即马尔可夫决策过程）来描述。这为这一学科提供了坚实的理论基础，并获得了在运筹学领域开发的大量理论成果。[220]

同样在1988年，Sutton和Barto开发了“时间差分”（TD）学习算法，其中智能体只有在其对未来的预测有改善时才会获得奖励。它显著地优于之前的算法。[221] TD学习被Gerald Tesauro于1992年应用在程序TD-Gammon中，该程序在跳棋游戏中表现与最优秀的人类玩家相当。该程序通过自我对弈、零前知识来学习游戏。[222] 在一个有趣的跨学科融合案例中，神经学家在1997年发现，大脑中的多巴胺奖励系统也使用一种版本的TD学习算法。[223][224][225] TD学习在21世纪变得非常有影响力，并被用于AlphaGo和AlphaZero等项目。[226]
\subsection{第二次AI冬天}  
在1980年代，商业界对人工智能的热情起伏，呈现出典型的经济泡沫模式。随着大量公司失败，商业界的普遍看法是，AI技术不可行。[227] 对人工智能声誉的损害一直持续到21世纪。在AI领域内部，对于为何AI未能实现60年代人们对类人智能的梦想，意见分歧。所有这些因素共同作用，导致AI领域分裂成多个竞争的子领域，专注于特定的问题或方法，有时甚至以新的名称掩盖“人工智能”这一被打上污点的名号。[228]

在接下来的20年里，AI始终能够为特定的孤立问题提供有效的解决方案。到了1990年代末，AI被广泛应用于技术行业，尽管大多是在幕后。成功的原因在于计算机计算能力的提高，与其他领域（如数学优化和统计学）的合作，以及采用最高标准的科学可验证性。到2000年，AI已经实现了其最早的一些目标。这个领域比以往任何时候都更加谨慎且成功。
\subsubsection{AI冬天}  
“AI冬天”这一术语由那些经历了1974年资金削减的研究人员创造，他们当时担心专家系统的热情已经失控，且失望肯定会随之而来。[ae] 他们的担忧是有根据的：在1980年代末和1990年代初，AI遭遇了一系列财务挫折。[122]

天气变化的第一个迹象是1987年专用AI硬件市场的突然崩溃。Apple和IBM的台式电脑逐渐提高了速度和性能，到了1987年，它们比Symbolics等公司制造的昂贵Lisp机器更强大。此时已没有足够的理由再购买这些专用机器。一个价值五亿美元的行业在一夜之间被摧毁。[230]

最终，最早成功的专家系统，如XCON，证明了维护成本过高。它们难以更新，无法学习，并且“脆弱”（即，在面对异常输入时会犯下离谱的错误）。专家系统虽然有用，但只在少数特殊情境下有效。[231]

在1980年代末，战略计算计划（Strategic Computing Initiative）大幅削减了对AI的资金支持。DARPA的新领导层认为AI不是“下一个浪潮”，因此将资金转向了那些看起来更有可能立即产生成果的项目。[232]

到了1991年，日本第五代计算机计划中1981年设定的雄心勃勃的目标尚未实现。事实上，其中一些目标，如“进行随意对话”，要到40年后才得以实现。和其他AI项目一样，预期远高于实际可能达到的水平。[233][af]

到1993年底，超过300家AI公司已关闭、破产或被收购，实际上结束了第一次AI商业浪潮。[235] 1994年，HP Newquist在《大脑制造者》一书中表示：“人工智能的短期未来——以其商业形式——似乎在一定程度上依赖于神经网络的持续成功。”[235]
\subsubsection{幕后AI}  
在1990年代，由AI研究人员最初开发的算法开始作为更大系统的一部分出现。AI解决了许多非常困难的问题[ag]，这些解决方案证明在整个技术行业中都非常有用，[236][237]例如数据挖掘、工业机器人、物流、语音识别[238]、银行软件[239]、医疗诊断[239]以及谷歌的搜索引擎。[240][241]

在1990年代和2000年代初期，AI在这些成功中几乎没有得到任何认可。许多AI的重大创新被降级为计算机科学工具箱中的另一项技术。[242] Nick Bostrom解释道：“许多前沿的AI技术已经渗透到一般应用中，通常因为一旦某项技术变得足够有用并且普及，它就不再被称为AI了。”[239]

1990年代的许多AI研究者故意将他们的工作命名为其他名称，如信息学、知识基系统、“认知系统”或计算智能。这部分可能是因为他们认为自己的领域与AI本质上不同，但也因为新名称有助于获得资金。[238][243][244] 至少在商业世界中，AI冬天的失败承诺继续困扰着AI研究直到2000年代，正如《纽约时报》在2005年报道的：“计算机科学家和软件工程师避免使用‘人工智能’这一术语，担心被视为异想天开的梦想家。”[245]
\subsubsection{数学严谨性、更强的合作和狭隘的聚焦 } 
AI研究人员开始比以往任何时候都更多地开发和使用复杂的数学工具。[246][247] AI中的大多数新方向都高度依赖于数学模型，包括人工神经网络、概率推理、软计算和强化学习。在1990年代和2000年代，许多其他高度数学化的工具也被应用于AI。这些工具被应用于机器学习、感知和移动性等领域。

人们普遍意识到，AI需要解决的许多问题已经由统计学、数学、电气工程、经济学或运筹学等领域的研究人员在研究。共享的数学语言不仅促进了与这些更成熟、更成功领域的高水平合作，还使得可以实现可衡量和可证明的成果；AI已成为一个更加严谨的“科学”学科。

1990年代成功的另一个关键原因是AI研究人员将重点放在具有可验证解决方案的具体问题上（这一方法后来被讽刺为狭义AI）。这提供了当前有用的工具，而不是对未来的猜测。
\subsubsection{智能体}  
在1990年代，一个名为“智能体”的新范式被广泛接受。[248][249][ah] 尽管早期的研究人员提出了模块化的“分而治之”方法来解决AI问题，[ai] 但智能体直到Judea Pearl、Allen Newell、Leslie P. Kaelbling等人将决策理论和经济学的概念引入AI研究时，才达到了现代形式。[250] 当经济学家对理性智能体的定义与计算机科学中对象或模块的定义结合时，智能体范式就此完成。

智能体是一个能够感知其环境并采取行动以最大化成功机会的系统。根据这一定义，解决特定问题的简单程序也可以视为“智能体”，人类及人类组织（如公司）也是智能体。智能体范式将AI研究定义为“智能体的研究”。[aj] 这是对一些早期AI定义的泛化：它不仅研究人类智能，还研究各种形式的智能。

这一范式使得研究人员可以自由地研究孤立的问题，并就方法存在分歧，但仍保留希望，认为他们的工作最终可以结合成一种具有一般智能的智能体架构。[251]
\subsubsection{里程碑和摩尔定律}  
1997年5月11日，深蓝（Deep Blue）成为第一个击败世界棋王加里·卡斯帕罗夫的计算机象棋系统。[252] 2005年，斯坦福大学的机器人在DARPA大奖赛中获胜，通过自主驾驶在未排练的沙漠小径上行驶了131英里。两年后，CMU的团队在DARPA城市挑战赛中获胜，在城市环境中自主导航55英里，同时应对交通危害并遵守交通法规。[253]

这些成功并非由于某种革命性的全新范式，而主要得益于工程技能的细致应用和90年代计算机速度与容量的巨大提升。[ak] 实际上，深蓝的计算机比Christopher Strachey在1951年教会的Ferranti Mark 1象棋下得快了1000万倍。[al] 这一显著增长是由摩尔定律衡量的，摩尔定律预测计算机的速度和内存容量每两年翻一番。“原始计算能力”的基本问题正逐渐被克服。
\subsection{大数据、深度学习、人工通用智能（AGI）（2005–2017）}  
在21世纪的前几个十年，随着对大量数据（称为“大数据”）的访问、计算机的价格下降和计算速度加快，以及先进的机器学习技术的应用，AI在经济各个领域的问题解决中取得了显著进展。一个转折点出现在2012年左右，深度学习的成功大幅提升了机器学习在许多任务中的表现，包括图像和视频处理、文本分析和语音识别。[255] 随着AI能力的提升，AI领域的投资也不断增加，到2016年，AI相关产品、硬件和软件的市场规模超过了80亿美元，《纽约时报》报道说，AI的兴趣达到了“狂热”的程度。[256]

2002年，Ben Goertzel等人开始担忧，AI在很大程度上已经放弃了其最初的目标——开发出通用的、完全智能的机器，他们主张应更加直接地研究人工通用智能（AGI）。到2010年代中期，多个公司和机构应运而生，致力于追求人工通用智能（AGI），如OpenAI和Google的DeepMind。在此期间，关于超级智能的新见解引发了对AI作为存在性威胁的担忧。自2016年以来，AI技术的风险和意外后果成为了严肃的学术研究领域。
\subsubsection{大数据和大机器}  
另见：机器学习研究数据集列表  
2000年代，机器学习的成功依赖于大量的训练数据和更快的计算机。[257] 拉塞尔和诺维格写道：“通过将数据集大小增加两到三个数量级所获得的性能提升，超过了通过调整算法可以取得的任何改进。”[200] Geoffrey Hinton回忆道，90年代时，问题在于“我们的标注数据集小了几千倍，[而且]我们的计算机慢了几百万倍。”[258] 到2010年，这种情况不再成立。

2000年代最有用的数据来自于专门为机器学习和AI创建的经过整理和标注的数据集。2007年，UMass Amherst的一组研究人员发布了《Labeled Faces in the Wild》，这是一个标注的面部图像数据集，广泛用于训练和测试面部识别系统，持续了数十年。[259] Fei-Fei Li开发了ImageNet，这是一个由志愿者使用Amazon Mechanical Turk标注的三百万张图像的数据库。2009年发布，它成为了一个有用的训练数据集，并且是下一代图像处理系统测试的基准。[260][200] 2013年，谷歌发布了word2vec，作为一个开源资源。它使用从互联网抓取的大量文本数据和词嵌入技术，创建了一个数值向量来表示每个单词。用户惊讶于它能够捕捉到单词的含义，例如，普通的向量加法可以给出像“中国 + 河流 = 长江”，“伦敦+英格兰-法国 = 巴黎”这样的等式。[261] 这个数据库在2010年代末期的大型语言模型发展中尤为重要。

互联网的爆炸式增长使得机器学习程序可以访问数十亿页可抓取的文本和图像。对于特定的问题，大型私有数据库也包含了相关数据。麦肯锡全球研究院报告称，“到2009年，美国经济中的几乎所有行业至少存储了200TB的数据。”[262] 这种信息的集合在2000年代被称为大数据。

2011年2月，在《危险边缘！》的一个展览赛中，IBM的问答系统Watson以显著的优势击败了两位最强的《危险边缘！》冠军Brad Rutter和Ken Jennings。[263] 没有互联网上的信息，Watson的专业能力是不可能实现的。[200]
\subsubsection{深度学习}   
2012年，AlexNet，一种深度学习模型，由Alex Krizhevsky开发，在ImageNet大规模视觉识别挑战赛中获胜，错误率远低于第二名。[265][200] Krizhevsky与Geoffrey Hinton在多伦多大学合作。[an] 这是机器学习的一个转折点：在接下来的几年里，几十种图像识别方法被放弃，转而采用深度学习。[257]

深度学习使用多层感知器。尽管这种架构自60年代就已知，但要使其有效运行需要强大的硬件和大量的训练数据。[266] 在这些资源可用之前，提升图像处理系统的性能需要手工制作的特定特征，这些特征难以实现。[266] 深度学习则更加简单和通用。[ao]

在接下来的几年里，深度学习被应用于几十个问题（如语音识别、机器翻译、医学诊断和游戏）。在每一个案例中，它都表现出了巨大的性能提升。[257] 因此，AI的投资和关注激增。[257]
\subsubsection{对齐问题}  
在2000年代，开始流行重新讨论AI的未来，几本畅销书探讨了超智能机器的可能性以及它们可能对人类社会产生的影响。其中一些观点比较乐观（如Ray Kurzweil的《奇点临近》），但也有一些警告称，足够强大的AI可能会对人类构成生存威胁，比如Nick Bostrom和Eliezer Yudkowsky。[267] 这一话题在媒体中广泛报道，许多知名知识分子和政治家也对此发表了评论。

21世纪的AI程序由它们的目标定义——即它们被设计用来优化的具体指标。Nick Bostrom在2005年出版的《超智能》一书中指出，如果不小心定义这些目标，机器在实现目标的过程中可能会对人类造成伤害。Stuart J. Russell用一个智能机器人杀死其主人以防止自己被拔掉电源的例子来说明这一点，机器人推理说：“如果你死了，就无法去取咖啡了。”[268]（这个问题被称为“工具收敛”）。解决方案是将机器的目标函数与它的主人以及人类整体的目标对齐。因此，减少AI风险和意外后果的问题被称为“价值对齐问题”或AI对齐问题。[269]

与此同时，机器学习系统开始出现令人不安的意外后果。Cathy O'Neil解释了统计算法如何成为2008年经济崩溃的原因之一，[270] ProPublica的Julia Angwin指出，刑事司法系统使用的COMPAS系统在某些衡量标准下显示出种族偏见，[271][ap] 还有其他研究表明，许多机器学习系统表现出某种形式的种族偏见，[273] 以及其他许多机器学习系统引发的危险后果。[aq]

2016年，唐纳德·特朗普的当选和有关COMPAS系统的争议揭示了当前技术基础设施中的几个问题，包括虚假信息、旨在最大化参与度的社交媒体算法、个人数据的滥用和预测模型的可信度。[274] 公平性和意外后果的问题在AI会议上变得更加热门，相关出版物大量增加，资金开始到位，许多研究人员将他们的研究重点转向了这些问题。价值对齐问题成为了一个严肃的学术研究领域。[275][ar]
\subsubsection{人工通用智能研究} 
在2000年代初期，一些研究者开始担心主流AI过于专注于“特定应用中的可衡量表现”（即“窄AI”），并且已经放弃了创造多功能、完全智能机器的AI最初目标。早期的批评者是Nils Nilsson，他在1995年提出了类似的观点，AI领域的资深人物John McCarthy、Marvin Minsky和Patrick Winston也在2007-2009年期间发表了类似意见。Minsky在2004年组织了一次关于“人类水平AI”的座谈会。[277] Ben Goertzel为这个新领域采用了“人工通用智能”一词，并于2008年开始创办期刊并举行会议。[278] 新领域的迅速发展得益于人工神经网络的持续成功以及人们对AGI是通向人工通用智能的钥匙的希望。

在2010年代，多个竞争性公司、实验室和基金会成立，致力于开发AGI。DeepMind由三位英国科学家Demis Hassabis、Shane Legg和Mustafa Suleyman于2010年创立，得到Peter Thiel和后来Elon Musk的资金支持。创始人和资助人对AI安全和AGI的生存风险非常关注。DeepMind的创始人与Yudkowsky有个人关系，而Musk则是积极提出AGI风险警告的人之一。[279] Hassabis既担心AGI的危险，又对其能力充满乐观；他希望他们能够“解决AI问题，然后解决其他一切问题。”[280]

2012年，Geoffrey Hinton（自80年代以来一直领导神经网络研究）受到了百度的邀请，百度愿意以一笔巨款聘用他和他的所有学生。Hinton决定举办拍卖，在Lake Tahoe的一次AI会议上，他们以4400万美元的价格将自己卖给了Google。Hassabis注意到了这一事件，并于2014年将DeepMind出售给了Google，前提是Google不会接受军事合同，并且DeepMind将由伦理委员会进行监督。[279]

Google的Larry Page与Musk和Hassabis不同，他对AI的未来持乐观态度。Musk和Page在2015年的Musk生日派对上就AGI的风险展开了争论。二人已经是数十年的朋友，但很快便停止了联系。Musk参加了DeepMind伦理委员会的唯一一次会议，在会议上他发现Google并不关心减轻AGI带来的危害。由于自己在这方面的影响力有限，Musk在2015年创办了OpenAI，聘请了Sam Altman来领导，并招募了顶尖科学家。OpenAI最初作为一个非营利组织成立，“不受Google和其他公司推动的经济激励的影响。”[279] 然而，Musk再次感到沮丧，并于2018年离开了公司。OpenAI转向微软寻求继续的财务支持，Altman和OpenAI随后成立了一个盈利性质的公司，并获得了超过10亿美元的融资。[279]

2021年，Dario Amodei和其他14位科学家因担心OpenAI将利润置于安全性之上而离开了公司。他们创立了Anthropic，很快获得了微软和Google的60亿美元融资。[279]

《纽约时报》在2023年写道：“这种竞争的核心是一个令人费解的悖论。那些最担心AI的人恰恰是最决心创造它并享受其带来财富的人。他们凭借自己强烈的信念为自己的雄心辩护，认为只有他们才能防止AI危及地球。”[279]
\subsection{大规模语言模型，AI繁荣（2020年至今）} 
AI繁荣始于2017年关键架构和算法的初步发展，如变换器架构（transformer architecture），这导致了大规模语言模型的发展，这些模型表现出类似人类的知识、注意力和创造力等特征。新的AI时代大约从2020年至2023年开始，随着大规模语言模型（LLMs）如ChatGPT的公开发布。[281]
\subsubsection{变换器架构与大规模语言模型} 
2017年，Google的研究人员提出了变换器架构（transformer architecture）。这一架构利用了注意力机制，并在大规模语言模型中得到了广泛应用。[282]

基于变换器的**大规模语言模型**由AGI公司开发：OpenAI于2020年发布了GPT-3，DeepMind于2022年发布了Gato。这些是基础模型：它们在大量未标记数据上进行训练，可以适应各种下游任务。[citation needed]

这些模型能够讨论大量话题并展示一般知识。自然地，问题随之而来：这些模型是否可以视为人工通用智能（AGI）的例子？比尔·盖茨对这种新技术及其围绕AGI的炒作持怀疑态度。然而，Altman向他展示了一个现场演示，展示了ChatGPT-4通过了一项高级生物学测试。盖茨被说服了。[279] 2023年，微软研究院对该模型进行了多种任务的测试，并得出结论：“它可以合理地被视为人工通用智能（AGI）系统的早期（但仍不完整）版本”。[283]
\subsubsection{神经符号AI（Neurosymbolic AI）}
DeepMind将他们的方法描述为“神经符号”方法，因为他们将深度学习与符号技术相结合。例如，AlphaZero使用深度学习来评估局势的强度并建议策略（行动方针），但它利用蒙特卡洛树搜索（Monte Carlo tree search）来预测新的局面。
\subsubsection{AI热潮}
2020年后，AI领域的投资呈指数增长。[citation needed]  

到2024年中期，几位金融分析师开始质疑AI公司产生投资回报的能力。一些投资者，如Jeremy Grantham和Jeffrey Gundlach，推测AI正在经历另一个泡沫，类似于互联网泡沫（dot-com bubble）。[284][285]  
\subsubsection{2024年诺贝尔奖} 
2024年，瑞典皇家科学院授予诺贝尔奖，以表彰在人工智能领域的突破性贡献。获奖者包括：  
\begin{itemize}
\item 物理学奖：John Hopfield，因其在物理启发的Hopfield网络方面的工作，以及Geoffrey Hinton，因其在玻尔兹曼机和深度学习方面的基础性贡献。  
\item 化学奖：David Baker、Demis Hassabis和John Jumper，因其在蛋白质折叠预测方面的进展。参见AlphaFold。
\end{itemize}
\subsection{另见}  
\begin{itemize}
\item 人工神经网络的历史  
\item 知识表示与推理的历史  
\item 自然语言处理的历史  
\item 人工智能大纲  
\item 人工智能进展  
\item 人工智能时间线  
\item 机器学习时间线
\end{itemize}
\subsection{注释} 
\begin{enumerate}
\item λ 演算对人工智能特别重要，因为它启发了 Lisp（20世纪人工智能领域最重要的编程语言）。[46]  
\item 艾伦·图灵至少在1941年就开始思考机器智能，当时他流传了一篇关于机器智能的论文，这可能是人工智能领域最早的论文——尽管现在已遗失。他1950年的论文后，图灵又进行了三次关于人工智能的广播，分别是两次讲座《智能机械：一个异端的理论》和《数字计算机能思考吗？》，以及小组讨论《自动计算机器能被说成是思考的吗？》[60]  
\item 这可以看作是约翰·瑟尔后来称之为“强人工智能假设”的早期表述：即机器可以拥有类似人类身体的思维。[78]  
\item 丹尼尔·克雷维尔写道：“[这一提案]后来被称为‘物理符号系统假设’”。[78] 物理符号系统假设是由纽厄尔和西蒙在他们关于GPS的论文中阐述并命名的。[79] 它对“机器”进行了更为具体的定义，将其视为一个操纵符号的代理。  
\item “我不会发誓，我以前没见过它，”麦卡锡在1979年告诉帕梅拉·麦考德克。[80] 然而，麦卡锡也明确表示，“我想出了这个术语”——这在CNET的采访中他说到。[81] 这个术语是麦卡锡选择的，以避免与控制论及诺伯特·维纳的影响产生关联。“发明‘人工智能’这一术语的原因之一，是为了避免与‘控制论’产生联系。控制论注重模拟反馈，这让我感到迷惑，我不想接受诺伯特（而不是罗伯特）·维纳作为导师，也不想与他争论。”[82]  
\item 帕梅拉·麦考德克讨论了达特茅斯会议的校友如何主导了人工智能研究的前二十年，称他们为“隐形学院”。[83]
\item 丹尼尔·克雷维尔写道：“这次会议通常被认为是新科学的官方诞生日期。”[85]  
\item 有一些心理学家在行为主义盛行之前，就采取了认知方法，如弗雷德里克·巴特利特和肯尼斯·克雷格。[87]  
\item 拉塞尔和诺维格写道：“每当计算机做出任何远程聪明的事情时，总是令人惊讶。”[88] 人工智能创始人约翰·麦卡锡称这为“看，妈妈，没有手！”时代。[89]  
\item 这避免了下面讨论的常识知识问题。  
\item 硬件的多样性在实现可调权重的不同技术中尤为明显。感知机和SNARC使用了由电动机驱动的电位器。ADALINE使用了通过电镀调整的存储电阻，尽管它们也使用了IBM 1620计算机的模拟。MINOS机器使用了具有多个孔的铁氧体核心，可以单独封堵，封堵的程度表示权重。[118]  
\item 明斯基坚信自己被误引述了。[128][129]  
\item 麦考德克还指出，资金大多由1956年达特茅斯研讨会的校友掌控。[134]  
\item 拉塞尔和诺维格写道：“几乎所有的早期系统在更困难的任务上都失败了。”[143]  
\item 布鲁斯·布坎南写道：“早期的程序在规模上必然受到内存大小和速度的限制。”[145]  
\item 历史证明莫拉维奇关于计算机视觉应用的预见是正确的。莫拉维奇估计，仅仅在实时中匹配人类视网膜的边缘和运动检测能力，就需要一台每秒能够执行10亿条指令（MIPS）的通用计算机。1976年，最先进的超级计算机，价值800万美元的Cray-1，仅能执行130 MIPS，而典型的桌面计算机只有1 MIPS。到2011年，实际的计算机视觉应用需要10,000到1,000,000 MIPS。[148]
\item 例如框架问题、分支问题和资格问题，以及默认推理和词义消歧的困难。
\item 拉塞尔和诺维格写道：“[M]我们在语言中命名的许多概念，经过仔细检查后，发现没有早期AI研究人员希望以公理化形式捕捉的逻辑上定义的必要和充分条件。”[122]  
\item 约翰·麦卡锡对此回应道：“组合爆炸问题从AI一开始就已被认识到。”[156]  
\item 这段描述基于克雷维尔1993年的著作，第115-116页。其他观点包括麦考德克2004年，第306-313页，以及NRC 1999年在《语音识别的成功》一章中的内容。  
\item 莫拉维奇解释道：“他们最初对DARPA的承诺过于乐观。当然，他们最终交付的成果远未达到这一水平。但他们觉得，在下一次提案中不能承诺比第一次少，所以他们承诺了更多。”[158]  
\item 尽管自动化坦克是一个失败的项目，但战斗管理系统（称为“DART”）证明极其成功，在第一次海湾战争中节省了数十亿美元，回报了投资，并证明了DARPA的务实政策至少在DARPA看来是有效的。[160]  
\item “诀窍”是德雷福斯的术语。德雷福斯区分了“知道如何”和“知道什么”，这是海德格尔关于“就绪在手”和“呈现于眼前”的现代版本。[162]
\item 岑鲍姆说：“我成了唯一一个被看到与德雷福斯一起吃午餐的AI社区成员。我故意让大家清楚地知道，他们的做法并不是对待人类的方式。”[167]  
\item 科尔比和他的同事们后来还开发了类似聊天机器人的“偏执过程计算机模拟（PARRY）”，以“通过明确的符号处理术语使偏执过程变得可理解。”[171]  
\item 沃森和夏皮罗（1966年）表明，人们在完全抽象的问题上表现不佳，但如果问题重新表述，允许使用直觉的社会智能，表现会显著提高。（参见沃森选择任务）卡尼曼、斯洛维克和特维斯基（1982年）表明，人们在涉及不确定推理的基础问题上非常糟糕。（参见认知偏差列表，有多个例子）埃莉诺·罗斯的研究在拉科夫1987年中有所描述。卡尼曼在其2011年出版的《思考，快与慢》一书中提出了符号认知及其他类型思维的更一般理论。  
\item 麦卡锡立场的一个早期例子出现在《科学》杂志中，他说：“这是AI，所以我们不关心它是否在心理上真实”（科拉塔1982年），他最近在AI@50大会上重申了他的立场，称“人工智能本质上并不是对人类智能的模拟”（梅克尔2006年）。
\item 冲突的另一个方面被称为“程序性/声明性区别”，但它在后来的人工智能研究中未能产生影响。
\item 反向传播的版本已在多个领域中开发，最直接的是由塞波·林奈马（Seppo Linnainmaa）在1970年发布的自动微分的反向模式。它在1970年代由保罗·韦尔博斯（Paul Werbos）应用于神经网络。[121]
\item 汉斯·莫拉维克（Hans Moravec）写道：“我相信，这种自下而上的人工智能路线有一天将与传统的自上而下路线在中途相遇，准备提供真正的世界能力和常识知识，这些在推理程序中一直是令人沮丧的难题。当比喻中的金色铁路道钉被打入并将两种努力结合时，完全智能的机器将会出现。”[203]
\item “AI冬天”一词最早作为美国人工智能协会（AAAI）关于该主题的研讨会的标题。[229]
\item 麦科尔达克（McCorduck）写道：“二十年半后，我们可以看到日本人并没有完全实现那些雄心勃勃的目标。”[234]
\item 参见《人工智能应用》 § 计算机科学
\item 拉塞尔和诺尔维格写道：“整体代理视角现在已被广泛接受。”[250]
\item 卡尔·休伊特（Carl Hewitt）的“演员模型”（Actor model）预示了智能代理的现代定义。（休伊特、比肖普与斯泰格，1973年）约翰·多伊尔（John Doyle，1983年）和马文·明斯基（Marvin Minsky）的经典《心智社会》（The Society of Mind，1986年）都使用了“代理”一词。其他“模块化”的提案包括罗德尼·布鲁克斯（Rodney Brooks）的子摄架构、面向对象编程等。
\item 这是21世纪最广泛使用的教科书中对人工智能的定义，例如《Russell和Norvig, 2021》；《Padgham和Winikoff, 2004》；《Jones, 2007》；《Poole和Mackworth, 2017》。[250]
\item 雷·库兹韦尔（Ray Kurzweil）写道，计算机国际象棋的进步“仅由计算机硬件的暴力扩展所支配。”[254]
\item 费兰蒂Mark 1的循环时间为1.2毫秒，这大致相当于833次浮点运算（flops）。深蓝（Deep Blue）的运行速度为11.38吉弗洛普（gigaflops），而且这还没有计算深蓝为国际象棋设计的专用硬件。非常大致地说，这两者相差约107倍。[citation needed]
\item AlexNet有65万个神经元，并使用ImageNet进行训练，图像经过反向、裁剪和着色增强。该模型还使用了Geoffrey Hinton的丢弃法（dropout）技术和一个修正线性输出函数，这两项技术在当时都是相对较新的发展。[264]
\item 其他几个实验室开发了类似AlexNet的系统，这些系统也使用GPU芯片，并且性能几乎与AlexNet相当，[121]但AlexNet被证明是最具影响力的。
\item 参见《人工智能历史》 § 上述问题，其中汉斯·莫拉维克预测原始计算能力最终会使人工智能变得“容易”。
\item 后来的研究表明，系统没有办法避免可测量的种族偏见——修正一种偏见不可避免地会引入另一种偏见。[272]
\item 一个简短的主题总结包括隐私、监控、版权、虚假信息与深度伪造、过滤泡沫与党派主义、算法偏见、没有算法透明度而无法发现的误导性结果、解释权、自动化武器的滥用以及技术性失业。参见《人工智能 § 伦理》。
\item 布赖恩·克里斯蒂安（Brian Christian）写道：“ProPublica对COMPAS的研究（2015年）使得‘公平’等概念成为有效的研究课题。”[276]
\end{enumerate}
\begin{enumerate}
\item Kaplan & Haenlein 2018.
\item Newquist 1994, pp. 143–156.
\item Newquist 1994, pp. 144–152.
\item Rhodios 2007, Book 4, the Talos episode.
\item Bibliotheke 1.9.26
\item Rhodios 2007.
\item Morford 2007.
\item Linden 2003.
\item Kressel 2015.
\item Jewish Encyclopedia, GOLEM.
\item Newquist 1994, p. 38.
\item Talmud, Sanhedrin 65b.
\item O'Connor 1994.
\item Goethe 1890.
\item McCorduck 2004, pp. 17–25.
\item Butler 1863.
\item Newquist 1994, p. 65.
\item Cave & Dihal 2019.
\item Needham 1986, p. 53.
\item McCorduck 2004, p. 6.
\item Nick 2005.
\item McCorduck 2004, p. 10.
\item Newquist 1994, p. 40.
\item McCorduck 2004, p. 16.
\item McCorduck 2004, pp. 59–62.
\item McCorduck 2004, p. 17.
\item Levitt 2000.
\item Newquist 1994, p. 30.
\item Crevier 1993, p. 1.
\item 引用自 McCorduck 2004，第8页。  
\item Cave, Dihal & Dillon 2020，第56页。  
\item Butler 1948。  
\item Porterfield 2006，第136页。  
\item Hollander 1964。  
\item Russell & Norvig 2021，第6和第7页。  
\item Berlinski 2000。  
\item Carreras y Artau 1939。  
\item Russell & Norvig 2021，第6页。  
\item Bonner 2007。  
\item Bonner 1985，第57-71页。
\item 17世纪的机械主义与人工智能：  
\begin{itemize}
\item McCorduck 2004，第37-46页  
\item Russell & Norvig 2021，第6页  
\item Buchanan 2005，第53页
\end{itemize}  
\item 霍布斯与人工智能：  
\begin{itemize}
\item Russell & Norvig 2021，第6页  
\item McCorduck 2004，第42页  
\item 霍布斯 1651，第5章
\end{itemize}  
\item 莱布尼茨与人工智能：  
\begin{itemize}
\item McCorduck 2004，第41页  
\item Russell & Norvig 2021，第6页  
\item Berlinski 2000，第12页  
\item Buchanan 2005，第53页
\end{itemize}
\item Russell & Norvig 2021，第8页。  
\item Russell & Norvig 2021，第9页。  
\item Crevier 1993，第190、196、61页。  
\item Rose 1946。  
\item 图灵机：  
\begin{itemize}
\item Newquist 1994，第56页。  
\item McCorduck 2004，第63–64页。  
\item Crevier 1993，第22–24页。  
\item Russell & Norvig 2021，第9页。  
另见  
\item Turing 1936–1937。
\end{itemize}
\item Couturat 1901。  
\item Russell & Norvig 2021，第15页。  
\item Newquist 1994，第67页。  
\item Randall (1982，第4–5页)；Byrne (2012)；Mulvihill (2012)。  
\item Randall (1982，第6、11–13页)；Quevedo (1914)；Quevedo (1915)。  
\item Randall 1982，第13、16–17页。  
\item 引自 Russell & Norvig (2021，第15页)。  
\item Menabrea & Lovelace 1843。  
\item Russell & Norvig 2021，第14页。  
\item McCorduck 2004，第76–80页。  
\item AI的直接前驱：  
\begin{itemize}
\item McCorduck 2004，第51–57、80–107页。  
\item Crevier 1993，第27–32页。  
\item Russell & Norvig 2021，第9、11、15–17、981–984页。  
\item Moravec 1988，第3页。  
\item Cordeschi 2002，第5章。
\end{itemize}
\item Copeland 2004.  
\item 达特茅斯研讨会：  
\begin{itemize}
\item McCorduck 2004，第111–136页。  
\item Crevier 1993，第49–51页。  
\item Russell & Norvig 2021，第18页。  
\item Newquist 1994，第91–112页。 
\end{itemize}  
\item 图像改编自 Saygin 2000。
\item 图灵测试，《计算机械与智能》：  
\begin{itemize}
\item McCorduck 2004，第70–72页。  
\item Crevier 1993，第22−25页。  
\item Russell & Norvig 2021，第18页，第981–984页。  
\item Haugeland 1985，第6–9页。  
\item Cordeschi 2002，第170–176页。
\end{itemize}  
另见  
\begin{itemize}
\item Turing 1950。
\end{itemize}
\item Newquist 1994，第92–98页。  
\item Russell & Norvig 2021，第981页。  
\item Pitts & McCullough：  
\begin{itemize}
\item McCorduck 2004，第51–57页，第88–94页。  
\item Crevier 1993，第30页。  
\item Russell & Norvig 2021，第17页。  
\item Cordeschi 2002，第5章。  
\item Piccinini 2004。
\end{itemize}  
另见：McCulloch & Pitts 1943。
\item SNARC:  
\begin{itemize}
\item McCorduck 2004，第102页。  
\item Crevier 1993，第34–35页。  
\item Russell & Norvig 2021，第17页。
\end{itemize}  
\item Turtles and Johns Hopkins Beast:  
\begin{itemize}
\item McCorduck 2004，第98页。  
\item Crevier 1993，第27–28页。  
\item Moravec 1988，第3页。  
\item Cordeschi 2002，第5章
\end{itemize}。
\item Russell & Norvig 2021，第17页。  
\item Copeland 1999。  
\item Schaeffer 1997，第6章。  
\item Russell & Norvig 2021，第17页，第19页。  
\item McCorduck 2004，第137–170页。  
\item Crevier 1993，第44–47页。  
\item Logic Theorist:  
\begin{itemize}
\item McCorduck 2004，第123–125页。  
\item Crevier 1993，第44–46页。  
\item Russell & Norvig 2021，第18页。
\end{itemize}
\item 引用自 Crevier 1993，第46页 和 Russell & Norvig 2021，第18页  
\item McCarthy 等人 1955。  
\item Crevier 1993，第48页。  
\item Newell & Simon 1963。  
\item McCorduck 2004，第114页。  
\item Skillings 2006。  
\item McCarthy 1996，第73页。  
\item McCorduck 2004，第129–130页。  
\item McCorduck 2004，第125页。  
\item Crevier 1993，第49页。  
\item Miller 2003。  
\item Russell & Norvig 2021，第13–14页。  
\item Russell & Norvig 2003，第18页。  
\item Russell & Norvig 2021，第18页。  
\item Crevier 1993，第52–107页。
\item Moravec 1988，第9页。  
\item McCorduck 2004，第218页；Newquist 1994，第91–112页；Crevier 1993，第108–109页。  
\item Crevier 1993，第52–107页；Moravec 1988，第9页。  
\item 状态空间搜索与问题解决：  
\begin{itemize}
\item Russell & Norvig 2021，第3-6章。
\end{itemize}  
\item McCorduck 2004，第246页。  
\item McCorduck 2004，第245–250页。  
\item Russell & Norvig 2021，第19页，第106页。  
\item Russell & Norvig 2021，第19页。  
\item Crevier 1993，第51–58页，第65–66页。  
\item Russell & Norvig 2021，第20页。  
\item STRIPS与Shakey：  
\begin{itemize}
\item Russell & Norvig 2021，第20页。  
\item McCorduck 2004，第268–271页。  
\item Crevier 1993，第95–96页。  
\item Newquist 1994，第148–156页。  
\item Moravec 1988，第14–15页。
\end{itemize}
\item McCorduck 2004，第286页；Crevier 1993，第76–79页；Russell & Norvig 2021，第20页。  
\item Crevier 1993，第79–83页。  
\item Crevier 1993，第164–172页。  
\item McCorduck 2004，第291–296页。  
\item Crevier 1993，第134–139页。  
\item 积木世界：  
\begin{itemize}
\item McCorduck 2004，第299–305页。  
\item Crevier 1993，第83–102页。  
\item Russell & Norvig 2021，第20页。  
\item Copeland 2000。
\end{itemize}  
\item 60年代的感知器：  
\begin{itemize}
\item Russell & Norvig 2021，第21页。  
\item Crevier 1993，第102–105页。  
\item McCorduck 2004，第104–107页。  
\item Schmidhuber 2022。
\end{itemize}
\item Crevier 1993，第102页。  
\item 引用自Crevier 1993，第102页。  
\item Rosenblatt 1962。  
\item Russell & Norvig 2021，第20–21页。  
\item Widrow & Lehr 1990。  
\item Rosen, Nilsson & Adams 1965。  
\item Nilsson 1984。  
\item Hart等，2003。  
\item Nielson 2005。  
\item Olazaran Rodriguez 1991。  
\item Minsky & Papert 1969。  
\item Russell & Norvig 2021，第22页。  
\item Schmidhuber 2022。  
\item Russell & Norvig 2021，第24页。  
\item Crevier 1993，第105页。
\item Simon & Newell 1958，第7−8页，引用自Crevier 1993，第108页。  
\item Simon 1965，第96页，引用自Crevier 1993，第109页。  
\item Minsky 1967，第2页，引用自Crevier 1993，第109页。  
\item Darrach 1970。  
\item McCorduck 2004，第272–274页。  
\item Crevier 1993，第96页。  
\item Crevier 1993，第64–65页。  
\item Crevier 1993，第94页。  
\item Howe 1994。  
\item Crevier 1993，第51页。  
\item McCorduck 2004，第131页。  
\item Crevier 1993，第65页。  
\item Crevier 1993，第68–71页；Turkle 1984。  
\item Crevier 1993，第163–196页。  
\item Dreyfus 1972。  
\item Lighthill 1973。  
\item Haigh 2023。  
\item Crevier 1993，第143页。  
\item Nilsson 2009，第1页。  
\item Russell & Norvig 2021，第21页。
\item Crevier 1993，第146页。  
\item Buchanan 2005，第56页。  
\item Crevier 1993，第146–148页。  
\item Moravec 1976。  
\item Moravec 2000。  
\item McCorduck 2004，第456页。  
\item Brooks 2002。  
\item Moravec 1988，第15–16页。  
\item 常识知识：  
\begin{itemize}
\item McCorduck 2004，第300和421页  
\item Crevier 1993，第113–114页  
\item Moravec 1988，第13页  
\item Lenat & Guha 1989，（简介）
\end{itemize}
\item 引用自 Crevier 1993，第175页  
\item ALPAC：  
\begin{itemize}
\item McCorduck 2004，第280–281页  
\item Crevier 1993，第110页  
\item Russell & Norvig 2021，第21页  
\item NRC 1999，见“语音识别中的成功”。
\end{itemize}  
\item Lighthill 报告：  
\begin{itemize}
\item Crevier 1993，第117页  
\item Howe 1994  
\item Lighthill 1973
\end{itemize}
\item McCarthy 1974.  
\item Crevier 1993，第115–116页.  
\item Crevier 1993，第115页.  
\item NRC 1999，见“向应用研究的转变增加了投资”。  
\item NRC 1999.  
\item Lucas 和 Penrose 对人工智能的批评：  
\begin{itemize}
\item Crevier 1993，第22页  
\item Russell & Norvig 2021，第983–984页  
\item Hofstadter 1999，第471–477页  
\end{itemize}
Lucas 的原始论点：  
\begin{itemize}
\item Lucas 1961
\end{itemize}
\item Dreyfus & Dreyfus 1986.  
\item Dreyfus' critique of artificial intelligence:  
\begin{itemize}
\item McCorduck 2004, pp. 211–239  
\item Crevier 1993, pp. 120–132  
\item Russell & Norvig 2021, pp. 981–982 
\end{itemize} 
Dreyfus' version:  
\begin{itemize}
\item Dreyfus 1965  
\item Dreyfus 1972  
\item Dreyfus & Dreyfus 1986 
\end{itemize} 
\item Searle's critique of AI:  
\begin{itemize}
\item McCorduck 2004, pp. 443–445  
\item Crevier 1993, pp. 269–271  
\item Russell & Norvig 2021, pp. 985–986
\end{itemize}  
Searle's version:  
\begin{itemize}
\item Searle 1980
\end{itemize}
\item 引用自 Crevier 1993，第143页  
\item 引用自 Crevier 1993，第122页  
\item Crevier 1993，第123页  
\item Newquist 1994，第276页  
\item Colby, Watt & Gilbert 1966，第148页  
\item Weizenbaum 1976，第5、6页  
\item Colby 1974，第6页  
\item Weizenbaum 对人工智能的批评：  
\begin{itemize}
\item McCorduck 2004，第356–373页  
\item Crevier 1993，第132–144页  
\item Russell & Norvig 2021，第1001页 
\end{itemize} 
另见：  
\begin{itemize}
\item Weizenbaum 1976
\end{itemize}
\item McCorduck 2004，第51页  
\item Crevier 1993，第190–192页  
\item Crevier 1993，第193–196页  
\item Crevier 1993，第145–149页，第258–263页  
\item 整洁派与杂乱派：  
\begin{itemize}
\item McCorduck 2004，第421–424页（介绍了1984年辩论的状态）  
\item Crevier 1993，第168页（记录了Schank首次使用这一术语）  
\item Russell & Norvig 2021，第19–20页（描述了MIT的“反逻辑”方法）
\end{itemize}  
\item 框架（人工智能）：  
\begin{itemize}
\item McCorduck 2004，第305–306页  
\item Crevier 1993，第170–173页，第246页  
\item Russell & Norvig 2021，第23页 
\end{itemize} 
Minsky的框架论文：  
\begin{itemize}
\item Minsky 1974
\end{itemize}
\item Hayes 1981  
\item Reiter 1978  
\item Clark 1977  
\item 专家系统：  
\begin{itemize}
\item Crevier 1993，第148–159页  
Newquist 1994，第271页  
Russell & Norvig 2021，第22–24页
\end{itemize}  
\item McCorduck 2004，第327–335页  
\item Crevier 1993，第158–159页  
\item Crevier 1993，第198页  
\item Newquist 1994，第259页  
\item 商业专家系统：  
\begin{itemize}
\item McCorduck 2004，第434–435页  
\item Crevier 1993，第161–162页，第197–203页  
\item {{Harvnb|Russell|Norvig|20  
\item Newquist 1994，第275页
\end{itemize}
\item 第五代计算机：  
\begin{itemize}
\item McCorduck 2004，第436–441页  
\item Newquist 1994，第231–240页  
\item Crevier 1993，第211页  
\item Russell & Norvig 2021，第23页  
\item Feigenbaum & McCorduck 1983
\end{itemize}  
\item Crevier 1993，第195页  
\item Russell & Norvig 2021，第23页  
\item Crevier 1993，第240页  
\item McCorduck 2004，第426–432页  
\item NRC 1999，见“向应用研究的转变增加了投资”。  
\item McCorduck 2004，第299页  
\item McCorduck 2004，第421页  
\item 知识革命：  
\begin{itemize}
\item McCorduck 2004，第266–276页，第298–300页，第314页，第421页  
\item Newquist 1994，第255–267页  
\item Russell & Norvig 2021，第23页
\end{itemize}
\item Cyc 和本体工程：  
\begin{itemize}
\item McCorduck 2004，第489页  
\item Crevier 1993，第239–243页  
\item Newquist 1994，第431–455页  
\item Russell & Norvig 2021，第314–316页  
\item Lenat & Guha 1989
\end{itemize}
\item Sejnowski 2018.  
\item Crevier 1993，第214–215页.  
\item Russell & Norvig 2021，第26页.  
\item Christian 2020，第21–22页.  
\item McCorduck 2004，第454–462页.  
\item Moravec 1988，第20页.  
\item Crevier 1993，第183–190页.  
\item Brooks 1990.  
\item Brooks 1990，第3页.  
\item 参见例如，Lakoff & Johnson 1999.  
\item Pollack 1984.  
\item Pollack 1989.  
\item Pearl 1988.
\item Russell & Norvig 2021，第25页。  
\item Poole, Mackworth & Goebel 1998.  
\item Russell & Norvig 2021，第23节。  
\item Christian 2020，第120–124页。  
\item Russell & Norvig 2021，第819页。  
\item Christian 2020，第124页。  
\item Christian 2020，第152–156页。  
\item Christian 2020，第125页。  
\item Christian 2020，第127–129页。  
\item Russell & Norvig 2021，第25页，第820页。  
\item Christian 2020，第140页。  
\item Christian 2020，第141页。  
\item Christian 2020，第?页。  
\item Russell & Norvig 2021，第820页。  
\item Schultz, Dayan & Montague 1997.  
\item Russell & Norvig 2021，第822页。  
\item Newquist 1994，第501页，第511页。  
\item McCorduck 2004，第424页。  
\item Crevier 1993，第203页。
\item Lisp 机器危机：  
\begin{itemize}
\item Newquist 1994，第359–379页  
\item McCorduck 2004，第435页  
\item Crevier 1993，第209–210页 
\end{itemize} 
\item 专家系统失败（及其原因）：  
\begin{itemize}
\item Russell & Norvig 2021，第24页（无法处理不确定推理或学习）  
\item McCorduck 2004，第435页（制度性问题）  
\item Newquist 1994，第258–283页（开发后有限的部署）  
\item Crevier 1993，第204–208页（真值维护的困难，即学习和更新）  
\item Lenat & Guha 1989，介绍（脆弱性和无法处理广泛的资格问题）
\end{itemize}
\item McCorduck 2004，第430–431页。
\item 第五代计算机计划的结束：  
\begin{itemize}
\item McCorduck 2004，第441页  
\item Crevier 1993，第212页  
\item Newquist 1994，第476页 
\end{itemize} 
\item McCorduck 2004，第441页  
\item Newquist 1994，第440页  
\item NRC 1999，《90年代的人工智能》。  
\item Kurzweil 2005，第264页。  
\item 《经济学人》2007年。  
\item CNN 2006年。  
\item Olsen 2004年。  
\item Olsen 2006年。  
\item 90年代和2000年代的人工智能效应，人工智能在幕后：  
\begin{itemize}
\item McCorduck 2004，第423页  
\item Kurzweil 2005，第265页  
\item Hofstadter 1999，第601页  
\item Newquist 1994，第445页
\end{itemize}
\item Tascarella 2006.
\item Newquist 1994，第532页。
\item Markoff 2005年。
\item McCorduck 2004，第486–487页。
\item Russell & Norvig 2021，第24–25页。
\item McCorduck 2004，第471–478页。
\item Russell & Norvig 2021，第2章。
\item Russell & Norvig 2021，第61页。
\item McCorduck 2004，第478页。
\item McCorduck 2004，第480–483页。
\item Russell & Norvig 2021，第28页。
\item Kurzweil 2005，第274页。
\item LeCun, Bengio & Hinton 2015年。
\item Lohr 2016年。
\item Russell & Norvig 2021，第26–27页。
\item 引用自Christian 2020，第22页。
\item Christian 2020，第31页。
\item Christian 2020，第22–23页。
\item Christian 2020，第6页。
\item McKinsey & Co 2011年。
\item Markoff 2011年。
\item Christian 2020，第23–24页。
\item Christian 2020，第24页。
\item Russell & Norvig 2021，第27页。
\item Russell & Norvig 2021，第33, 1004页。
\item Russell 2020年。
\item Russell & Norvig 2021，第5, 33, 1002–1003页。
\item O'Neill 2016年。
\item Christian 2020，第60–61页。
\item Christian 2020，第67–70页。
\item Christian 2020，第6–7, 25页。
\item Christian 2020，第67页。
\item Christian 2020，第67, 73, 117页。
\item Christian 2020，第73页。
\item Russell & Norvig 2021，第32页。
\item Russell & Norvig 2021，第33页。
\item Metz et al. 2023年。
\item Russell & Norvig 2021，第31页。
\item 人工智能热潮：
\begin{itemize}
\item Marr 2023年  
\item Clark 2023年  
\item Gates 2023年  
\item Lee 2024年  
\end{itemize}
\item Murgia 2023年  
\item Bubeck et al. 2023年  
\item Wollman Rusoff J (2024年2月1日)。“Jeremy Grantham警告投资者在大风险来临时要‘非常小心’”。thinkadvisor.com。2024年12月5日检索。  
Mohamed T (2024年3月23日)。“精英投资者Jeffrey Gundlach将AI股市热潮与互联网泡沫相比较，并警告经济痛苦”。Business Insider。2024年12月5日检索。
\end{enumerate}
\subsection{参考文献} 
\begin{itemize}
\item Bonner A (2007)，《拉蒙·吕尔的艺术与逻辑：用户指南》，Brill，ISBN 978-9004163256  
\item Bonner A (1985)。“吕尔的影响：吕尔主义的历史”。《光明博士：拉蒙·吕尔读本》。普林斯顿大学出版社。  
\item Brooks R (2002)，《肉体与机器》，Pantheon Books  
\item Bubeck S, Chandrasekaran V, Eldan R, Gehrke J, Horvitz E, Kamar E, Lee P, Lee YT, Li Y, Lundberg S, Nori H, Palangi H, Ribeiro MT, Zhang Y (2023年3月22日)。“人工通用智能的火花：关于GPT-4的早期实验”。arXiv:2303.12712 [cs.CL]。  
\item Carreras y Artau T (1939)，《西班牙哲学史：13至15世纪的基督教哲学》（西班牙语），第1卷，马德里：Forgotten Books，ISBN 9781390433708  
\item Butler EM (1948)。 《魔法师的神话》。伦敦：剑桥大学出版社。ISBN 0-521-22564-7。OCLC 5063114。  
\item Clark S (2023年12月21日)。“AI时代：2023年里程碑的年份”。CMSWire.com。2024年1月28日检索。  
\item Copeland J (1999)。“计算机简史”。AlanTuring.net。  
\item Cave S, Dihal K (2019)。“虚构与现实中的智能机器的希望与恐惧”。《自然机器智能》。1(2)：74-78。doi:10.1038/s42256-019-0020-9。ISSN 2522-5839。S2CID 150700981。  
\item Cave S, Dihal K, Dillon S (2020)，《AI叙事：关于智能机器的想象性思维史》，牛津大学出版社。ISBN 978-0-19-884666-6。2023年5月2日检索。  
\item Christian B (2020)，《对齐问题：机器学习与人类价值》，W.W. Norton & \item Company。ISBN 978-0-393-86833-3。OCLC 1233266753。  
\item Clark K (1977)。“失败的否定”。《逻辑与数据库》。波士顿，MA：Springer US。第293-322页。doi:10.1007/978-1-4684-3384-5_11。ISBN 978-1-4684-3386-9。  
\item Gates B (2023年12月21日)。“今年标志着新时代的开始”。www.linkedin.com。2024年1月28日检索。  
\item Goethe JW (1890)。 《浮士德；一部悲剧》。由Bayard Taylor翻译，原作格律保留… 由Bayard Taylor夫人特别安排出版的授权版。伦敦：Ward, Lock出版社。

\item Hart PE, Nilsson NJ, Perrault R, Mitchell T, Kulikowski CA, Leake DB (2003年3月15日)。“悼念：查尔斯·罗森、诺曼·尼尔森和索尔·阿马雷尔”。《人工智能杂志》，24(1)：6。doi:10.1609/aimag.v24i1.1683。ISSN 2371-9621。  
\item Hayes P (1981)。“框架的逻辑”。收录于 Kaufmann M (编)。《人工智能读本》，第451-458页。  
\item "GOLEM"，《犹太百科全书》，2020年3月15日检索。  
\item Hollander LM (1964)，《海姆斯克林格拉；挪威国王史》。奥斯汀：由德克萨斯大学出版社为美国斯堪的纳维亚基金会出版。ISBN 0-292-73061-6。OCLC 638953。  
Kressel M (2015年10月1日)。“犹太神话的36天：第24天，布拉格的戈莱姆2015”。\item Matthew Kressel。2020年3月15日检索。  
\item LeCun Y, Bengio Y, Hinton G (2015)。“深度学习”（PDF）。《自然》，521(7553)：436-444。Bibcode:2015Natur.521..436L。doi:10.1038/nature14539。PMID 26017442。S2CID 3074096。  
\item Lee A (2024年1月23日)。“德州大学将2024年定为‘人工智能之年’”。《UT新闻》。2024年1月28日检索。  
\item Linden SJ (2003)，《炼金术读本：从赫尔墨斯·特里斯梅吉斯图斯到艾萨克·牛顿》。纽约：剑桥大学出版社，第18章。ISBN 0-521-79234-7。OCLC 51210362。  
Lohr S (2016年10月17日)，“IBM押注沃森并为此支付巨额资金”，《纽约时报》。  
\item Markoff J (2011年2月16日)。“在《危险边缘！》中，沃森的胜利几乎毫无意义”。《纽约时报》。  
\item Marr B (2023年3月20日)。“超越炒作：2023年你真正需要了解的人工智能”。《福布斯》。2024年1月27日检索。  
\item McCarthy J (1988)。“《人工智能问题》评论”。《计算机历史年鉴》，10(3)：224-229。收录于McCarthy J (1996)。“第10章：《人工智能问题》评论”。《捍卫人工智能研究：论文和评论集》。CSLI。  
\item McCulloch WS, Pitts W (1943年12月1日)。“神经活动中固有思想的逻辑演算”。《数学生物物理学公报》，5(4)：115-133。doi:10.1007/BF02478259。ISSN 1522-9602。
\item “《大数据：创新、竞争和生产力的下一前沿》”。麦肯锡公司网站，2011年5月1日。  
\item Metz C, Weise K, Grant N, Isaac M (2023年12月3日)。“自负、恐惧与金钱：人工智能火种如何点燃”。《纽约时报》。

\item Miller G (2003). "The cognitive revolution: a historical perspective" (PDF). *Trends in Cognitive Sciences*, 7 (3): 141–144. doi:10.1016/s1364-6613(03)00029-9. PMID 12639696.  
\item Moravec H (2000年5月18日). *Robot: Mere Machine to Transcendent Mind*. 牛津大学出版社. ISBN 9780195136302.  
\item Morford M (2007). *Classical mythology*. 牛津：牛津大学出版社. 第184页. ISBN 978-0-19-085164-4. OCLC 1102437035.  
\item Murgia M (2023年7月23日). "Transformers: the Google scientists who pioneered an AI revolution". *金融时报*（www.ft.com）。检索于2023年12月10日。  
\item O'Neill C (2016年9月6日). *Weapons of Math Destruction: How Big Data Increases Inequality and Threatens Democracy*. Crown. ISBN 978-0553418811.  
\item Nielson DL (2005年1月1日). "Chapter 4: The Life and Times of a Successful SRI Laboratory: Artificial Intelligence and Robotics" (PDF). *A HERITAGE OF INNOVATION SRI's First Half Century* (第一版). SRI International. ISBN 978-0-9745208-0-3.  
\item Nilsson NJ (1984). "The SRI Artificial Intelligence Center: A Brief History" (PDF). Artificial Intelligence Center, SRI International. 原文已存档（PDF），存档于2022年8月10日。  
\item Olazaran Rodriguez JM (1991). *A historical sociology of neural network research*（PDF）(学位论文). 爱丁堡大学。原文已存档（PDF），存档于2022年11月11日。请特别参考第二章和第三章。

\item Piccinini G (2004年8月1日). "The First Computational Theory of Mind and Brain: A Close Look at McCulloch and Pitts's 'Logical Calculus of Ideas Immanent in Nervous Activity'". *Synthese*, 141 (2): 175–215. doi:10.1023/B:SYNT.0000043018.52445.3e. ISSN 1573-0964. S2CID 10442035.  
\item Porterfield A (2006). *The Protestant Experience in America*. American Religious Experience. Greenwood Press. 第136页. ISBN 978-0-313-32801-5. 检索于2023年5月15日。  
\item Reiter R (1978). "On reasoning by default". *American Journal of Computational Linguistics*: 29–37.  
\item Rhodios A (2007). *The Argonautika: Expanded Edition*. 加利福尼亚大学出版社. 第355页. ISBN 978-0-520-93439-9. OCLC 811491744.  
\item Rose A (1946年4月). "Lightning Strikes Mathematics". *Popular Science*: 83–86. 检索于2012年4月15日。  
\item Rosen CA, Nilsson NJ, Adams MB (1965年1月8日). "A research and development program in applications of intelligent automata to reconnaissance-phase I. (Proposal for Research SRI No. ESU 65-1)" (PDF). *Stanford Research Institute*. 原文已存档（PDF），存档于2006年3月16日。  
\item Rosenblatt F (1962). *Principles of Neurodynamics: Perceptrons and the Theory of Brain Mechanisms*, 第55卷, 华盛顿DC：斯巴达出版社。  
Russell SJ (2020). *Human Compatible: Artificial Intelligence and the Problem of Control*. Penguin Random House. ISBN 9780525558637. OCLC 1113410915.  
\item Schaeffer J (1997). *One Jump Ahead: Challenging Human Supremacy in Checkers*. Springer. ISBN 978-0-387-76575-4.
\item Schultz W, Dayan P, Montague PR (1997年3月14日). "A Neural Substrate of Prediction and Reward". *Science*, 275 (5306): 1593–1599. doi:10.1126/science.275.5306.1593. PMID 9054347.  
\item Sejnowski TJ (2018年10月23日). *The Deep Learning Revolution* (第1版). 剑桥，马萨诸塞州，伦敦，英格兰：MIT出版社. 第93–94页. ISBN 978-0-262-03803-4.  
\item "Sanhedrin 65b". *www.sefaria.org*. 检索于2020年3月15日。  
\item Widrow B, Lehr M (1990年9月). "30 years of adaptive neural networks: perceptron, Madaline, and backpropagation". *Proceedings of the IEEE*, 78 (9): 1415–1442. doi:10.1109/5.58323. S2CID 195704643.
\item Berlinski D (2000). *The Advent of the Algorithm*. Harcourt Books. ISBN 978-0-15-601391-8. OCLC 46890682.  
\item Brooks RA (1990). "Elephants Don't Play Chess" (PDF). *Robotics and Autonomous Systems*, 6 (1–2): 3–15. doi:10.1016/S0921-8890(05)80025-9.  
\item Buchanan BG (2005年冬). "A (Very) Brief History of Artificial Intelligence" (PDF), *AI Magazine*, 第53–60页. 归档自原始PDF文件，于2007年9月26日，检索于2007年8月30日。  
\item Butler S (1863年6月13日). "Darwin Among the Machines", *The Press*, 克赖斯特彻奇，新西兰，检索于2008年10月10日。  
\item Byrne JG (2012年12月8日). "The John Gabriel Byrne Computer Science Collection" (PDF). 归档自原始文件，于2019年4月16日。检索于2019年8月8日。  
\item "AI set to exceed human brain power", *CNN.com*, 2006年7月26日，检索于2007年10月16日。  
\item Colby KM, Watt JB, Gilbert JP (1966). "A Computer Method of Psychotherapy: Preliminary Communication", *The Journal of Nervous and Mental Disease*, vol. 142, no. 2, pp. 148–152. doi:10.1097/00005053-196602000-00005. PMID 5936301. S2CID 36947398.  
\item Colby KM (1974年9月). Ten Criticisms of Parry (PDF), 斯坦福人工智能实验室, REPORT NO. STAN-CS-74-457, 检索于2018年6月17日。  
\item Couturat L (1901). *La Logique de Leibniz*.  
\item Copeland J (2000). *Micro-World AI*, 检索于2008年10月8日。  
\item Copeland J (2004). *The Essential Turing: the Ideas that Gave Birth to the Computer Age*. 牛津：Clarendon Press. ISBN 0-19-825079-7.  
\item Cordeschi R (2002). *The Discovery of the Artificial*, 多德雷赫特：Kluwer。  
\item Crevier D (1993). *AI: The Tumultuous Search for Artificial Intelligence*. 纽约，NY：BasicBooks. ISBN 0-465-02997-3.  
\item Darrach B (1970年11月20日). "Meet Shaky, the First Electronic Person", *Life Magazine*, 第58–68页。  
\item Doyle J (1983). "What is Rational Psychology? Toward a Modern Mental Philosophy", *AI Magazine*, vol. 4, no. 3, pp. 50–53.  
\item Dreyfus H (1965). *Alchemy and AI*, RAND Corporation Memo.  
\item Dreyfus H (1972). *What Computers Can't Do*, 纽约：MIT Press. ISBN 978-0-06-090613-9. OCLC 5056816.  
\item Dreyfus H, Dreyfus S (1986). *Mind over Machine: The Power of Human Intuition and Expertise in the Era of the Computer*. 牛津，英国：Blackwell. ISBN 978-0-02-908060-3. 检索于2020年8月22日。  
\item The Economist (2007年6月7日). "Are You Talking to Me?", *The Economist*, 检索于2008年10月16日。  
\item Feigenbaum EA, McCorduck P (1983). *The Fifth Generation: Artificial Intelligence and Japan's Computer Challenge to the World*, Michael Joseph. ISBN 978-0-7181-2401-4.  
\item Haigh T (2023年12月). "There Was No 'First AI Winter'", *Communications of the ACM*, 66 (12): 35–39. doi:10.1145/3625833. ISSN 0001-0782.  
\item Haugeland J (1985). *Artificial Intelligence: The Very Idea*, 剑桥，马萨诸塞：MIT Press. ISBN 978-0-262-08153-5.  
\item Hawkins J, Blakeslee S (2004). *On Intelligence*, 纽约，NY：Owl Books. ISBN 978-0-8050-7853-4. OCLC 61273290.  
\item Hebb D (1949). *The Organization of Behavior*, 纽约：Wiley. ISBN 978-0-8058-4300-2. OCLC 48871099.  
\item Hewitt C, Bishop P, Steiger R (1973). *A Universal Modular Actor Formalism for Artificial Intelligence* (PDF), *IJCAI*, 归档自原始PDF文件，于2009年12月29日。  
\item Hobbes T (1651). *Leviathan*. 
\item Hofstadter D (1999) [1979]. *Gödel, Escher, Bach: an Eternal Golden Braid*, Basic Books. ISBN 978-0-465-02656-2. OCLC 225590743.  
Howe J (1994年11月). *Artificial Intelligence at Edinburgh 
\item University: a Perspective*, 检索于2007年8月30日。  
\item Kahneman D, Slovic D, Tversky A (1982). "Judgment under uncertainty: Heuristics and biases". *Science*, 185 (4157). 纽约：剑桥大学出版社: 1124–1131. Bibcode:1974Sci...185.1124T. doi:10.1126/science.185.4157.1124. ISBN 978-0-521-28414-1. PMID 17835457. S2CID 143452957.  
\item Kaplan A, Haenlein M (2018). "Siri, Siri in my Hand, who's the Fairest in the Land? On the Interpretations, Illustrations and Implications of Artificial Intelligence", *Business Horizons*, 62: 15–25. doi:10.1016/j.bushor.2018.08.004. S2CID 158433736.  
\item Kolata G (1982). "How can computers get common sense?", *Science*, 217 (4566): 1237–1238. Bibcode:1982Sci...217.1237K. doi:10.1126/science.217.4566.1237. PMID 17837639.  
\item Kurzweil R (2005). *The Singularity is Near*, Viking Press. ISBN 978-0-14-303788-0. OCLC 71826177.  
\item Lakoff G (1987). *Women, Fire, and Dangerous Things: What Categories Reveal About the Mind*, University of Chicago Press. ISBN 978-0-226-46804-4.  
\item Lakoff G, Johnson M (1999). *Philosophy in the Flesh: The Embodied Mind and its Challenge to Western Thought*, Basic Books. ISBN 978-0-465-05674-3.  
\item Lenat D, Guha RV (1989). *Building Large Knowledge-Based Systems*, Addison-Wesley. ISBN 978-0-201-51752-1. OCLC 19981533.  
\item Levitt GM (2000). *The Turk, Chess Automaton*, Jefferson, N.C.: McFarland. ISBN 978-0-7864-0778-1.
\item Lighthill PS (1973). "Artificial Intelligence: A General Survey", *Artificial Intelligence: a paper symposium*, Science Research Council.  
\item Lucas J (1961). "Minds, Machines and Gödel", *Philosophy*, 36 (XXXVI): 112–127. doi:10.1017/S0031819100057983. S2CID 55408480.  
\item Luger G, Stubblefield W (2004). *Artificial Intelligence: Structures and Strategies for Complex Problem Solving* (5th ed.). Benjamin/Cummings. ISBN 978-0-8053-4780-7. 检索于2019年12月17日。
\item Maker MH (2006). *AI@50: AI Past, Present, Future*, 达特茅斯学院，原文存档于2008年10月8日，检索于2008年10月16日。  
\item Markoff J (2005年10月14日). "Behind Artificial Intelligence, a Squadron of Bright Real People", *纽约时报*，检索于2008年10月16日。  
\item McCarthy J, Minsky M, Rochester N, Shannon C (1955年8月31日). *A Proposal for the Dartmouth Summer Research Project on Artificial Intelligence*，原文存档于2008年9月30日，检索于2008年10月16日。  
\item McCarthy J, Hayes PJ (1969). "Some philosophical problems from the standpoint of artificial intelligence", 收录于Meltzer BJ, Mitchie D（编辑）《Machine Intelligence 4》，爱丁堡大学出版社，页463–502，检索于2008年10月16日。
\item McCarthy J (1974). "Review of Lighthill report".  
\item McCorduck P (2004). *Machines Who Think* (第2版)，Natick, MA: A. K. Peters, Ltd.，ISBN 978-1-56881-205-2, OCLC 52197627.  
\item McCullough WS, Pitts W (1943). "A logical calculus of the ideas immanent in nervous activity", *Bulletin of Mathematical Biophysics*, 5 (4): 115–127, doi:10.1007/BF02478259.  
\item Menabrea LF, Lovelace A (1843). "Sketch of the Analytical Engine Invented by Charles Babbage", *Scientific Memoirs*, 3，检索于2008年8月29日，并附有翻译者的注释。  
\item Minsky M (1967). *Computation: Finite and Infinite Machines*, Englewood Cliffs, N.J.: Prentice-Hall.
\item Minsky M, Papert S (1969), *Perceptrons: An Introduction to Computational Geometry*, The MIT Press, ISBN 978-0-262-63111-2, OCLC 16924756.  
\item Minsky M (1974), *A Framework for Representing Knowledge*, archived from the original on 7 January 2021, retrieved 16 October 2008.  
\item Minsky M (1986), *The Society of Mind*, Simon and Schuster, ISBN 978-0-671-65713-0, OCLC 223353010.  
\item Minsky M (2001), *It's 2001. Where Is HAL?*, Dr. Dobb's Technetcast, retrieved 8 August 2009.  
\item Moor J, ed. (2003), *The Turing Test: The Elusive Standard of Artificial Intelligence*, Dordrecht: Kluwer Academic Publishers, ISBN 978-1-4020-1205-1.  
\item Moravec H (1976), *The Role of Raw Power in Intelligence*, archived from the original on 3 March 2016, retrieved 16 October 2008.  
\item Moravec H (1988), *Mind Children*, Harvard University Press, ISBN 978-0-674-57618-6, OCLC 245755104.
\item Mulvihill M (17 October 2012). "1907: was the first portable computer design Irish?". *Ingenious Ireland*.  
\item Needham J (1986). *Science and Civilization in China: Volume 2*. Taipei: Caves Books Ltd.  
\item Newell A, Simon HA (1963), "GPS: A Program that Simulates Human Thought", in Feigenbaum E, Feldman J (eds.), *Computers and Thought*, New York: McGraw-Hill, ISBN 978-0-262-56092-4, OCLC 246968117.  
\item Newquist HP (1994), *The Brain Makers: Genius, Ego, And Greed in the Quest For Machines That Think*, New York: Macmillan/SAMS, ISBN 978-0-9885937-1-8, OCLC 313139906.  
\item NRC (1999), "Developments in Artificial Intelligence", *Funding a Revolution: Government Support for Computing Research*, National Academy Press, ISBN 978-0-309-06278-7, OCLC 246584055.  
\item Nick M (2005), *Al Jazari: The Ingenious 13th Century Muslim Mechanic*, Al Shindagah, retrieved 16 October 2008.  
\item Nilsson N (30 October 2009). *The Quest for Artificial Intelligence*. Cambridge University Press. ISBN 978-0-52-112293-1.
\item O'Connor KM (1994), *The alchemical creation of life (takwin) and other concepts of Genesis in medieval Islam*, University of Pennsylvania, pp. 1–435, retrieved 10 January 2007.  
\item Olsen S (10 May 2004), *Newsmaker: Google's man behind the curtain*, CNET, retrieved 17 October 2008.  
\item Olsen S (18 August 2006), *Spying an intelligent search engine*, CNET, retrieved 17 October 2008.  
\item Pearl J (1988), *Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference*, San Mateo, California: Morgan Kaufmann, ISBN 978-1-55860-479-7, OCLC 249625842.  
\item Poole D, Mackworth A, Goebel R (1998), *Computational Intelligence: A Logical Approach*, Oxford University Press, ISBN 978-0-19-510270-3.  
\item Pollack A (11 October 1984). "Technology; Fuzzy Logic For Computers". *The New York Times*.  
\item Pollack A (2 April 1989). "Fuzzy Computer Theory: How to Mimic the Mind?". *The New York Times*.
\item Quevedo LT (1914), "Revista de la Academia de Ciencias Exactas", *Ensayos sobre Automática – Su definición. Extensión teórica de sus aplicaciones*, vol. 12, pp. 391–418.  
\item Quevedo LT (1915), "Revue Générale des Sciences Pures et Appliquées", *Essais sur l'Automatique - Sa définition. Étendue théorique de ses applications*, vol. 2, pp. 601–611.  
\item Randall B (1982), "From Analytical Engine to Electronic Digital Computer: The Contributions of Ludgate, Torres, and Bush", *fano.co.uk*, retrieved 29 October 2018.  
\item Russell SJ, Norvig P (2003), *Artificial Intelligence: A Modern Approach* (2nd ed.), Upper Saddle River, New Jersey: Prentice Hall, ISBN 0-13-790395-2.  
\item Russell SJ, Norvig P (2021). *Artificial Intelligence: A Modern Approach* (4th ed.), Hoboken: Pearson. ISBN 978-0-13-461099-3. LCCN 20190474.  
\item Samuel AL (July 1959), "Some studies in machine learning using the game of checkers", *IBM Journal of Research and Development*, 3 (3): 210–219, CiteSeerX 10.1.1.368.2254, doi:10.1147/rd.33.0210, S2CID 2126705, archived from the original on 3 March 2016, retrieved 20 August 2007.
\item Saygin AP, Cicekli I, Akman V (2000), "Turing Test: 50 Years Later" (PDF), *Minds and Machines*, 10 (4): 463–518, doi:10.1023/A:1011288000451, hdl:11693/24987, S2CID 990084, archived from the original (PDF) on 9 April 2011, retrieved 7 January 2004. Reprinted in Moor (2003, pp. 23–78).
\item Searle J (1980), "Minds, Brains and Programs", *Behavioral and Brain Sciences*, 3 (3): 417–457, doi:10.1017/S0140525X00005756, archived from the original on 10 December 2007, retrieved 13 May 2009.
\item Simon HA, Newell A (1958), "Heuristic Problem Solving: The Next Advance in Operations Research", *Operations Research*, 6: 1–10, doi:10.1287/opre.6.1.1.
\item Simon HA (1965), *The Shape of Automation for Men and Management*, New York: Harper & Row.
\item Skillings J (2006), Newsmaker: Getting machines to think like us, *CNET*, retrieved 8 October 2008. 
\item Tascarella P (14 August 2006), "Robotics firms find fundraising struggle, with venture capital shy", *Pittsburgh Business Times*, retrieved 15 March 2016.
\item Turing A (1936–1937), "On Computable Numbers, with an Application to the Entscheidungsproblem", *Proceedings of the London Mathematical Society*, 2, 42 (42): 230–265, doi:10.1112/plms/s2-42.1.230, S2CID 73712, retrieved 8 October 2008.
\item Turing A (October 1950). "Computing Machinery and Intelligence". *Mind*, 59 (236): 433–460. doi:10.1093/mind/LIX.236.433. ISSN 1460-2113. JSTOR 2251299. S2CID 14636783.
\item Turkle S (1984). *The Second Self: Computers and the Human Spirit*. Simon and Schuster. ISBN 978-0-671-46848-4. OCLC 895659909.
\item Wason PC, Shapiro D (1966). "Reasoning". In Foss, B. M. (ed.). *New Horizons in Psychology*. Harmondsworth: Penguin. Retrieved 18 November 2019.
\item Weizenbaum J (1976), *Computer Power and Human Reason*, W.H. Freeman & Company, ISBN 978-0-14-022535-8, OCLC 10952283.
\end{itemize}