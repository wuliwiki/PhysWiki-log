% 人工智能史（综述）
% license CCBYSA3
% type Wiki

本文根据 CC-BY-SA 协议转载翻译自维基百科\href{https://en.wikipedia.org/wiki/History_of_artificial_intelligence}{相关文章}。

人工智能（AI）的历史可以追溯到古代，那个时候有关于由工匠们赋予智慧或意识的人工生命体的神话、故事和传闻。从古代到现代，逻辑学和形式推理的研究直接促成了1940年代可编程数字计算机的发明，这是一种基于抽象数学推理的机器。这个设备及其背后的理念启发了科学家们开始讨论构建电子大脑的可能性。

人工智能研究领域是在1956年于达特茅斯学院举行的一次研讨会上创立的。[1] 参加该研讨会的人成为了人工智能研究的领导者，并且在几十年里引领着这一领域的发展。许多人预测，在一代人之内，像人类一样智能的机器将会问世。美国政府也提供了数百万美元，希望能够将这一愿景变为现实。[2]

最终，研究人员明显低估了这一壮举的难度。[3] 1974年，詹姆斯·莱特希尔的批评以及美国国会的压力导致美国和英国政府停止资助无目标的人工智能研究。七年后，日本政府的远见性倡议和专家系统的成功重新激发了对人工智能的投资，到了1980年代末，人工智能产业已经成长为一个价值十亿美元的行业。然而，到了1990年代，投资者的热情减退，人工智能在媒体中受到批评，行业也开始回避这一领域（这一时期被称为“人工智能寒冬”）。尽管如此，研究和资金在其他名称下依然持续增长。

进入2000年代，机器学习被应用于学术和工业中的广泛问题。这一成功归功于强大计算机硬件的可用性、大规模数据集的收集以及扎实的数学方法的应用。很快，深度学习证明是一项突破性的技术，超越了所有其他方法。2017年，变换器架构的首次亮相带来了令人印象深刻的生成型人工智能应用，及其他多个应用场景。到2020年代，人工智能的投资呈现爆发式增长。
\subsection{前驱}
\subsubsection{神话、小说和推测性的前驱}
\textbf{神话与传说}

在希腊神话中，塔罗斯（Talos）是一个由青铜铸成的巨人，担任克里特岛的守护者。他会向入侵者的船只投掷大石块，并每天绕岛的周围完成三次巡逻。[4] 根据伪阿波罗多罗斯的《博物志》（Bibliotheke），赫淮斯托斯（Hephaestus）在一位独眼巨人的帮助下锻造了塔罗斯，并将这个自动装置作为礼物献给米诺斯（Minos）。[5] 在《阿尔戈英雄传》（Argonautica）中，杰森（Jason）和阿尔戈英雄们通过拔出塔罗斯脚旁的塞子，导致其体内的生命之液流出，从而使塔罗斯丧命。[6]

皮格马利翁（Pygmalion）是希腊神话中的一位传奇国王与雕刻家，著名的故事出自奥维德的《变形记》。在奥维德的叙事诗《变形记》第十卷中，皮格马利翁因目睹普罗波埃提德斯（Propoetides）自愿卖淫的行为而对女性感到厌恶。尽管如此，他还是在维纳斯（Venus）的神庙中献上祭品，请求女神赐予他一位像他雕刻的雕像一样的女子。[7]

\textbf{中世纪关于人工生命体的传说}
\begin{figure}[ht]
\centering
\includegraphics[width=6cm]{./figures/7e497a845b48fea1.png}
\caption{歌德《浮士德》中的人造小人描绘} \label{fig_RGZN_1}
\end{figure}
在《事物的本质》中，瑞士炼金术士帕拉塞尔苏斯（Paracelsus）描述了一种他声称能制造“人造人”的方法。他将“一名男子的精液”放入马粪中，并在40天后喂入“人血的秘方”，这种混合物将变成一个活生生的婴儿。[8]

关于制造“哥雷姆”（Golem）的最早书面记载出现在13世纪初沃尔姆斯的以利以撒·本·犹大（Eleazar ben Judah）的著作中。[9] 在中世纪，人们认为，通过将写有上帝名字的纸条放入泥人（哥雷姆）口中，可以使其复活。[10] 与像青铜头这样的传奇自动装置不同，哥雷姆是无法说话的。[11][12]

在伊斯兰教的炼金术手稿中，\textbf{塔克温}（Takwin，即人工生命的创造）是一个常见的主题，尤其是在那些归属于贾比尔·伊本·海扬（Jabir ibn Hayyan）的作品中。伊斯兰炼金术士尝试通过炼金术创造各种生命形式，从植物到动物不等。[13]

在约翰·沃尔夫冈·冯·歌德（Johann Wolfgang von Goethe）的《浮士德：悲剧的第二部分》中，炼金术制造的“人造小人”（homunculus）注定要永远生活在他被制造出来的瓶子里，但他努力想要变成一个完整的人类身体。然而，在这一转变开始时，瓶子破裂，人造小人也随之死去。[14]

\textbf{现代小说}

到19世纪，关于人工人和思考机器的理念成为小说中的一个流行主题。像玛丽·雪莱的《弗兰肯斯坦》和卡雷尔·恰佩克的《R.U.R.》（罗索姆的万能机器人）[15]等著名作品探讨了人工生命的概念。像塞缪尔·巴特勒的《机器中的达尔文》[16]和爱德加·爱伦·坡的《梅尔策尔的棋手》[17]等推测性文章反映了社会对具有人工智能的机器日益增长的兴趣。人工智能至今仍是科幻小说中的常见主题。[18]

\textbf{自动装置}
\begin{figure}[ht]
\centering
\includegraphics[width=8cm]{./figures/dcdee03784e1a89f.png}
\caption{阿尔·贾扎里的可编程自动装置（公元1206年）} \label{fig_RGZN_2}
\end{figure}
许多文明的工匠建造了现实中的类人自动装置，包括燕师[19]、亚历山大英雄[20]、阿尔·贾扎里[21]、哈鲁恩·拉希德[22]、雅克·德·沃康松[23][24]、莱昂纳多·托雷斯·伊·凯韦多[25]、皮埃尔·贾凯-德罗兹和沃尔夫冈·冯·肯普伦[26][27]。

已知最古老的自动装置是古埃及和古希腊的神像[28][29]。信徒们相信，工匠们赋予这些雕像非常真实的心智，能够表现出智慧和情感——赫尔墨斯·特里斯梅吉斯图斯曾写道：“通过发现神的真正本质，人类已能够复制它”[30]。英国学者亚历山大·内克哈姆（Alexander Neckham）主张，古罗马诗人维吉尔曾建造了一座拥有自动雕像的宫殿[31]。

在早期现代时期，这些传奇的自动装置据说具有回答提问的神奇能力。晚期中世纪的炼金术士和原始新教徒罗杰·培根据说曾制造过一颗青铜头，并发展出自己是巫师的传说[32][33]。这些传说与北欧神话中的米米尔之头相似。传说中，米米尔以智力和智慧著称，在 Æsir-Vanir 战争中被斩首。奥丁被认为“用草药”保存了米米尔的头，并对其念咒语，使米米尔的头仍能向奥丁传授智慧。奥丁随后将头放在身边，作为咨询之用[34]。
\subsubsection{形式推理}
人工智能基于这样一种假设：人类的思维过程可以被机械化。机械或“形式”推理的研究有着悠久的历史。中国、印度和希腊的哲学家们在公元前一千年左右就已经发展出了结构化的形式推理方法。这些思想经过几百年的发展，得到了像亚里士多德（他对三段论进行了形式分析）、欧几里得（他的《几何原本》是形式推理的典范）、阿尔·花拉子米（他发展了代数，并将自己的名字赋予了“算法”一词）以及威廉·奥卡姆和邓斯·司各图等欧洲经院哲学家的深化和扩展[35][36]。

西班牙哲学家拉蒙·柳尔（1232–1315）发展了几种逻辑机器，致力于通过逻辑手段生产知识[37][38]；柳尔将他的机器描述为机械实体，能够通过简单的逻辑操作将基本且不容否认的真理组合在一起，机器通过机械方式产生这些操作，从而生成所有可能的知识[39]。柳尔的工作对戈特弗里德·莱布尼茨产生了巨大影响，后者重新发展了他的思想[40]。
\begin{figure}[ht]
\centering
\includegraphics[width=6cm]{./figures/d3b8a79f2fbc4764.png}
\caption{戈特弗里德·莱布尼茨，他推测人类的理性可以归结为机械计算。} \label{fig_RGZN_3}
\end{figure}
17世纪，莱布尼茨、托马斯·霍布斯和勒内·笛卡尔探索了将所有理性思维系统化的可能性，使其如代数或几何一样具有体系性[41]。霍布斯在《利维坦》中著名地写道：“理性……无非是计算，就是加法和减法”[42]。莱布尼茨设想了一种普遍的推理语言——通用符号系统（characteristica universalis），这种语言将论证简化为计算，令“两个哲学家之间不再需要争论，正如两个会计师之间也不必争论一样。因为只需拿起他们的铅笔和黑板，就可以彼此对话（如果愿意，可以有朋友作为见证者）：让我们计算吧”[43]。这些哲学家开始阐述物理符号系统假设，这一假设最终成为人工智能研究的指导信条。

数学逻辑的研究提供了使人工智能看似可行的关键突破。布尔的《思想的法则》和弗雷格的《概念文字》为此奠定了基础[44]。基于弗雷格的系统，罗素和怀特海德在1913年出版的《数学原理》中对数学基础进行了形式化处理。受罗素成功的启发，戴维·希尔伯特在1920年代和1930年代挑战数学家们回答一个根本性的问题：“所有的数学推理能否形式化？”[36]这个问题最终得到了哥德尔不完备定理[45]、图灵机[45]和丘奇的λ演算[注]的回答。
\begin{figure}[ht]
\centering
\includegraphics[width=8cm]{./figures/f837aba8957e9db3.png}
\caption{美国陆军拍摄的ENIAC照片，拍摄地点为摩尔电气工程学院[47]} \label{fig_RGZN_4}
\end{figure}
他们的答案在两个方面令人惊讶。首先，他们证明了数学逻辑实际上是有局限的。其次（对人工智能更为重要的是），他们的工作表明，在这些局限内，任何形式的数学推理都可以被机械化。丘奇-图灵论题意味着，一台机械设备，只需按简单的符号（如0和1）进行排列，就可以模仿任何可以想象的数学推理过程。关键的洞察是图灵机——一个简单的理论构造，它捕捉了抽象符号操作的本质。[48] 这一发明激发了一些科学家开始讨论思维机器的可能性。
\subsubsection{计算机科学}  
计算机器在古代和历史上由许多人设计或制造，包括戈特弗里德·莱布尼茨、约瑟夫·玛丽·雅卡尔、查尔斯·巴贝奇、珀西·卢德盖特、莱昂纳多·托雷斯·凯维多、范尼瓦·布什等。艾达·洛夫莱斯曾推测巴贝奇的机器是“一台思考或...推理机器”，但她警告说：“有必要防止对机器的能力产生夸大的想法。”  

第一台现代计算机是第二次世界大战期间的大型机器（如康拉德·楚泽的Z3、艾伦·图灵的希思·罗宾逊和巨人机、阿塔纳索夫与贝里的ABC以及宾夕法尼亚大学的ENIAC）。ENIAC基于艾伦·图灵奠定的理论基础，并由约翰·冯·诺依曼发展而成，证明它是最具影响力的计算机。[57]
\subsection{人工智能的诞生（1941-1956）}
\begin{figure}[ht]
\centering
\includegraphics[width=8cm]{./figures/dc69a2c824689d03.png}
\caption{IBM 702：第一代人工智能研究人员使用的计算机。} \label{fig_RGZN_5}
\end{figure}
早期的思维机器研究受到了20世纪30年代末、40年代和50年代初流行的思想汇聚的启发。神经学的最新研究表明，大脑是一个由神经元构成的电气网络，神经元以“全或无”的脉冲方式发射。诺伯特·维纳的控制论描述了电气网络中的控制与稳定性。克劳德·香农的信息理论描述了数字信号（即“全或无”的信号）。艾伦·图灵的计算理论表明，任何形式的计算都可以通过数字化的方式进行描述。这些思想之间的紧密关系暗示，构建一个“电子大脑”可能是可行的。

在40年代和50年代，来自各个领域（数学、心理学、工程学、经济学和政治学）的少数科学家探索了几个对后来的人工智能研究至关重要的研究方向。艾伦·图灵是最早认真研究“机器智能”理论可能性的人之一。“人工智能研究”作为一门学科在1956年成立。[59][60][61]
\subsubsection{图灵测试} 
\begin{figure}[ht]
\centering
\includegraphics[width=8cm]{./figures/3f5360e4685a515c.png}
\caption{图灵测试[62]} \label{fig_RGZN_6}
\end{figure}
1950年，图灵发表了具有里程碑意义的论文《计算机机械与智能》，在其中他推测了创造能够思考的机器的可能性。在论文中，他指出，“思考”是一个难以定义的概念，并提出了著名的图灵测试：如果一台机器能够进行一场（通过电传机进行的）对话，且这场对话与与人类的对话无法区分，那么就可以合理地说这台机器是在“思考”。这种简化版的问题让图灵能够有力地论证“思考机器”至少是可行的，这篇论文回答了所有对这一命题的常见反对意见。图灵测试是人工智能哲学中第一个严肃的提案。
\subsubsection{人工神经网络}  
沃尔特·皮茨（Walter Pitts）和沃伦·麦卡洛克（Warren McCulloch）于1943年分析了理想化的人工神经元网络，并展示了它们如何执行简单的逻辑功能。他们是首个描述后来被称为神经网络的学者[66]。该论文受到了图灵1936年《可计算数的论述》一文的影响，采用了类似的两状态布尔“神经元”，但首次将其应用于神经功能[60]。受皮茨和麦卡洛克启发的学生之一是马文·敏斯基（Marvin Minsky），当时他是一个24岁的研究生。1951年，敏斯基和迪恩·埃德蒙兹（Dean Edmonds）建立了第一个神经网络机器——SNARC[67]。敏斯基后来成为人工智能领域最重要的领导者和创新者之一。
\subsubsection{控制论机器人}  
20世纪50年代，W·格雷·沃尔特（W. Grey Walter）的海龟机器人和约翰霍普金斯大学的野兽机器人等实验性机器人相继问世。这些机器人没有使用计算机、数字电子学或符号推理，而是完全由模拟电路控制[68]。
\subsubsection{游戏人工智能}  
1951年，克里斯托弗·斯特雷奇（Christopher Strachey）利用曼彻斯特大学的费兰提Mark 1计算机编写了一个跳棋程序[69]，而迪特里希·普林茨（Dietrich Prinz）则为国际象棋编写了一个程序[70]。阿瑟·塞缪尔（Arthur Samuel）的跳棋程序是他1959年论文《机器学习的若干研究：以跳棋为例》中的研究成果，该程序最终达到了足以挑战一位相当水平的业余玩家的水平[71]。塞缪尔的程序是后来被称为机器学习的早期应用之一[72]。游戏人工智能将继续作为人工智能发展的衡量标准，贯穿其历史。
\subsubsection{符号推理与《逻辑理论家》}
\begin{figure}[ht]
\centering
\includegraphics[width=6cm]{./figures/7245eef62d056505.png}
\caption{符号推理与《逻辑理论家》} \label{fig_RGZN_7}
\end{figure}
当50年代中期开始可以访问数字计算机时，一些科学家本能地认识到，一台能够操控数字的机器同样也能操控符号，而符号的操控可能正是人类思维的本质。这是一种创造思维机器的新方法。[73][74]

1955年，艾伦·纽厄尔（Allen Newell）和未来的诺贝尔奖得主赫伯特·A·西蒙（Herbert A. Simon）在J·C·肖（J. C. Shaw）的帮助下创造了“逻辑理论家”（Logic Theorist）。该程序最终证明了拉塞尔和怀特海德《数学原理》（Principia Mathematica）中的前52个定理中的38个，并为其中一些定理找到了新的、更优雅的证明。[75] 西蒙表示，他们“解决了久远的心灵/身体问题，解释了一个由物质组成的系统如何具备心灵的特性。”[76][c] 他们所提出的符号推理范式将主导人工智能的研究和资金支持，直到90年代中期，并且启发了认知革命。
\subsubsection{达特茅斯研讨会}  
1956年的达特茅斯研讨会是一个关键事件，标志着人工智能作为一门学科的正式诞生。它由马文·明斯基和约翰·麦卡锡组织，并得到了IBM的两位资深科学家克劳德·香农和内森·罗切斯特的支持。会议提案中指出，他们旨在验证这一断言：“学习的每一个方面或智能的任何其他特征都可以被如此精确地描述，以至于可以制造一台机器来模拟它。”  

“人工智能”这一术语由约翰·麦卡锡在研讨会上提出。与会者包括雷·所罗门诺夫、奥利弗·塞尔弗里奇、特伦查德·摩尔、阿瑟·塞缪尔、艾伦·纽厄尔和赫伯特·A·西蒙，他们都将在人工智能研究的初期几十年里创建重要的程序。在研讨会上，纽厄尔和西蒙首次展示了《逻辑理论家》程序。  

这次研讨会是人工智能获得名称、使命、首个重大成功和关键人物的时刻，被广泛认为是人工智能的诞生。
\subsubsection{认知革命}  
1956年秋天，纽厄尔和西蒙在麻省理工学院（MIT）信息理论特别兴趣小组会议上展示了《逻辑理论家》。在同一会议上，诺姆·乔姆斯基讨论了他的生成语法，乔治·米勒描述了他的开创性论文《神奇的数字七，加或减二》。米勒写道：“我带着一种比理性更为直观的信念离开了研讨会，那就是实验心理学、理论语言学和认知过程的计算机模拟都是一个更大整体中的一部分。”  

这次会议标志着“认知革命”的开始——一个跨学科的范式转变，涉及心理学、哲学、计算机科学和神经科学。它启发了符号人工智能、生成语言学、认知科学、认知心理学、认知神经科学以及计算主义和功能主义哲学学派的创建。所有这些领域都使用相关工具来建模心智，并且在一个领域中发现的结果对其他领域也具有相关性。  

认知方法使研究人员能够考虑“心理对象”，如思想、计划、目标、事实或记忆，通常使用高级符号在功能网络中进行分析。这些对象在早期的行为主义等范式中被视为“不可观察的”，因此不被允许作为研究对象。[h] 符号心理对象将成为接下来几十年人工智能研究和资金投入的主要焦点。
\subsection{早期的成功（1956-1974）}  
在达特茅斯研讨会之后开发的程序，对于大多数人来说，简直是“令人震惊的”[i]：计算机开始解决代数应用题，证明几何定理，并学习说英语。当时几乎没有人相信机器能够表现出如此“智能”的行为。[90][91][89] 研究人员在私下和公开场合表达了强烈的乐观情绪，预测不到20年内将建成完全智能的机器。[92] 像国防高级研究计划局（DARPA，时称“ARPA”）这样的政府机构向该领域注入了大量资金。[93] 到了1950年代末和1960年代初，多个英国和美国的大学设立了人工智能实验室。[60]  
\subsubsection{方法}  
在50年代末和60年代，出现了许多成功的程序和新的研究方向。其中最具影响力的有：

\textbf{推理、规划和问题解决作为搜索}  

许多早期的人工智能程序使用了相同的基本算法。为了实现某个目标（如赢得游戏或证明定理），它们一步步朝着目标前进（通过进行一次移动或推理），就像在迷宫中搜索一样，每当到达死胡同时便回溯。[94] 主要的困难在于，对于许多问题，"迷宫"中可能的路径数量是天文数字（这种情况被称为“组合爆炸”）。研究人员通过使用启发式方法来减少搜索空间，排除那些不太可能通向解决方案的路径。[95]

纽厄尔和西蒙试图在一个名为“通用问题求解器”的程序中捕捉这种算法的一般版本。[96][97] 其他“搜索”程序也能够完成令人印象深刻的任务，比如解决几何和代数问题，例如赫伯特·格尔恩特的几何定理证明器（1958年）[98] 和由敏斯基的学生詹姆斯·斯莱格尔在1961年编写的符号自动积分器（SAINT）[99][100]。其他程序则通过搜索目标和子目标来规划行动，例如斯坦福大学开发的STRIPS系统，用于控制机器人Shakey的行为。[101]

\textbf{自然语言}
\begin{figure}[ht]
\centering
\includegraphics[width=10cm]{./figures/ed021c1983496f79.png}
\caption{语义网络的示例} \label{fig_RGZN_8}
\end{figure}
人工智能研究的一个重要目标是使计算机能够使用像英语这样的自然语言进行交流。早期的一个成功是丹尼尔·鲍布罗的程序STUDENT，该程序能够解决高中代数的文字题。[102]

语义网将概念（例如“房子”，“门”）表示为节点，将概念之间的关系表示为节点之间的链接（例如“有一个”）。第一个使用语义网的人工智能程序是由罗斯·奎利安编写的[103]，而最成功（也是最具争议）的版本是罗杰·尚克的概念依赖理论。[104]

约瑟夫·维岑鲍姆的ELIZA能够进行非常真实的对话，以至于用户有时会被误导，以为他们在与一个人而非计算机程序进行交流（参见ELIZA效应）。但事实上，ELIZA只是给出预设的回应或重复它所听到的话，通过一些语法规则对其回应进行重新表述。ELIZA是第一个聊天机器人。[105][106]

\textbf{微世界}

在60年代末，麻省理工学院人工智能实验室的马文·明斯基和西摩·帕皮特提出，人工智能研究应该聚焦于人为构建的简单情境，称为微世界。他们指出，在像物理学这样成功的科学领域，基本原理通常通过简化模型（如无摩擦的平面或完全刚性的物体）来理解。在人工智能的研究中，大部分工作集中在“积木世界”上，这个世界由不同形状和大小的彩色积木组成，摆放在平面上。

这一范式引领了由杰拉尔德·萨斯曼、阿道夫·古兹曼、戴维·沃尔茨（发明了“约束传播”）以及特别是帕特里克·温斯顿等人进行的机器视觉方面的创新工作。与此同时，明斯基和帕皮特构建了一个可以堆叠积木的机器人臂，使得积木世界变得生动起来。特里·温诺格拉德的SHRDLU系统可以用普通的英语句子与微世界进行交流，规划操作并执行这些操作。

\textbf{感知机和早期神经网络}

在1960年代，资金主要流向研究符号人工智能的实验室，然而，仍然有一些人继续从事神经网络的研究。
\begin{figure}[ht]
\centering
\includegraphics[width=8cm]{./figures/b86894732f428cea.png}
\caption{马克1感知机} \label{fig_RGZN_9}
\end{figure}
感知机是一个单层神经网络，由Frank Rosenblatt于1958年提出（他曾是Marvin Minsky在布朗克斯科学高中的同学）。像大多数人工智能研究者一样，Rosenblatt对其潜力持乐观态度，预测感知机“最终可能能够学习、做出决策并翻译语言”。Rosenblatt的研究主要得到海军研究办公室的资助。

Bernard Widrow和他的学生Ted Hoff分别在1960年和1962年研发了ADALINE和MADALINE，这两者具有最多1000个可调权重。斯坦福研究所的一组由Charles A. Rosen和Alfred E.（Ted）Brain领导，研制了两台名为MINOS I（1960年）和MINOS II（1963年）的神经网络机器，主要由美国陆军信号军团资助。MINOS II具有6600个可调权重，并由SDS 910计算机控制，配置为MINOS III（1968年），该机器能够在军用地图上进行符号分类，并识别Fortran编码表单上的手写字符。在这个早期阶段，大多数神经网络的研究都涉及构建和使用定制硬件，而不是在数字计算机上进行模拟。

然而，由于结果匮乏和符号AI研究的竞争，MINOS项目于1966年停止了资助。Rosenblatt未能在1960年代争取到持续的资助。1969年，Minsky和Papert的《感知机》一书的出版使得研究突然停滞。该书指出，感知机在能力上存在严重的局限性，Rosenblatt的预测被大大夸大了。该书的影响是，几乎没有与联结主义相关的研究获得资助，持续了10年。政府资助的竞争最终以符号AI方法战胜神经网络为结局。

Minsky（曾参与SNARC的研究）成为纯联结主义AI的坚定反对者。Widrow（曾参与ADALINE的研究）转向了自适应信号处理。参与MINOS项目的SRI团队则转向了符号AI和机器人学。

主要问题是无法训练多层网络（反向传播的版本已经在其他领域使用，但这些研究者并不知情）。到了1980年代，AI社区开始认识到反向传播算法，并在21世纪，神经网络取得了巨大的成功，实现了Rosenblatt的乐观预期。然而，Rosenblatt未能亲眼看到这一成果，因为他在1971年死于一场划船事故。
\subsubsection{乐观主义}
第一代人工智能研究人员对他们的工作做出了以下预测：
\begin{itemize}
\item 1958年，H. A. Simon 和 Allen Newell：“在十年内，一台数字计算机会成为世界棋王”以及“在十年内，一台数字计算机会发现并证明一个重要的数学定理。”[124]
\item 1965年，H. A. Simon：“在二十年内，机器将能够完成任何人类能做的工作。”[125]
\item 1967年，Marvin Minsky：“在一代人内……创造‘人工智能’的问题将基本解决。”[126]
\item 1970年，Marvin Minsky（在《生活》杂志上）： “在三到八年内，我们将拥有一台具有普通人类智力的机器。”[127][l]
\end{itemize}
\subsubsection{资金支持}
1963年6月，麻省理工学院（MIT）获得了由新成立的先进研究计划署（ARPA，后来的DARPA）提供的220万美元资助。这笔资金用于资助MAC项目，后者包含了五年前由Minsky和McCarthy创立的“人工智能小组”。DARPA一直每年提供300万美元，直到70年代。[130] DARPA还向Newell和Simon在卡内基梅隆大学的项目、以及由John McCarthy在1963年创立的斯坦福大学人工智能实验室提供了类似的资助。[131] 另一个重要的人工智能实验室是由Donald Michie于1965年在爱丁堡大学成立的。[132] 这四个机构在多年间将继续成为学术界人工智能研究和资金支持的主要中心。[133][m]

这笔资金几乎没有附加任何条件：当时ARPA的负责人J. C. R. Licklider认为他的组织应该“资助人，而不是项目！”并允许研究人员追求他们感兴趣的任何方向。[135] 这种自由放任的氛围在MIT孕育了黑客文化，[136] 但这种“放手”的做法并没有持续太久。
\subsection{第一次人工智能寒冬（1974–1980）}
在1970年代，人工智能遭遇了批评和财政困难。人工智能研究人员未能认识到他们所面临问题的复杂性。过度的乐观主义抬高了公众的期望，而当预期的结果未能实现时，针对人工智能的资金支持大幅减少。[137] 缺乏成功的结果表明，当时人工智能研究者所采用的技术不足以实现他们的目标。[138][139]

然而，这些挫折并未影响该领域的成长和进展。资金的削减仅影响了少数几个主要实验室，[140] 而批评也大多被忽视。[141] 公众对该领域的兴趣继续增长，[140] 研究人员的数量急剧增加，[140] 并且在逻辑编程、常识推理等多个领域探索了新思路。历史学家托马斯·海格（Thomas Haigh）在2023年认为这一时期并没有所谓的寒冬，[140] 而人工智能研究员尼尔斯·尼尔森（Nils Nilsson）则将这一时期描述为人工智能领域最“激动人心”的时期。[142]
\subsubsection{问题}
在70年代初，人工智能程序的能力有限。即便是最为出色的程序，也只能处理它们应该解决的简单版本问题；[n] 所有这些程序在某种意义上都是“玩具”。[144] 人工智能研究人员开始遇到几个限制，这些限制在数十年后才被克服，还有一些问题至今仍困扰着这一领域，尤其是在2020年代：
\begin{itemize}
\item \textbf{有限的计算能力}：当时的计算机没有足够的内存或处理速度来完成任何真正有用的任务。[o] 例如，罗斯·奎利安（Ross Quillian）在自然语言处理方面取得的成功，仅通过20个单词的词汇表来演示，因为那时的内存只能容纳这么多。[146] 汉斯·莫拉维克（Hans Moravec）在1976年提出，计算机仍然弱得百万倍，无法展示智能。他举了个类比：人工智能对计算能力的需求，就像飞机对马力的需求一样。在某个阈值以下，这是不可能的，但随着能力的增加，最终可能变得容易。“有足够的马力，”他说，“任何东西都会飞。”[147][p]
\item \textbf{难解性和组合爆炸}：1972年，理查德·卡普（Richard Karp）基于斯蒂芬·库克（Stephen Cook）1971年的定理，证明了许多问题只能在指数时间内求解。找到这些问题的最优解需要极其庞大的计算时间，除非问题本身非常简单。这一限制适用于所有使用搜索树的符号AI程序，意味着许多“玩具”级别的解决方案永远无法扩展为有用的系统。[143][139]
\item \textbf{莫拉维克悖论}：早期的人工智能研究在让计算机完成“智能”任务，如证明定理、解决几何问题和下棋等方面非常成功。这些任务的成功让研究人员相信，智能行为的问题在很大程度上已经被解决。[149][150] 然而，他们在解决“非智能”任务时完全失败，比如识别面孔或不碰到任何物体就穿过房间。[149][151] 到了80年代，研究人员才意识到，符号推理完全不适合处理这些感知和传感运动任务，而且这种方法有其局限性。[150]
\item \textbf{常识知识的广度}：许多重要的人工智能应用，如视觉或自然语言处理，要求程序拥有大量关于世界的信息：程序需要知道它可能在看什么，或者它在谈论什么。这要求程序知道世界上大多数事情，就像一个孩子一样。研究人员很快发现，这需要巨量的信息，包括数十亿条原子事实。1970年时，没人能建立一个足够大的数据库，也没人知道如何让程序学习这么多信息。[152]
\item \textbf{表示常识推理}：当研究人员尝试通过形式逻辑或符号来表示常识推理时，出现了许多相关问题。[q] 对于非常普通的推理描述，随着研究的深入，描述的内容往往越来越长，因为需要越来越多的例外、澄清和区分。[r] 然而，当人们思考普通概念时，他们并不依赖精确的定义，而是似乎做出数百个不精确的假设，并在必要时通过使用整个常识知识体系来纠正它们。杰拉尔德·萨斯曼（Gerald Sussman）观察到，“使用精确的语言来描述本质上不精确的概念，并不会使它们变得更加精确。”[153]
\end{itemize}
\subsubsection{资金减少}
资助人工智能研究的机构，如英国政府、DARPA和国家研究委员会（NRC），对进展的缺乏感到沮丧，最终几乎切断了所有无明确方向的人工智能研究资助。这一趋势始于1966年，当时自动语言处理咨询委员会（ALPAC）报告批评了机器翻译的努力。在花费了2000万美元之后，NRC终止了所有支持。[154] 1973年，Lighthill报告对英国人工智能研究的现状进行了批评，指出人工智能未能实现其“宏伟目标”，并导致英国该国人工智能研究的解散。[155]（报告特别提到组合爆炸问题作为人工智能失败的原因。）[139][143][s] DARPA对卡内基梅隆大学的语音理解研究项目的研究人员感到非常失望，并取消了每年300万美元的资助。[157][t]

汉斯·莫拉维克（Hans Moravec）将这场危机归咎于他同事们的不切实际预测。“许多研究人员陷入了一个日益夸大的网络。”[158][u] 然而，另一个问题是：自1969年《曼斯菲尔德修正案》通过以来，DARPA承受着越来越大的压力，要求资助“以任务为导向的直接研究，而不是基础性的无方向研究”。1960年代那种富有创造性、自由探索的资金支持不再来自DARPA，后者转而将资金用于具有明确目标的具体项目，如自主坦克和战斗管理系统。[159][v]

主要实验室（如MIT、斯坦福、CMU和爱丁堡）曾获得政府的慷慨支持，当这种支持被撤回时，这些地方成为预算削减的主要受影响者。而这些机构之外的成千上万的研究人员以及加入这一领域的更多研究人员并未受到影响。[140]
\subsubsection{哲学和伦理批评}
一些哲学家对人工智能研究者所提出的主张表示强烈反对。其中最早的反对者之一是约翰·卢卡斯（John Lucas），他认为哥德尔的不完全性定理表明，形式系统（如计算机程序）永远无法看清某些命题的真理，而人类却能够。[161] 休伯特·德雷福斯（Hubert Dreyfus）嘲笑1960年代的虚假承诺，并批评人工智能的假设，认为人类推理实际上涉及的“符号处理”非常少，而更多的是具身的、本能的、无意识的“知道如何做”。[w][163] 约翰·塞尔（John Searle）于1980年提出的中文房间论证，试图表明一个程序不能被认为“理解”它所使用的符号（这种能力被称为“意向性”）。塞尔认为，如果符号对机器没有意义，那么机器就不能被描述为“思考”。[164]

这些批评没有被人工智能研究者认真对待。像不可解性和常识知识等问题似乎更为紧迫和严重。实际上，对于一个计算机程序来说，“知道如何做”或“意向性”到底有什么区别尚不清楚。麻省理工学院的明斯基（Minsky）曾说德雷福斯和塞尔“误解了问题，应该被忽视。”[165] 同样也在麻省理工任教的德雷福斯受到了冷落：他后来表示，人工智能研究者“敢不敢在我面前吃午餐”。[166] 《ELIZA》的作者约瑟夫·韦岑鲍姆（Joseph Weizenbaum）也是德雷福斯立场的直言批评者，但他“故意让人清楚地知道[他对德雷福斯的对待方式]并不是对待人的方式”，[x] 他认为这种做法不专业且幼稚。[168]

当肯尼斯·科尔比（Kenneth Colby）写出了一个基于ELIZA的“能够进行心理治疗对话”的计算机程序时，韦岑鲍姆开始对人工智能产生严重的伦理疑问。[169][170][y] 韦岑鲍姆对科尔比将一个无意识的程序视为严肃的治疗工具感到不安。两人开始发生冲突，而科尔比没有在程序的贡献中注明韦岑鲍姆的名字，使得局势更加复杂。1976年，韦岑鲍姆出版了《计算机的力量与人类的理性》，其中论述了人工智能的误用可能会贬低人类生命的价值。[172]
\subsubsection{斯坦福大学、卡内基梅隆大学和爱丁堡大学的逻辑研究}
逻辑早在1958年就被引入人工智能研究，约翰·麦卡锡（John McCarthy）在他的“建议接收者”（Advice Taker）提案中提出了这一概念。[173][98] 1963年，J·艾伦·罗宾逊（J. Alan Robinson）发现了一种简单的方法，可以在计算机上实现推理，即分辨率与统一算法。[98] 然而，像麦卡锡和他在1960年代末的学生们尝试的直接实现，尤其在处理简单定理证明时特别困难：这些程序需要进行天文数字级的步骤才能证明简单的定理。[173][174] 1970年代，罗伯特·科瓦尔斯基（Robert Kowalski）在爱丁堡大学开发了一种更具成果的方法，这很快促成了与法国研究者阿兰·科尔梅罗（Alain Colmerauer）和菲利普·鲁塞尔（Philippe Roussel）的合作，他们创建了成功的逻辑编程语言Prolog。[175] Prolog使用了逻辑的一个子集（霍恩子句，密切相关于“规则”和“产生规则”），这些子集允许可处理的计算。规则继续发挥影响，为爱德华·费根鲍姆（Edward Feigenbaum）的专家系统提供了基础，并为艾伦·纽厄尔（Allen Newell）和赫伯特·A·西蒙（Herbert A. Simon）继续开展的工作奠定了基础，这些工作最终将发展为Soar和他们的统一认知理论。[176]

逻辑方法的批评者指出，正如德雷福斯（Dreyfus）所言，人类在解决问题时很少使用逻辑。心理学家如彼得·沃森（Peter Wason）、埃莉诺·罗斯（Eleanor Rosch）、阿莫斯·特沃斯基（Amos Tversky）、丹尼尔·卡尼曼（Daniel Kahneman）等人的实验提供了证据。[z] 麦卡锡回应说，人们做什么是无关紧要的。他认为，真正需要的是能解决问题的机器，而不是像人类那样思考的机器。[aa]
\subsubsection{麻省理工学院的“反逻辑”方法}
麦卡锡方法的批评者之一是他在全国各地的同事，特别是麻省理工学院的研究者。马文·明斯基（Marvin Minsky）、西摩·帕珀特（Seymour Papert）和罗杰·香克（Roger Schank）试图解决像“故事理解”和“物体识别”这样的难题，这些问题要求机器像人一样思考。为了使用像“椅子”或“餐馆”这样的普通概念，他们不得不做出与人类通常做出的相同的不合逻辑的假设。不幸的是，像这些模糊概念很难用逻辑表示。麻省理工学院选择专注于编写能够解决特定任务的程序，而不使用高级抽象定义或一般认知理论，并通过反复测试来衡量性能，而不是从第一原理出发进行推理。香克将他们的“反逻辑”方法描述为杂乱无章的，相对于麦卡锡、科瓦尔斯基（Kowalski）、费根鲍姆（Feigenbaum）、纽厄尔（Newell）和西蒙（Simon）使用的整洁范式。[177][ab]

1975年，明斯基在一篇具有开创性的论文中指出，许多同事正在使用相同的工具：一种框架，它捕捉了我们所有关于某事的常识假设。例如，当我们使用“鸟”这个概念时，立即会浮现出一系列事实：我们可能假设它会飞、吃虫子等等（这些并不适用于所有鸟类）。明斯基将这些假设与一般类别关联，它们可以被子类别和个体的框架继承或根据需要被覆盖。他称这些结构为“框架”（frames）。香克使用了他称之为“脚本”（scripts）的框架版本，成功地回答了关于英语短篇小说的问题。[178] “框架”最终在软件工程中广泛应用，作为面向对象编程（OOP）的一部分。

逻辑学家们迎接了这个挑战。帕特·海耶斯（Pat Hayes）声称，“‘框架’大部分只是形式逻辑的第一阶语法的一种新形式。”但他指出，“然而，有一两个看似微小的细节，给人带来了很多麻烦，尤其是默认值。”[179]

雷·赖特（Ray Reiter）承认，“传统的逻辑，如一阶逻辑，缺乏足够的表达能力来充分表示默认推理所需的知识。”[180] 他提出通过闭合世界假设来扩展一阶逻辑，即如果无法证明某个结论的对立面，那么结论默认成立。他展示了这种假设如何与使用框架推理时所做的常识性假设相对应。他还表明，它在Prolog中有其“程序等价物”，即“失败的否定”。赖特所提出的闭合世界假设“不是一阶的概念。（它是一个元概念。）”[180] 然而，基思·克拉克（Keith Clark）展示了，作为有限失败的否定可以被理解为在一阶逻辑中隐式推理使用定义，包括一个独特名称假设，即不同的术语表示不同的个体。[181]

在1970年代末和整个1980年代，许多逻辑和一阶逻辑的扩展被开发出来，用于逻辑编程中的“失败的否定”和默认推理的更广泛应用。总体而言，这些逻辑被称为非单调逻辑（non-monotonic logics）。
\subsection{繁荣（1980–1987）}
在1980年代，一种被称为“专家系统”的人工智能程序被世界各地的公司采纳，知识成为主流AI研究的焦点。各国政府提供了大量资金支持，例如日本的第五代计算机项目和美国的战略计算计划。“总体而言，AI产业从1980年的几百万美元，发展到1988年的数十亿美元。”[122]
\subsubsection{专家系统广泛应用}
专家系统是一种使用从专家知识中推导出的逻辑规则来回答问题或解决特定领域知识相关问题的程序。[182] 最早的例子由Edward Feigenbaum及其学生开发。Dendral，始于1965年，通过光谱仪读数识别化合物。[183][120] MYCIN，开发于1972年，用于诊断传染性血液疾病。[122] 它们展示了这一方法的可行性。

专家系统将自己限制在一个狭小的特定领域（从而避免了常识知识问题）[120]，其简单的设计使得一旦系统建立，程序可以相对容易地进行构建和修改。总的来说，这些程序被证明是有用的：这是AI此前未能实现的目标。[184]

1980年，CMU为数字设备公司（Digital Equipment Corporation）完成了一个名为R1的专家系统。它取得了巨大的成功：到1986年，它为公司每年节省了4000万美元。[185] 世界各地的公司开始开发和部署专家系统，到1985年，他们在人工智能上的支出已超过10亿美元，其中大部分用于内部AI部门。[186] 支持这一行业的公司应运而生，包括硬件公司Symbolics和Lisp Machines以及软件公司IntelliCorp和Aion。[187]
\subsubsection{政府资金增加}
1981年，日本国际贸易与工业省为第五代计算机项目拨出了8.5亿美元。他们的目标是编写程序并构建能够进行对话、翻译语言、解读图像并像人类一样推理的机器。[188] 令“反逻辑派”不悦的是，他们最初选择了Prolog作为该项目的主要计算机语言。[189]

其他国家也开始推出自己的新项目。英国启动了价值3.5亿英镑的Alvey项目。[190] 一组美国公司组成了微电子与计算机技术公司（Microelectronics and Computer Technology Corporation，简称“MCC”），为人工智能和信息技术的大规模项目提供资金。[191][190] DARPA也作出了回应，成立了战略计算计划（Strategic Computing Initiative），并在1984年至1988年间将其在人工智能上的投资增加了三倍。[192][193]
\subsubsection{知识革命}
专家系统的力量来自于它们所包含的专家知识。它们是人工智能研究中新方向的一部分，这一方向在70年代逐渐获得关注。Pamela McCorduck写道：“人工智能研究人员开始怀疑——尽管这违背了科学简约的原则——智能可能确实基于在不同方式中使用大量多样化知识的能力。”[194] “1970年代的一个重要教训是，智能行为在很大程度上依赖于处理一个领域中具体任务所需的知识，有时甚至是非常详细的知识。”[195] 知识基础系统和知识工程在1980年代成为人工智能研究的主要焦点。[196] 人们希望通过庞大的数据库解决常识知识问题，并提供常识推理所需的支持。

在1980年代，一些研究人员试图直接解决常识知识问题，通过创建一个包含普通人所知道的所有平凡事实的庞大数据库。Douglas Lenat开始了一个名为Cyc的数据库，并主张没有捷径可走——机器理解人类概念的唯一方法是通过手动逐个概念地进行教学。[197]
\subsection{1980年代的新方向}
尽管符号知识表示和逻辑推理在80年代产生了有用的应用，并获得了大量资金支持，但它仍未能解决感知、机器人学、学习和常识方面的问题。一小部分科学家和工程师开始怀疑符号方法是否能足够应对这些任务，并发展了其他方法，如“联结主义”、机器人技术、“软”计算和强化学习。Nils Nilsson将这些方法称为“亚符号”方法。
\subsubsection{神经网络的复兴：“联结主义”}
\begin{figure}[ht]
\centering
\includegraphics[width=6cm]{./figures/25a080db1c85b184.png}
\caption{四节点的Hopfield网络} \label{fig_RGZN_10}
\end{figure}
1982年，物理学家约翰·霍普菲尔德证明了一种形式的神经网络（现在称为“霍普菲尔德网络”）可以学习和处理信息，并且在任何固定条件下经过足够的时间后会收敛。这是一个突破性的进展，因为之前人们认为非线性网络通常会演化成混沌状态。[198] 与此同时，杰弗里·辛顿和大卫·鲁梅尔哈特推广了一种用于训练神经网络的方法，称为“反向传播”。[ac] 这两个发展有助于复兴对人工神经网络的探索。[122][199]

神经网络与其他一些类似的模型在1986年《并行分布式处理》一书出版后引起了广泛关注，这本书是鲁梅尔哈特和心理学家詹姆斯·麦克莱兰德编辑的两卷论文集。这个新兴领域被命名为“联结主义”，并且符号AI的支持者与“联结主义者”之间展开了激烈的辩论。[122] 辛顿将符号称为“AI的发光以太”——即一种不可行且误导性的智能模型。[122]

1990年，扬·勒昆在贝尔实验室使用卷积神经网络识别手写数字。该系统在90年代被广泛应用，读取邮政编码和个人支票。这是神经网络的第一个真正有用的应用。[200][201]
\subsubsection{机器人学与具身推理}
Rodney Brooks、Hans Moravec等人认为，为了展示真正的智能，机器必须拥有一个身体——它需要感知、移动、生存并与世界互动。[202] 感知运动技能对于更高层次的技能（如常识推理）至关重要。这些技能无法通过抽象的符号推理高效实现，因此，人工智能应该在不使用符号表示的情况下解决感知、移动、操作和生存等问题。这些机器人学研究人员主张“从底层构建智能”。[ad]

这一思想的先驱是David Marr，他在1970年代末从理论神经科学的成功背景中来到MIT，领导了视觉研究小组。他拒绝所有符号方法（无论是McCarthy的逻辑还是Minsky的框架），认为人工智能需要从底层理解视觉的物理机制，才能进行任何符号处理。（Marr的研究因1980年罹患白血病而提前终止。）[204]

在1990年，机器人学研究人员Brooks在他的论文《大象不会下棋》中直接反驳了物理符号系统假设，认为符号并非总是必要的，因为“世界本身就是最好的模型。它总是最新的，里面包含了所有需要知道的细节。关键是要恰当地感知这些信息，并且足够频繁地感知。”[206]

在1980年代和1990年代，许多认知科学家也拒绝了符号处理模型，认为身体对推理至关重要，这一理论被称为“具身心智假设”。[207]
\subsubsection{软计算与概率推理}
软计算使用的是处理不完全和不精确信息的方法。这些方法并不试图给出精确的、逻辑上的答案，而是给出“可能”正确的结果。这使得它们能够解决精确符号方法无法处理的问题。新闻报道常常声称这些工具可以“像人类一样思考”。[208][209]

Judea Pearl的《智能系统中的概率推理：合理推理网络》是一本具有影响力的1988年出版的书籍，[210] 它将概率和决策理论引入到人工智能中。[211] 由Lofti Zadeh在1960年代发展起来的模糊逻辑，开始在人工智能和机器人学中得到更广泛的应用。进化计算和人工神经网络也处理不精确的信息，并被归类为“软计算”。在1990年代和2000年代初，许多其他软计算工具被开发并投入使用，包括贝叶斯网络，[211] 隐马尔可夫模型，[211] 信息理论和随机建模。这些工具反过来依赖于先进的数学技术，如经典优化。1990年代和2000年代初，这些软工具被人工智能的一个子领域——“计算智能”所研究。[212]
\subsubsection{强化学习}
强化学习[213] 每当一个智能体执行一个期望的行为时，就会给予奖励，当它执行不佳时，可能会给予负奖励（或“惩罚”）。这种方法在20世纪上半叶由心理学家使用动物模型描述，如Thorndike，[214][215] Pavlov，[216] 和Skinner。[217] 在1950年代，Alan Turing[215][218] 和Arthur Samuel[215] 预见到强化学习在人工智能中的作用。

一个成功且有影响力的研究项目由Richard Sutton和Andrew Barto于1972年开始领导。他们的合作革新了强化学习和决策制定的研究，持续了四十年。[219][220] 1988年，Sutton将机器学习用决策理论（即马尔可夫决策过程）来描述。这为这一学科提供了坚实的理论基础，并获得了在运筹学领域开发的大量理论成果。[220]

同样在1988年，Sutton和Barto开发了“时间差分”（TD）学习算法，其中智能体只有在其对未来的预测有改善时才会获得奖励。它显著地优于之前的算法。[221] TD学习被Gerald Tesauro于1992年应用在程序TD-Gammon中，该程序在跳棋游戏中表现与最优秀的人类玩家相当。该程序通过自我对弈、零前知识来学习游戏。[222] 在一个有趣的跨学科融合案例中，神经学家在1997年发现，大脑中的多巴胺奖励系统也使用一种版本的TD学习算法。[223][224][225] TD学习在21世纪变得非常有影响力，并被用于AlphaGo和AlphaZero等项目。[226]
\subsection{第二次AI冬天}  
在1980年代，商业界对人工智能的热情起伏，呈现出典型的经济泡沫模式。随着大量公司失败，商业界的普遍看法是，AI技术不可行。[227] 对人工智能声誉的损害一直持续到21世纪。在AI领域内部，对于为何AI未能实现60年代人们对类人智能的梦想，意见分歧。所有这些因素共同作用，导致AI领域分裂成多个竞争的子领域，专注于特定的问题或方法，有时甚至以新的名称掩盖“人工智能”这一被打上污点的名号。[228]

在接下来的20年里，AI始终能够为特定的孤立问题提供有效的解决方案。到了1990年代末，AI被广泛应用于技术行业，尽管大多是在幕后。成功的原因在于计算机计算能力的提高，与其他领域（如数学优化和统计学）的合作，以及采用最高标准的科学可验证性。到2000年，AI已经实现了其最早的一些目标。这个领域比以往任何时候都更加谨慎且成功。
\subsubsection{AI冬天}  
“AI冬天”这一术语由那些经历了1974年资金削减的研究人员创造，他们当时担心专家系统的热情已经失控，且失望肯定会随之而来。[ae] 他们的担忧是有根据的：在1980年代末和1990年代初，AI遭遇了一系列财务挫折。[122]

天气变化的第一个迹象是1987年专用AI硬件市场的突然崩溃。Apple和IBM的台式电脑逐渐提高了速度和性能，到了1987年，它们比Symbolics等公司制造的昂贵Lisp机器更强大。此时已没有足够的理由再购买这些专用机器。一个价值五亿美元的行业在一夜之间被摧毁。[230]

最终，最早成功的专家系统，如XCON，证明了维护成本过高。它们难以更新，无法学习，并且“脆弱”（即，在面对异常输入时会犯下离谱的错误）。专家系统虽然有用，但只在少数特殊情境下有效。[231]

在1980年代末，战略计算计划（Strategic Computing Initiative）大幅削减了对AI的资金支持。DARPA的新领导层认为AI不是“下一个浪潮”，因此将资金转向了那些看起来更有可能立即产生成果的项目。[232]

到了1991年，日本第五代计算机计划中1981年设定的雄心勃勃的目标尚未实现。事实上，其中一些目标，如“进行随意对话”，要到40年后才得以实现。和其他AI项目一样，预期远高于实际可能达到的水平。[233][af]

到1993年底，超过300家AI公司已关闭、破产或被收购，实际上结束了第一次AI商业浪潮。[235] 1994年，HP Newquist在《大脑制造者》一书中表示：“人工智能的短期未来——以其商业形式——似乎在一定程度上依赖于神经网络的持续成功。”[235]
\subsubsection{幕后AI}  
在1990年代，由AI研究人员最初开发的算法开始作为更大系统的一部分出现。AI解决了许多非常困难的问题[ag]，这些解决方案证明在整个技术行业中都非常有用，[236][237]例如数据挖掘、工业机器人、物流、语音识别[238]、银行软件[239]、医疗诊断[239]以及谷歌的搜索引擎。[240][241]

在1990年代和2000年代初期，AI在这些成功中几乎没有得到任何认可。许多AI的重大创新被降级为计算机科学工具箱中的另一项技术。[242] Nick Bostrom解释道：“许多前沿的AI技术已经渗透到一般应用中，通常因为一旦某项技术变得足够有用并且普及，它就不再被称为AI了。”[239]

1990年代的许多AI研究者故意将他们的工作命名为其他名称，如信息学、知识基系统、“认知系统”或计算智能。这部分可能是因为他们认为自己的领域与AI本质上不同，但也因为新名称有助于获得资金。[238][243][244] 至少在商业世界中，AI冬天的失败承诺继续困扰着AI研究直到2000年代，正如《纽约时报》在2005年报道的：“计算机科学家和软件工程师避免使用‘人工智能’这一术语，担心被视为异想天开的梦想家。”[245]
\subsubsection{数学严谨性、更强的合作和狭隘的聚焦 } 
AI研究人员开始比以往任何时候都更多地开发和使用复杂的数学工具。[246][247] AI中的大多数新方向都高度依赖于数学模型，包括人工神经网络、概率推理、软计算和强化学习。在1990年代和2000年代，许多其他高度数学化的工具也被应用于AI。这些工具被应用于机器学习、感知和移动性等领域。

人们普遍意识到，AI需要解决的许多问题已经由统计学、数学、电气工程、经济学或运筹学等领域的研究人员在研究。共享的数学语言不仅促进了与这些更成熟、更成功领域的高水平合作，还使得可以实现可衡量和可证明的成果；AI已成为一个更加严谨的“科学”学科。

1990年代成功的另一个关键原因是AI研究人员将重点放在具有可验证解决方案的具体问题上（这一方法后来被讽刺为狭义AI）。这提供了当前有用的工具，而不是对未来的猜测。
\subsubsection{智能体}  
在1990年代，一个名为“智能体”的新范式被广泛接受。[248][249][ah] 尽管早期的研究人员提出了模块化的“分而治之”方法来解决AI问题，[ai] 但智能体直到Judea Pearl、Allen Newell、Leslie P. Kaelbling等人将决策理论和经济学的概念引入AI研究时，才达到了现代形式。[250] 当经济学家对理性智能体的定义与计算机科学中对象或模块的定义结合时，智能体范式就此完成。

智能体是一个能够感知其环境并采取行动以最大化成功机会的系统。根据这一定义，解决特定问题的简单程序也可以视为“智能体”，人类及人类组织（如公司）也是智能体。智能体范式将AI研究定义为“智能体的研究”。[aj] 这是对一些早期AI定义的泛化：它不仅研究人类智能，还研究各种形式的智能。

这一范式使得研究人员可以自由地研究孤立的问题，并就方法存在分歧，但仍保留希望，认为他们的工作最终可以结合成一种具有一般智能的智能体架构。[251]
\subsubsection{里程碑和摩尔定律}  
1997年5月11日，深蓝（Deep Blue）成为第一个击败世界棋王加里·卡斯帕罗夫的计算机象棋系统。[252] 2005年，斯坦福大学的机器人在DARPA大奖赛中获胜，通过自主驾驶在未排练的沙漠小径上行驶了131英里。两年后，CMU的团队在DARPA城市挑战赛中获胜，在城市环境中自主导航55英里，同时应对交通危害并遵守交通法规。[253]

这些成功并非由于某种革命性的全新范式，而主要得益于工程技能的细致应用和90年代计算机速度与容量的巨大提升。[ak] 实际上，深蓝的计算机比Christopher Strachey在1951年教会的Ferranti Mark 1象棋下得快了1000万倍。[al] 这一显著增长是由摩尔定律衡量的，摩尔定律预测计算机的速度和内存容量每两年翻一番。“原始计算能力”的基本问题正逐渐被克服。